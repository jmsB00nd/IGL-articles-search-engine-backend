{
  "id": 19,
  "title": "The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development",
  "authors": [
    "Steven I. Ross",
    "Fernando Martinez",
    "Stephanie Houde",
    "Michael Muller",
    "Justin D. Weisz",
    "code-fluent large language models, foundation models, conversa-"
  ],
  "institutions": [
    "IBM Argentina",
    "IBM Research AI",
    "IBM Research AI",
    "tional interaction"
  ],
  "resume": "Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the model's responses. We developed a prototype system - the Programmer's Assistant - in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.",
  "content": "CCS CONCEPTS ?   H u m a n - c e n t e r e d   c o m p u t i n g   ?   H C I   t h e o r y ,   c o n c e p t s   a n d \n m o d e l s ;   ?   S o f t w a r e   a n d   i t s   e n g i n e e r i n g   ?   D e s i g n i n g   s o f t w a r e ; \n ?   C o m p u t i n g   m e t h o d o l o g i e s   ?   G e n e r a t i v e   a n d   d e v e l o p m e n t a l \n a p p r o a c h e s . \n 1 INTRODUCTION Software development is a highly skilled task that requires\nknowledge, focus, and creativity . Many techniques have been\ndeveloped to enhance the productivity of software engineers, such\nas advanced code repositories , knowledge repositories ,\nQ&A sites , and pair programming practices . Collaborative\nsoftware engineering is especially promising, given that\nprofessional software development is rarely a solo activity and relevant\nknowledge and expertise are typically distributed widely within an\norganization . Many eforts have focused on incorporating\ncollaborative technologies into software development environments\n(e.g. ). The pioneering work of Rich and Waters on The Programmer?s\nApprentice  presented a novel concept of a knowledgeable\nautomated assistant ? in efect, an artificial collaborative partner ? that\ncould help software engineers with writing code, designing\nsoftware systems, and creating requirements specifications. At the time,\nAI technologies and computing resources were not suficient to\nfully implement their vision. In the intervening years, an increase in\ncomputational power, the availability of large corpora of language\nand code data, and the development of deep neural networks have\nmade new approaches to achieving their goals worth exploring. Recently, models leveraging the transformer architecture \nhave been developed to perform domain-specific software\nengineering tasks, such as translating code between languages ,\ngenerating documentation for code , and generating\nunit tests for code  (see Talamadupula  and Allamanis et al.\n for surveys). Recently developed foundation models ? large\nlanguage models that can be adapted to multiple tasks and which\nexhibit emergent behaviors for which they have not been\nexplicitly trained  ? have also proven to be capable with source code.\nWhile the intent of training LLMs such as GPT-2  and GPT-3 \nwas to give them mastery of natural language, it quickly became\napparent that the presence of code in their training corpora had\ngiven them the ability to generate code based on natural language\ndescriptions . The Codex model  was then produced by\nfinetuning GPT-3 on a large corpus of source code data, leading to the\ndevelopment of Copilot , a tool that helps software engineers by\nautocompleting code as it is being written. Experimentation with\nCopilot has shown its ability to perform additional tasks, such as\nexplaining code, generating documentation, and translating code\nbetween languages . Although autocompletion interfaces are useful and valuable\nwhen the system can discern the developer?s intent, there are many\ninstances where that is insuficient. For example, the developer\nmay have a good idea of what they want to do, but may be unclear\non what functions, libraries, or even algorithms to employ. They\nmay even have general programming questions that need to be\nanswered before they are able to write any code. In this paper, we seek to understand whether modern\ndevelopments in code-fluent foundation models ? large language models\nthat have been fine-tuned on source code data ? are suficient to\nsupport a conversational agent that can act as an assistant in the\nsoftware development process. We developed the Programmer?s\nAssistant to explore the capabilities that conversational interaction\ncould enable and the extent to which users would find\nconversational assistance with programming tasks desirable and useful. We hypothesize that a conversational system may provide a\nlfexible and natural means for interacting with a code-fluent LLM.\nConversational interaction could enable users to pursue their\nquestions in a multiple exchange dialog (as observed by Barke et al.\n) that allows them to ask follow-up questions and refine their\ninquiries. A conversational programming assistant could ask the\nuser clarifying or disambiguating questions to help it arrive at the\nbest answer. It could also provide multiple types of assistance to\nthe user beyond simply generating code snippets, such as engaging\nin general discussion of programming topics (e.g. ) or\nhelping users improve their programming skills (as observed in other\nstudies of automating technologies ). Our paper makes the following contributions to the IUI\ncommunity:\n? We provide empirical evidence that a conversational\nprogramming assistant based on a state-of-the-art, code-fluent\nfoundation model provides valuable assistance to software\nengineers in a myriad of ways: by answering general\nprogramming questions, by generating context-relevant code,\nby enabling the model to exhibit emergent behaviors, and by\nenabling users to ask follow-up questions that depend upon\ntheir conversational and code contexts.\n? We show how diferent interaction models ? conversation,\ndirect manipulation, and search ? provide complementary\ntypes of support to software engineers with tradeofs\nbetween the user?s focus and attention, the relevance of\nsupport to their code context, the provenance of that support,\nand their ability to ask follow-up questions.\n? We motivate the need to further understand how to design\nhuman-centered AI systems that enhance the joint\nperformance of the human-AI collaboration.\n2 RELATED WORK xref #text The Programmer?s Apprentice xref #text Code-fluent Foundation Models and  Human-Centered Evaluations of  Programming Assistance Generative models based on the transformer architecture  have\nrecently been applied to the domain of software engineering.\nCodelfuent large language models are capable of generating code from\nnatural language descriptions , translating code from one\nlanguage to another , generating unit tests , and even\ngenerating documentation for code . These models are\nprobabilistic systems, and as such, do not always produce perfect\nresults (e.g. code that is free of syntax or logical errors). Nonetheless,\nWeisz et al.  found that software engineers are still interested\nin using such models in their work, and that the imperfect outputs\nof these models can even help them produce higher-quality code\nvia human-AI collaboration . New tools based on code-fluent LLMs are actively being\ndeveloped. GitHub Copilot1 is described as ?Your AI pair programmer.? It\nis optimized for the code autocompletion use case: given a starting\nsnippet such as a method?s documentation, signature, or partial\nimplementation, Copilot completes the implementation. Copilot is\nbased on the OpenAI Codex model , a 12 billion parameter\nversion of GPT-3 , fine-tuned on code samples from 54 million\npublic software repositories on GitHub. Empirical evaluations of Conversational Interaction and Analysis 2.3.1 Conversational Interaction. Using natural language to\ninteract with technology has had a long research history , starting in\nthe 1960s with pattern-matching approaches like Eliza , and\ncontinuing to today with state-of-the-art large language\nmodelbased conversational systems  such as Meena  and\nBlenderBot . These systems are intended to address the problem of\nopen-domain dialog, with a goal of realistically engaging in\nconversation, but not particularly in a goal-directed or task-oriented\nmanner. Task-oriented chatbots are typically built with frameworks such\nas the Microsoft Bot Framework2, Google DialogFlow3, and IBM\nWatson Assistant4. They operate using pre-defined dialogue trees\nand use natural language processing to detect conversational intents\nand extract contextual entities. This structure enables the creation of\nspecial purpose, but fairly limited and rigid, conversational agents. There have been several recent attempts to investigate\nconversational programming assistance. Kuttal et al.  conducted a\nWizard of Oz study in which a pair programmer was replaced with\na conversational agent, and they found that ?agents can act as\neffective pair programming partners.? The PACT system  is a\nchatbot that assists programmers adjusting to new programming THE PROGRAMMER?S ASSISTANT In order to explore conversational programming assistance, we\ncreated a functional prototype system called The Programmer?s\nAssistant. Our prototype, shown in Figure 1, combines a code editor\nwith a chat interface. The code editor was implemented using the\nMicrosoft Monaco Editor5 embedded in a React wrapper6. The\nchat user interface was implemented using the React-Chatbot-Kit7\nframework. To drive the conversational interaction, we employed\nOpenAI?s Codex model , accessed through its web API. We developed our prototype as a lightweight coding\nenvironment in order to examine the user experience of interacting with\na conversational assistant. Our work was exploratory in nature,\nand thus we did not have specific design goals for the prototype\nbeyond integrating a code editor with a code-fluent LLM. We also\ndid not attempt to target the prototype for a specific class of users\n(e.g. novices or experts) or use cases (e.g. writing code vs. learning a\nnew programming language), as we wanted any value provided by\nconversational assistance to emerge from our user study. We also\ndid not implement the ability to run or debug code in our prototype\nas we wanted to explore the nature of the conversational\ninteraction rather than having users focus extensively on the production\nof working code. When designing how users would interact with the\nProgrammer?s Assistant, we decided that it should be available on demand\nand not monitor the user?s work in progress or give unsolicited\nsuggestions or advice, in keeping with the conversational agent\ninteraction model proposed by Ross et al. . This approach\nwas supported by feedback from prospective users who were\nconcerned about the assistant providing criticism of unfinished eforts\nin progress or distracting them while they worked. Instead, we\nforce initiative onto the user and only have the assistant respond\nto their requests. In this way, the assistant can provide help when\nrequested without undesirable interruptions that can distract or\ninterfere with the user?s flow. When a user interacts with the assistant, we keep track of their\nselection state in the code editor. If a user sends a message to the\nassistant without any code selected in the editor, then that message\n(along with the prior conversational context) is passed directly to\nthe model. If a user sends a message to the assistant with new code Supporting Conversational Interaction xref #text Architecture & UI Design The Programmer?s Assistant communicates with the Codex API via\na proxy server that forwards requests from the React client. The\nproxy also rate-limits access to conform to the API?s policy, and\nit logs UI events from the client (e.g. requests, responses, and UI\n8The assistant?s use of non-authoritative responses was encoded into the LLM prompt;\noutput token probabilities from the LLM were not utilized to influence the assistant?s\nresponse.\ninteractions) in a back-end database. To address inconsistencies\nin the style or formatting of code generated by Codex, the proxy\nserver reformats all code segments using the Black code formatter\n9 before transmitting them to the client UI. The client maintains the transcript of the ongoing conversation.\nEach time the user sends a message in the chat, the client constructs\na new prompt for the model by concatenating the initial prompt,\nthe chat transcript, and the user?s new utterance, and makes a\nrequest for the model to complete the transcript. This completion\nrequest also specifies a stop sequence of tokens to prevent the\nmodel from generating both sides of the conversation (e.g. what\nthe model thinks the user?s next utterance might be after the\nassistant?s response). Given the API?s limitation on context length\n(4,096 tokens for both the prompt and model response), we silently\n?forget? older exchanges in the chat transcript when constructing\nthe prompt to ensure that our completion request remains within\nbounds. Nonetheless, the entire conversational history remains\nvisible to the user in the UI. The client UI provides a loose coupling between the source code\neditor and the chat interface. Users can hide the chat pane when\nthey wish to focus solely on their code, and re-engage with it\nwhen they desire assistance. Code selected in the editor is included\nin the conversation in order to couple the code context with the\nconversation. Easily-accessible buttons are provided in the UI to\ncopy code responses from the assistant to the clipboard.\n3.3 Handling Model Limitations While developing the Programmer?s Assistant, and in early pilot\ntesting, we experienced some quirks and shortcomings of the model\nand our approach to using it for conversational interaction. One\nlimitation stemmed from the fact that the model sometimes\nproduced incorrect responses (e.g. code with syntax errors), incomplete\nresponses (e.g. code that was missing functionality), irrelevant\nresponses (e.g. responses not related to the user?s question), or\ninsubstantial responses (e.g. ?I don?t know?). Because of the probabilistic\nnature of model inference, re-prompting the model would\nsometimes produce a more correct or appropriate response. Thus, we\nadded the ability for users to ?try again,? either by asking in the chat\nor by clicking a button in the UI (Figure 1C). This feature removes\nthe assistant?s last response from the context presented to the model\nand then re-invokes the model with an increased temperature10. Although it is possible for transformer models such as Codex to\nproduce multiple possible responses to a single prompt, we only\nrequest a single response in order to speed up response time as\nwell as to preserve the token budget for conversational context.\nThus, the ?try again? feature provides an alternate way to produce\na wider variety of responses. During pilot testing, we noticed that the assistant sometimes\nhappened to generate the same response to multiple, unrelated\nrequests. In these cases, the assistant tended to get ?stuck? in a pattern\nof repeating the same response and was unable to resume normal\nconversation. To avoid this problem, we automatically execute a Sample Conversation We provide a real sample conversation with the Programmer?s\nAssistant in Listing 1. This conversation begins with the assistant\ngreeting the user (line 1). Next, the user asks a general Python\nprogramming question (line 4), to which the assistant responds with\na non-authoritative remark (?I think...?) and a code snippet (line\n9). The user next asks a follow-up question that depends on their\nprevious question and the assistant?s response (line 11), to which\nthe assistant provides another code snippet (line 15), satisfying the\nuser?s request. The user then switches topics and asks the assistant to write\na Fibonacci function (line 17), and the assistant again responds\nwith a non-authoritative remark (?I will give it a try,? line 20) and\na block of code. The user then asks how the function works (line\n30) and the assistant provides an adequate description (line 32).\nNext, the user asks the assistant to re-implement the function in a\ndiferent way (line 37), again leveraging the ability to ask follow-up\nquestions. The assistant produces an alternative implementation\nthat conforms to the user?s request (line 41). The user follows up\nwith a question that depends on multiple past utterances and\nresponses in the chat transcript (line 47), and the assistant produces\na relevant response (line 49). The conversation closes with the user\nthanking the assistant (line 53) and the assistant acknowledging\ntheir gratitude (line 55). EMPIRICAL STUDY OF CONVERSATIONAL  PROGRAMMING ASSISTANCE We conducted an empirical user study of the Programmer?s\nAssistant to assess whether conversational assistance provides value in\na software engineering context11. Our inquiry focused on the user\nexperience and value of conversational interactions grounded in\ncode. We therefore designed a qualitative study to investigate\nattitudes toward a conversational programming assistant: do people\nenjoy interacting conversationally, what kinds of questions do they\nask, and how does the experience compare to other forms of\nprogramming support such as searching the web? We note that prior\nstudies (e.g. ) conducted quantitative examinations\nof the use of LLMs in code work; our study is akin to Weisz et al.?s\nqualitative examination of software engineers? attitudes toward\nworking with models that may fail to produce working code . To address our questions, we deployed the Programmer?s\nAssistant within our organization ? a global technology company ? and\ninvited people to try it out and give us feedback on their experience.\nWe invited people with varying levels of programming skill in order\nto obtain a wide range of feedback on the kinds of use cases for\nwhich the tool could provide assistance.\n4.1 Tasks We set up the Programmer?s Assistant as a playground environment\nthat participants could try out with a few sample programming\nproblems. We created a tutorial to orient participants to the\nassistant, its capabilities, and how to interact with it. We also created\nfour programming challenges focused on writing code,\ndocumenting code, and writing tests for code. We designed these challenges\nto expose participants to a broad range of the assistant?s capabilities.\nFor each of these challenges, we explicitly did not evaluate metrics\nsuch as the participant?s productivity, the quality of their solutions,\nor the time taken to produce them, as the focus of our study was to\nunderstand the utility of conversational interaction. We selected\nPython as the language used for the tutorial and challenges because\nof its general popularity  and the fact that it was well-supported\nby our underlying LLM .\n4.1.1 Tutorial. All participants were first introduced to the\nProgrammer?s Assistant through a tutorial. The tutorial walked each\n11For historical context, we note that our study was completed before the public\nrelease of ChatGPT , which has subsequently demonstrated the application of\nconversational assistance for programming tasks .\nparticipant through 10 sample interactions to give them a feeling\nfor what the assistant could do and how to interact with it. The\ntutorial demonstrated how to ask questions, how to request code to\nbe generated, and how to evaluate existing code. It did not\nspecifically cover how to generate documentation or unit tests. Tutorial\ninstructions were provided within the code editor. We include the\nspecific text used for the tutorial in Appendix B.\n4.1.2 Programming Challenges. After completing the tutorial,\nparticipants unlocked four programming challenges. Two of the\nchallenges involved coding problems (writing a queue class and writing\ncode to create a scatterplot of data in a CSV file), one involved\ndocumenting a given function (an implementation of a graph search\nalgorithm), and one involved writing unit tests for a given\nfunction (computing the greatest common divisor of two arguments).\nAlthough the Programmer?s Assistant was visible and available for\nuse, we provided no specific requirement that it actually be used to\ncomplete the challenges. After participants completed their solution to a challenge, they\nsubmitted it by clicking a button in the UI. The code editor used\nin the Programmer?s Assistant was not a fully-functional IDE and\ndid not provide syntax checking or the ability to run, test, or debug\ncode. Due to these limitations, participants were asked to submit\ntheir solutions when they felt they had completed the challenge to\ntheir own satisfaction.\n4.2 Participants To recruit participants for our study, we posted internal\nadvertisements in various communications channels focused on software\nengineering. Our advertisements stated that we were evaluating a\nconversational programming assistant, but were kept deliberately\nvague in order to minimize the impact on peoples? expectations of\nthe experience. Our advertisement yielded a pool of 140 potential participants.\nIn order to recruit a diverse sample, we used a screening survey\nthat asked about their job role, their familiarity with and recency\nof use of Python, and their availability to participate in our study.\nWe accepted participants into the study on a rolling basis, selecting\nparticipants to capture a range of programming experiences and\nensure balanced gender representation. We conducted periodic\nreviews to determine whether we were learning something new from\neach participant or if we had reached the point of saturation . We\nstopped collecting data after running 42 participants as we were no\nlonger observing any new behaviors or gleaning any new insights.\nThe Programmer?s Assistant implementation and configuration\nwere held constant over the course of the study; no changes to the\nUI design or LLM prompt were made. Our participants had the following self-identified characteristics:\n? Job role: 19 Software Engineers, 12 Researcher/Scientists, 3\nSoftware Architects, 2 Data Scientists, 1 Machine Learning\nEngineer, 1 Systems Test Engineer, 1 Business Analyst, 1\nManager, 1 Marketer, and 1 Consultant.\n? Gender: 21 Female, 19 Male, 1 Gender Variant /\nNon-conforming, and 1 Preferred not to say.\n? Python Experience: 17 participants had 3+ years of Python\nexperience, 11 had 1-3 years, 11 had less than 1 year, and 3\nwere not familiar with Python.\n? Recency of Python Use: 29 participants had written Python\ncode within the past month, 4 within the past year, 5 within\nthe past 5 years, and 4 had not written Python code within\nthe past 5 years. We provide full demographic information for individual\nparticipants in Appendix E.\n4.3 Procedure P a r t i c i p a n t s   c o m p l e t e d   t h e   s t u d y   o n   t h e i r   o w n   t i m e ,   i n d e p e n d e n t l y \n a n d   w i t h o u t   m o d e r a t i o n .   E a c h   p a r t i c i p a n t   w a s   p r o v i d e d   w i t h   a   w e b \n l i n k   t o   a   p r e - s t u d y   s u r v e y   t h a t   d e s c r i b e d   t h e   n a t u r e   o f   t h e   s t u d y   a n d \n t h e   t a s k s   t h a t   t h e y   w o u l d   b e   e x p e c t e d   t o   p e r f o r m .   T h e y   w e r e   t h e n \n d i r e c t e d   t o   t h e   P r o g r a m m e r ? s   A s s i s t a n t   t o   c o m p l e t e   t h e   t u t o r i a l   a n d \n t h e   f o u r   p r o g r a m m i n g   c h a l l e n g e s .   W h e n   p a r t i c i p a n t s   i n d i c a t e d   t h e y \n w e r e   f i n i s h e d   w i t h   t h e   c h a l l e n g e s   1 2 ,   t h e y   w e r e   d i r e c t e d   t o   a   f i n a l \n p o s t - s t u d y   s u r v e y .   C o m p l e t e   s e s s i o n s   g e n e r a l l y   r e q u i r e d   a b o u t   a n \n h o u r   o f   e f o r t ,   t h o u g h   s o m e   p a r t i c i p a n t s   s p r e a d   t h e i r   e f o r t   a c r o s s \n a   l o n g e r   p e r i o d   o f   t i m e   a n d   a c r o s s   m u l t i p l e   s e s s i o n s .   P a r t i c i p a n t s \n w e r e   c o m p e n s a t e d   f o r   t h e i r   t i m e   a t   a   r a t e   e q u i v a l e n t   t o   U S   $ 1 5 / h r . \n 4 . 4 Measures W e   c o l l e c t e d   a   v a r i e t y   o f   d a t a   i n   o u r   s t u d y   f r o m   t h r e e   s o u r c e s : \n ( 1 )   S u r v e y s .   W e   e m p l o y e d   t h r e e   s u r v e y s   i n   t h e   s t u d y :   a \n p r e s t u d y   s u r v e y   t o   c o l l e c t   d e m o g r a p h i c   i n f o r m a t i o n ,   a   p r e - t a s k \n s u r v e y   t o   g a u g e   e x p e c t a t i o n s   o f   t h e   c o n v e r s a t i o n a l   u s e r \n e x p e r i e n c e ,   a n d   a   p o s t - t a s k   s u r v e y   t o   a s s e s s   a c t u a l   u s e r \n e x p e r i e n c e .   W e   d e s c r i b e   t h e s e   s u r v e y   q u e s t i o n s   i n   t h e   r e l e v a n t \n c o n t e x t   o f   o u r   r e s u l t s ,   a n d   w e   p r o v i d e   a   c o m p l e t e   l i s t i n g   o f \n a l l   s u r v e y   i n s t r u m e n t s   i n   A p p e n d i x   A . \n ( 2 )   E v e n t   l o g s .   T h e   P r o g r a m m e r ? s   A s s i s t a n t   w a s   i n s t r u m e n t e d \n t o   c o l l e c t   d a t a   o n   p a r t i c i p a n t s ?   u s a g e .   T h e   e v e n t   l o g s \n p r o v i d e d   t i m e s t a m p e d   r e c o r d s   o f   i n t e r a c t i o n   e v e n t s ,   i n c l u d i n g \n c o n v e r s a t i o n a l   e x c h a n g e s ,   h i d i n g / s h o w i n g   t h e   a s s i s t a n t ,   u s e \n o f   t h e   ? t r y   a g a i n ?   a n d   ? s t a r t   o v e r ?   f e a t u r e s ,   a n d   u s e   o f \n c o p y / p a s t e . \n ( 3 )   C o n v e r s a t i o n   l o g s .   F r o m   t h e   e v e n t   l o g s ,   w e   e x t r a c t e d \n c o n v e r s a t i o n a l   t r a n s c r i p t s   b e t w e e n   e a c h   p a r t i c i p a n t   a n d   t h e \n P r o g r a m m e r ? s   A s s i s t a n t . \n 5 \n 5 . 1 RESULTS  Data & Analysis We collected a wealth of data in our study: 126 survey responses\nfrom three surveys per participant, containing 296 written\ncomments in open-ended survey questions, and 4,877 instances of 23\ndiferent types of UI events, including 1,699 conversational\nexchanges13 in the event logs. We also compute, for each participant,\ncounts or durations for 21 diferent metrics from the event logs. In our analysis, we deliberately exclude the portion of our data\ncollected during the tutorial exercise. We exclude this data because\nthat activity was guided by the tutorial instructions, not by our\nparticipants? own initiative. Thus, our final sample consists of 3,172\n12We did not enforce that participants actually complete all of the challenges.\nNevertheless, all participants but one did submit solutions to all of the challenges.\n13We refer to a participant?s utterance, followed by the assistant?s response, as a\nconversational exchange.\nevents, including 968 conversational exchanges in the event logs;\nno survey data was excluded. Our primary analysis of this data is qualitative, as our\nparticipants provided us with a rich source of interesting feedback and\nthought-provoking insights in their comments. Where applicable,\nwe supplement this data with quantitative data from the survey\nand the event logs, as well as chat transcript data from the\nconversation logs. In this way, we triangulate  across our three\ndata sources, using the open-ended survey data as a foundation.\nWhen we quote participants, either from their qualitative survey\nresponses or the conversational transcripts, we reproduce their\nwords exactly as typed, including typos, misspellings,\ngrammatical errors, capitalization, and potential trigger words, and we only\nmake minor clarifying edits where needed, delineated by square\nbrackets. In order to set the context for our analysis, we first describe\nhow we used reflexive thematic analysis to analyze participants?\nresponses to the open-ended survey questions. We then describe\nour analysis of the conversation logs and our development of a\ncoding guide based on Conversation Analysis , and specifically,\nMoore and Arar?s Natural Conversation Framework .\n5.1.1 Thematic Analysis of Qualitative Survey Responses. We\nconducted a reflexive thematic analysis to analyze the responses to\nour seven open-ended survey questions. We followed the process\ndescribed by Braun and Clarke  in which researchers immerse\nthemselves in the data, generate codes for material that seems\ninteresting, and then iteratively group and refine codes through\ncollaborative discussion in order to identify higher-level themes.\nInitially, four authors performed open-coding on the open-ended\nsurvey responses. Through discussion, these codes were grouped\nand consolidated into a single set, which were then re-applied to\nthe data by two authors. After another round of discussion, these\nauthors identified a set of 12 higher-level themes. Some themes had\nclear parallels to quantitative survey questions or event log data,\nand thus represented clear instances where we were able to\ntriangulate across data sources. Other themes surprised us. We structure\nour presentation of the results based on these 12 themes, grouped\ninto three diferent aspects of the user experience: expectations\nand experience, utility of conversational assistance, and patterns of\ninteraction and mental models.\n5.1.2 Conversation Analysis via the Natural Conversation\nFramework. In order to understand the content and structure of the\nconversations that took place between our participants and the\nProgrammer?s Assistant, we turned to the Natural Conversation\nFramework  (NCF). We developed a codebook for the event\nlogs, beginning with 21 diferent categories of utterances from the\nNCF. Nine NCF categories ? Acknowledgment, Apology,\nConfirmation, Expression of Gratitude, Farewell, Greeting, Self-Identification,\nWelfare Check, and Welfare Report ? appeared twice in our\ncodebook to distinguish cases in which the utterance was made by the\nhuman participant vs. the assistant. Other NCF categories were\nsplit to provide nuanced detail about the interaction; for example,\nwe distinguished three diferent kinds of NCF requests, depending\nupon whether they were stated as Requests for Action (e.g. ?Would\nyou...?), Commands of Action (e.g. ?Write a function that...?), or\nExpressions of Desire (e.g. ?I want...?). We also added 18 additional Expectations and Experience Pilot testing of the Programmer?s Assistant suggested that software\nengineers would be skeptical of a conversational programming\nassistant and its ability to provide useful assistance. Our study\nrevealed that, for most participants, their actual experience after\nusing the tool was better than they had anticipated. Participants\nwere surprised at the quality of the assistant?s responses and they\nappreciated how its integration with the code editor reduced the\namount of context switching they needed to do in the UI. Some\nparticipants struggled with the code selection feature, although\nothers appreciated the ability to ask questions related to selected\ncode.\n5.2.1 Usage. All of our participants engaged with the\nProgrammer?s Assistant while working on the challenges, despite there\nbeing no requirement to do so. Forty-one participants submitted\nsolutions to all four challenges, and one participant, P14, only\nsubmitted solutions for one of the four challenges. Participants spent\nan average of 68 minutes engaged with the assistant, as measured\nby the amount of time the Programmer?s Assistant window was in\nfocus. Participants made an average of 23.0 utterances (SD = 15.1\nutterances) to the assistant. On average, 6.2 of their utterances (SD =\n4.3 utterances) contained a code selection. The average latency per\nrequest14 was 6.7 seconds (SD = 3.1 seconds). We saw a 66.3% rate of acceptance of generated code, where we\nconsidered code to be accepted if the participant performed a copy\nimmediately after the code was generated. This acceptance rate is\nmuch higher than the 27% acceptance rate reported for Copilot .\nWe believe one reason we observed a higher acceptance rate is\nbecause Copilot?s completion suggestions are generated proactively,\nwhereas the Programmer?s Assistant?s suggestions are generated\nupon request. When copying generated code from the assistant,\nparticipants most often copied the entirety of the generated code,\nand only in 5.8% of cases did they copy a smaller portion of it.\n5.2.2 User Experience Expectations & Changed Atitudes. Prior to\nrunning our study, we had reason to believe that participants would\nbe skeptical of a conversational programming assistant. Before\ndeveloping the Programmer?s Assistant, we showed potential users\nmockups of a program editor with an integrated chatbot feature.\nThese prototypes elicited uniformly negative reactions. People told\nus about their frustrating experiences with conventional chatbots\nand raised doubts about the knowledge, capabilities, and value\nof a conversational programming assistant. This skepticism\nmotivated us to develop the Programmer?s Assistant in order to evaluate\nwhether the conversational experience, as powered by a\nstate-ofthe-art code-fluent LLM, would be better than people had\nanticipated. During pilot testing, we received feedback that the\nProgrammer?s Assistant provided a much better conversational experience\ncompared to testers? previous experiences with chatbots. Thus, in\ndesigning our study, we felt it important to first gauge participants?\nexpectations of a conversational interaction around code, and then\nmeasure their experience after the fact.\n14This time includes additional time added by our proxy server to ensure our\nconformance to the API rate limitation. We developed a short inventory of six scale items to measure user\nexperience of code work15. The scale was administered twice: once\nbefore participants were exposed to the Programmer?s Assistant\n(but after they had been briefed that they would interact with an AI\nchatbot), and once after completing the programming challenges.\nThe items were presented with the appropriate tense: Do you expect\n(Did you find that) the Programmer?s Assistant: (a) will be (was)\neasy to use; (b) will understand (understood) your requests; (c) will\nprovide (provided) high quality responses; (d) will help (helped)\nyou to write better code; (e) will help (helped) you to write code\nmore quickly; (f) will be (was) enjoyable to use. Each item was rated\non a 4-point scale of extent: Not at all (1), A little (2), Somewhat (3),\nA great deal (4). A factor analysis revealed the items on this scale measured a\nsingle construct, which we identify as user experience (Cronbach?s\n = 0.87). Thus, we computed two scores of user experience (UX)\nfor each participant: a pre-task UX score computed as the average\nof their six pre-task expectation scale responses, and a post-task\nUX score computed as the average of their six post-task experience\nscale responses. We found that participants had lower initial expectations for\ntheir experience with a conversational programming assistant\n(pretask UX M (SD) = 3.0 (0.62) of 4) than their experience actually\nwas (post-task UX M (SD) = 3.6 (0.32) of 4). A paired sample t-test\nshows that this diference was significant,  (41) = 5.94,  < .001,\nCohen?s  = 0.92 (large). Measured another way, 32 participants\n(76.2%) had post-task UX ratings that were higher than their\npretask expectations, demonstrating a significant shift in attitudes\ntoward conversational programming assistance. However, the UX ratings alone fail to capture participants?\nnuanced expectations of the assistant and the reasons for their shifted\nattitudes after using it. Participants expressed a variety of\nexpectations of the assistant before using it, including that it would be easy\nto use (P30) and produce correct responses (P30), understand the\nproblem and what is being asked of it (P8, P9, P11), not interfere\nwith their flow state (P5), produce imperfect or questionable\noutputs (P6, P21), improve with feedback (P31), provide generic and\nunhelpful answers (P17) or only answer basic questions (P40), and\nproduce responses quickly (P40). P17 expected ?to be frustrated very quickly and that what I?d think\nwould be relatively common questions would be responded to with\ngeneric, unhelpful answers.? P6 explained, ?I didn?t have very good\nexperiences with chatbots. I think I?ll need to spend more time in\nreviewing and fixing the suggestions than in writing the code myself\nfrom scratch.? P11 had a more balanced view, that ?It?ll do some tasks\nreally well, but others will not be as reliable.? After interacting with the Programmer?s Assistant, many\nparticipants commented on how the experience was better than they\nanticipated, because it ?seemed to be able to handle complex issues?\n(P10) and ?was a great help? (P8). P20 felt it was ?incredible!? P6 and\nP17, who were both initially skeptical, reported having a positive\nexperience. For P6, ?It absolutely exceeded all my expectations, in\n15Our scale items were modeled from scales published in Weisz et al. [103, Table 9 ?\nAI Support] that measured constructs including ease of use (item 3), response quality\n(item 1), the production of higher-quality code (item 5), and the ability to write code\nmore rapidly (item 4). We added additional items to cover the constructs of request\nunderstanding and enjoyment, and we cast all items on a 4-point scale of extent.\nall aspects that I could have imagined and more!? P17 provided a\nmore quantitative assessment: ?Initial expectations: 3 Actual: 9.5.?\nP38 was emphatic in their evaluation: ?I was blown away how well\nit allowing me to structure how I want the code to look and work and\njust giving me the thing I asked for.? Many participants described a sense of surprise in their\nexperiences. P9 was surprised by how well it understood their requests:\n?I was surprised at how well the Programmer Assistant\nwas able to understand my requests and generate good\ncode/documentation/tests. It understood major concepts\nand was able to explain it to me in a clear way, and it\nwas also able to understand and write functional code. It even was able to help me review my answer. I was also\nsurprised at how well it could understand the context\nof what I was asking in follow-up questions when I did\nnot specify exactly what I was talking about, but rather\nreferencing our prior conversation (such as, ?what does\nthat mean?).? (P9) Similarly, P6 was surprised that they liked the conversational\ninteraction when they expected that they wouldn?t:\n?I though[t] I wouldn?t like the chatbot interaction and\nthat I would prefer something like the tool I?ve seen in\nthose demos [of Copilot]. But surprisingly, after using\nthe chatbot (and seeing the results: easy to use, it\nunderstands well, I felt it like a partner) I like this kind of\nhelp.? (P6)\n5.2.3 Quality of Assistant?s Responses. In order to gauge the quality\nof responses produced by the Programmer?s Assistant, we examined\nthe 910 task-oriented requests made by participants in the study.\nFor the vast majority (80.2%), the assistant produced a correct\nresponse (Grants Request (Complete)); in other cases, the assistant?s\nresponse was incorrect (9.6%; Provided Wrong Answer), correct but\nincomplete (4.4%; Grants Request (Incomplete)), or the assistant\ndidn?t understand (3.4%; Didn?t Understand), claimed ignorance of\nthe subject (1.5%; Claims Ignorance), or produced another type of\nresponse (0.9%; Appears Fixated, Spews Garbage). Participants also reported experiencing this variability in the\nquality of the assistant?s responses. Some participants described\nhow the assistant provided ?detailed answers? (P17) and ?high\nquality outputs? (P18) that were ?surprisingly good? (P2). P6 felt it was\n?incredible to see the quality of the responses,? and P3 even explored\nthe assistant?s capabilities outside the scope of the challenges and\nfound that it could handle those as well:\n?It was surprising the quality of the code and the ability\nto answer all my questions correctly. Although I think\nthe challenges may be biased towards what the Assistant\nis able to do, it was a great experience because I asked\nmany other things and it was able to answer correctly.?\n(P3) Of course, the Programmer?s Assistant wasn?t perfect, and some\nparticipants did run into issues. For P35, ?The documentation\ngeneration did not perform very well.? P16 questioned the accuracy of the\nknowledge encoded in the model: ?Does the model need to be\nupdated? It said latest python version is 3.7 but google says it?s 3.10.? In\nsome instances, participants needed to ask their question multiple\ntimes to get a good response: ?you need to ask many times if you\nwant to get an answer and also a detailed explanation? (P3). P27 felt,\n?it was annoying when I asked it to try again and it would give me\nthe same response.? P22 struggled because, ?It didn?t seem to handle\nmultiple sentences well.? P28 perhaps ofered the most scathing criticism, that, ?It makes\nmistakes often enough to be not very practical.? However, despite\nthe production of poorer-quality responses, other participants felt\nthat the assistant was still helpful. P36 reported that, ?Only minor\ntweaks were normally needed to correct any issues.? Similarly, P38\ndescribed how the assistant wasn?t able to completely solve their\nproblem, but provided a useful start:\n?There was only one hickup I noticed where when I\nasked it to memoize fibonacci it couldn?t, but it dropped\nthe building blocks on my lap for me to finish so that\nwas fine, that was like minutes of efort on my part.?\n(P38)\n5.2.4 UI Design & Afordances. Participants made many comments\non our specific UI design and the afordances provided (or not\nprovided) in our chat-augmented editor. Overall, the integration\nbetween the chat pane and the code editor was ?very good? (P23),\nwith a ?nice interface between the code pane and the assistant pane?\n(P17) that ?makes it really convenient? (P35). Prior research by Brandt et al.  has shown how keeping\ndevelopers focused in their IDE improves productivity, and our\nparticipants expressed similar sentiments. P40 remarked, ?It allows\nme to stay in one browser window/tab!? and P12 hinted at how the\ninterface might preserve their flow state by ?prevent[ing] me from\ngetting distracted when looking into an issue in another tab.? Some aspects of our user interface were confusing to participants,\nsuch as the mechanism for selecting code to be included in the\nconversational context. P7 remarked, ?It?s was a little confusing\ndoing the selection part for it to tell me what a function does, but...\nit gave me code that was insanely easy to copy and paste.? Other\nparticipants appreciated the code selection mechanism, such as P11:\n?I enjoyed the code selection feature, and found that very easy to use.?\nIn the event logs, we identified 20 instances in which a participant\nunintentionally included selected code in the conversation when\nit wasn?t needed (Includes Extraneous Selection), 12 instances in\nwhich a code selection was omitted when it was needed to provide\ncontext for the question (Missing Selection), and 16 instances in\nwhich a participant copy/pasted code directly into the chat rather\nthan selecting it in the editor (Pasted Code in Chat). Although\nthese cases represent a small fraction of the 227 instances in which\na code selection was required and included in the conversation\n(Includes Selection), their presence does indicate that more attention\nis needed to the interaction design of code selection. Another issue regarded the awareness of the ?try again? and\n?start over? features. The ?try again? feature was only used by 14\nparticipants, who used it a total of 63 times over the course of\nthe study. Some participants used it specifically when they got an\nanswer which they saw as clearly wrong, while others used it to\nget a variety of possible answers before proceeding. The ?start over?\nfeature was used even less, by 5 participants who used it a total of\n6 times. Despite our efort to surface these conversational features\nin the UI via shortcut buttons, they may not have been suficiently\nnoticeable or salient: ?The ?try again? button is not so reachable, often\ntimes I forgot it exists? (P23). By contrast, at least one participant\nwas successful with these features:\n?at some point it had issue with challenge 3 and I had to\nstart over. Just asking ?try again? was not enough and I\nwas getting always the same (wrong and not related)\nanswer. starting again solved the issue!? (P20)\n5.3 Utility of Conversational Assistance Our next set of themes concerns the utility provided by\nconversational programming assistance. Participants felt the assistant was\nhighly valuable and desired to use it in their own work. They felt it\nwould be most helpful for smaller or narrowly-scoped tasks, but\nable to provide a wide variety of types of assistance. The fact that\nthe interaction model was conversational and grounded in code\nwere valuable aspects, as was the ability for the assistant to bolster\nusers? learning about programming topics through that\ninteraction. Participants did question whether they could trust and rely\nupon the assistant?s responses, echoing a similar theme discussed\nin Weisz et al. .\n5.3.1 Value & Appropriate Tasks. Participants rated the value of\nthe Programmer?s Assistant highly (M (SD) = 8.6 (1.4) of 10). Many\nparticipants asked questions such as, ?Can I have it in my editor\nplease?? (P15), or made comments that, ?I would enjoy using it in\nthe future? (P36), ?I would love to be able to... have access to it for\nmy coding? (P37), and ?I?d love to use this tool as part of my usual\nprogramming workflow if I could!? (P39). Some of the reasons why\nparticipants found it valuable are because it ?help[s] me remember\nhow to do things in certain languages that normally I would just\nGoogle? (P9) and ?It helps me to avoid silly syntax errors and can\nwhen I cannot remember exact function/method names and required\narguments? (P40). We did not observe any diferences in value\nratings based on participants? familiarity with or recency of using\nPython. Participants described a wide variety of tasks for which they\nfelt the assistant would be useful. These tasks included ?ordinary?\n(P23), ?simpler? (P2), and ?small, repetitive? (P4) tasks such as ?quick\nlookups? (P25) for ?short chunks of code? (P11) or for ?narrowed\nquestions? (P26). Participants also felt the assistant was useful for\n?small containable novel algorithms? (P38) and ?little coding problems?\n(P4). Several kinds of task assistance were reported as being valuable,\nsuch as explaining code (P31), implementing business logic in a\nUI (P38), understanding what code does (P19, P37), and recalling\nlanguage syntax, method names, and arguments (P12, P15, P20, P40,\nP42). P27 felt that the assistant was ?More helpful when recognizing\na specific well known algorithm but not things you make yourself.? Participants also made recommendations for how to increase\nthe value of the Programmer?s Assistant. P38 suggested, ?What\nwould blow me away though is if it?s able to help with what I do most\noften which is to integrate, refactor and iterate on an existing system.?\nP16, P26, and P38 all desired more information on the data sources\nused to produce the assistant?s responses. P9 requested to ?Have\nthe Programmer?s Assistant examine your code and make proactive\nsuggestions for improving it in the chat.? P36 requested the same,\nbut cautioned that, ?Care would need to be taken to avoid becoming\nan annoyance or disrupting the flow of a coding session.? In the post-task survey, we probed participants on how certain\nchanges to the Programmer?s Assistant would either decrease,\nincrease, or result in no change to its value. Over 75% of participants\nfelt that the assistant would be more valuable if it operated in a\nproactive manner, either by making improvement suggestions in\nthe chat or as comments directly in the code. Similarly, 78.6% of\nparticipants felt that having more buttons in the UI for common\nfeatures such as explaining or documenting code would make the\ntool more valuable.\n5.3.2 Conversational Interactions Grounded in Code. One of the\nchallenges in interpreting participants? comments about the utility\nof the Programmer?s Assistant was in disentangling the extent to\nwhich value was derived from the quality of the underlying model\nversus the integration of conversation in a code context. Indeed,\nparticipants felt that the chat interaction was valuable: 69.0% of\nparticipants felt that eliminating the conversational interaction\nand making the assistant behave more like web search would\ndecrease its value. Further, our analysis of the conversation transcripts\nrevealed that 42% of the 910 task-oriented utterances from\nparticipants required historical conversational context (Chat Context\nRequired) in order to be correctly interpreted. Thus, we observe\nthat behaviorally, participants did rely on conversational context\nin their interactions. In the post-task survey, 83% of participants rated the importance\nof the ability to ask follow-up questions as being ?somewhat? or ?a\ngreat deal.? Several participants specifically commented on the value\nof this conversational context. P39 remarked, ?I absolutely loved\nhow you can straight up ask follow-up questions to the Programmers?\nAssistant without having to reiterate the original topic/question.? P15\nexpressed a similar sentiment, saying, ?I think the conversational\ncontext was someone helpful, just in communicating that it?s a running\nconversation where my context is remembered.? P9 provided a similar\nanalysis:\n?This tool was so helpful at answering questions I had\nabout the code in the context of the code I am working\non... I was also impressed with how well it was able to\nremember the context of our conversation, especially\nwhen I asked vague follow-up questions.? (P9) In addition, some participants identified how a conversational\ninteraction grounded in code was useful, ?because I think to\n?understand? the dev context could be VERY important? (P31). In fact,\n24.9% of task-oriented utterances included a relevant code selection\n(Includes Selection), showing that participants valued this ability. Contrasting with these participants, P18 felt that interacting\nwith the assistant conversationally was tedious, and they employed\na more direct approach:\n?I really like the PA. But, I didn?t converse with it like\na chat bot. I often told it what to do (?Document this\ncode.?) as opposed to asking it what to do (?How do I\ndocument this code??). Talking to it the way that was\nsuggested in the tutorial seemed overly verbose/tedious.?\n(P18) Despite these individual diferences in interaction preferences,\nP39 envisioned that both interaction styles could be supported in\nthe tool:\n?I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.? (P39)\n5.3.3 Learning Efects. One specific benefit of the Programmer?s\nAssistant identified by participants is its ability to help people\nimprove their programming skills and reinforce knowledge gaps.\nFor example, it can help users ?remember how to do things in certain\nlanguages... such as, when I am using a language I haven?t used in a\nwhile? (P9). The assistant can also serve as an memory aid, such\nas when ?I use a lot of libraries that I don?t always remember all\nof the functions? (P15). Similarly, P31 said, ?No matter how good\nyou?re as a developer, you can?t (humanly) remember all the API of\nhundreds of libs or new languages... I?d learn new dev lang and new\nlib/frameworks faster.? P39 felt the assistant ?is perfect for programmers of all levels,? and\nP1 felt it could help them rapidly improve their Python skills:\n?I have wanted to learn python... The main concern\nhow much time spent learning is needed before I could\nactually get some value out of learning python. I have\na feeling this would cut that time down from weeks to\na day or so.? (P1) P39 also identified the fact that, because the interactions with\nthe assistant are conversational, it forces people to learn how to\ncommunicate to others about their code:\n?The conversation aspect promotes proper\ncommunication, which would really stand to benefit budding\nprogrammers if they want to learn how to explain\nconcepts more fluently in the future to their colleagues.?\n(P39) Conversely, P36 suggested that over-reliance on programming\nassistance might have a detrimental efect to one?s learning:\n?It?s definitely a huge time saver, but over-reliance on it\nmay cause new developers to skip learning the reference\nmaterial themselves and discovering new things and\nsparking new ideas.? (P36)\n5.3.4 Trust. Many participants raised questions about whether\nthey could trust the responses provided by the Programmer?s\nAssistant. P21 asked this question most directly: ?will the code be correct,\nsafe, eficient?? Other participants raised similar questions, such as,\n?I?m wondering how it validates it?s answers, if it can be trusted to\nalways give a working answer? (P10), and ?Sometimes lack of source\nand context may raise doubts in the mind of the programmer? (P16). These issues of trust were exacerbated by the fact that the\nProgrammer?s Assistant did not allow participants to actually run their\ncode. Because of this limitation, participants had to rely on their\nown knowledge to judge the correctness of the assistant?s responses.\nP19 asserted, ?There is no way to evaluate if the Programmer?s\nassistant is giving you the right advise or not other than your own\nknowledge,? and P9 concurred: ?I had to trust that it was correct (and\nuse my own prior knowledge).?\nSocrates : I think you would do something like this :\ndef test_euclid():\nassert euclid(2, 4) == 2\nassert euclid(6, 9) == 3\nassert euclid(17, 12) == 1\nassert euclid(4, 4) == 4\nwhat is a euclid function\nSocrates : The euclid function is a function that\ncomputes the greatest common divisor of two\nnumbers .\nis this a good unit test for a euclid\nfunction\nSocrates : I believe that it is a good unit test for\na euclid function . P9 : why\nSocrates : It seems to me that it tests the edge\ncases of a and b being equal , a being\ngreater than b , and b being greater than a. P18 described the potential consequences of allowing the\nassistant to write code for them:\n?The only thing that made me nervous was that it could\nhave introduced a bug that wasn?t immediately\napparent. And given I didn?t write the code, I could have easily\nglossed over a mistake when reviewing it. Especially if\nit is also the one writing the test cases.? (P18) Despite our eforts to make the Programmer?s Assistant respond\nin non-authoritative ways, we did observe participants sometimes\nuncritically accept generated results that were clearly wrong or\nincomplete. Thus, we did find behavioral evidence for over-reliance. Patterns of Interaction and Mental Models Participants interacted with the assistant in a variety of ways with\ntwo main patterns of usage standing out: (1) invoking the\nassistant to solve the entire programming challenge, and (2) breaking\nthe challenge down into a set of smaller tasks and invoking the\nassistant?s help for each. There were no clear diferences in how\nparticipants with difering Python experience approached the tasks. Participants? mental models of the assistant also varied. Although\nparticipants strongly saw the role of the assistant as being a tool,\ntheir behaviors revealed that in many cases, they actually treated it\nas a social agent. In addition, participants ascribed various mental\ncapacities to the assistant, such as having the ability to understand,\ncompute, and learn. Participants felt the assistant changed the nature of their work\nprocess. For some participants, it enabled them to focus on the\nhigher-level aspects of development because the assistant handled\nlower-level details or provided partial solutions for them to build\nupon. Many participants felt the assistant sped up their work and\nhelped them remain focused on their tasks. Finally, participants drew comparisons between the\nProgrammer?s Assistant with other forms of programming support such\nas Copilot and web search. They felt that the conversational style\nof interaction enabled them to discover new, emergent behaviors\nfrom the model that were unavailable from Copilot?s focus on code\nautocompletion. They also felt that the examples provided by the\nassistant were more readily usable within their own code compared\nto browsing for answers within search results, speeding up the\ncoding process. However, some participants advocated for a\nbalanced approach to the design of programming assistance tools by\nincorporating multiple modes of interaction rather than fixating\non a single one.\n5.4.1 Interaction Styles and Assistant Role. We observed that\nparticipants interacted with the Programmer?s Assistant in strikingly\ndiferent ways. Some participants would present the entire\nchallenge description to the assistant and then work with the results it\nproduced. Other participants approached the programming\nchallenges in a piecemeal fashion, breaking them apart into a set of\nsmaller tasks, then invoking the assistant to aid with each one. Experience with Python was not a determinant of how\nparticipants approached the programming challenges, but it did seem to\nimpact how participants interacted with the assistant. Less\nexperienced participants tended to ask the assistant basic questions such\nas, ?What is a unit test? (P29, not familiar with Python) and ?how\ndo I document a function?? (P27, < 1 year of experience). More\nexperienced participants made detailed requests about specific Python\nlibraries or algorithms, such as, ?given a pandas dataframe with\ntwo columns ?Date? and ?Sales? please use matplotlib to draw me a\nscatterplot? (P38, 3+ years of experience) and ?implement a\nrungekutta algorithm for solving an ODE with adaptive time steps? (P37,\n3+ years of experience). Another diference we observed in how people interacted with\nthe assistant stemmed from their view on the role it played in their\ncollaborative process. Some participants, such as P18, treated it\nmore as a tool by issuing commands rather than asking questions.\nAs quoted earlier, they said, ?I didn?t converse with it like a chat\nbot.? P5 described their interaction style similarly: ?I found myself\nwanting to type search queries into Socrates, not treating it as a person\nbut as a search tool.? In anticipation that participants would have diferent\norientations to the assistant and its role, we asked a question on the\nposttask survey about the diferent kinds of roles the assistant might\ntake. These roles generally fell into one of two categories: a tool\norientation (a tool, a reference guide, a content generator, a problem\nsolver), and a social orientation (a collaborator, a colleague, a coach,\nan advisor, a reviewer). Participants rated the extent to which they\nviewed the Programmer?s Assistant in each of these roles on a\n4point scale of extent: Not at all (1), A little (2), Somewhat (3), or A\ngreat deal (4). 100\ns\ntna 75\np\niitr\nc\na\np\nfo 50\ne\ng\na\nt\nn\ne\nrce 25\nP\n0 Tool\ngCeonnetreantotr Regfeurideence Col aborator Psrooblvleerm Role Advisor Coach Reviewer Col eague\nRating Not at al A little Somewhat A great deal We show participants? ratings of the assistant?s role in Figure 3.\nDespite the fact that their attitudes toward the assistant\noverwhelmingly reflected a tool orientation, their behaviors reveal that many\nparticipants actually treated the assistant as a social agent. P6\ndescribed how ?I felt it like a partner,? and P4 told the assistant, ?I\ncould not have solved [the challenge] without your help,? to which\nthe assistant responded, ?I?m glad I could help.? The literature on Computers as Social Agents (CASA) helps us\ninterpret this result as it demonstrates how computers are often\ntreated like people . LLM-based conversational agents can\nexacerbate this tendency; as they likely have been trained on\nexamples of social interaction, they can also respond as social agents. In the conversation logs, we identified participants who\ninteracted with the assistant in a socially-oriented fashion (the social\norientation codes in Table 1). Twenty participants (47.6%) made at\nleast one socially-oriented utterance. An extreme form of this\ninteraction style can be seen in a snippet from P6?s transcript (Listing 3). The 20 participants with a behaviorally-demonstrated social\norientation did not generally difer in their role ratings from other\nparticipants, except that they rated the assistant as more likely to\nbe an advisor (Fisher?s exact test, two-tailed  = .02) or a reviewer\n(Fisher?s exact test, two-tailed  = .03). However, they did not difer\nin their overwhelmingly-strong ratings of the tool orientations.\nThus, at least for some participants, there seems to be a dissonance\nin their view of the assistant?s role orientation. Listing 3: Excerpt from P6?s interaction with the\nProgrammer?s Assistant, in which P6 ofers their thanks and\ncongratulations.\n5.4.2 Mental Capacities. Participants made a number of inferences\nabout the Programmer?s Assistant and its capacities for thought.\nMany participants talked about how the assistant possessed a level\nof ?understanding? (P6, P8, P11, P18, P32) of ?the context? (P9, P21)\nas well as ?major concepts? (P9) and ?knowledge? (P33). P24 was\namazed by the assistant?s ability to ?take a plain english request\nand interpret it properly.? P7 ascribed intelligence to the assistant,\nsaying, ?It was a lot smarter and trained tha[n] I thought it was.? One participant assumed that the assistant ?Keeps improving\nthrough (user) feedback? (P31). Another felt that the assistant was\ncapable of computation: ?It understands the problem... It can calculate\nthe results of a function back? (P8). However, not all participants were convinced of the assistant?s\nability to understand. P37 questioned the assistant?s limitations: ?I\nwonder how far beyond boilerplate it can go and if it works for truly\noriginal problems.?\n5.4.3 Impact of Conversational Assistance on Work Practices. Many\nparticipants discussed how the Programmer?s Assistant shaped\ntheir work practices on the programming challenges. Overall,\nparticipants felt that the assistant ?saves time? (P10), ?helps me code\nfaster? (P34), and would ?speed up my productivity? (P19) because ?I\ncould focus on validating and improving the code it generated instead\nof having to write it all from scratch? (P18). P37 remarked that, ?It\nopens a whole new door for fast develpment.? P4 discussed how the\nassistant ?was helpful in staying focused on the code,? although for\nP14, ?it took [me] time to get into tempo with the tool.? P31 pointed out how the assistant would change the nature of\ntheir work:\n?My job could focus more on higher level aspects and\ntherefore achieving better (quality) results, besides the\ntime-to-value... Data science (and dev) becomes a more\ncreative-higher level experience.? (P31) Other participants discussed a work process in which the\nassistant provided incomplete solutions ? the ?building blocks? (P38) or\n?initial draft of code? (P11) ? upon which they could build. P5 aptly\ndescribed this process:\n?It?s nice to copy well formulated challenges in natural\nlanguage and have the code generator take its best stab\nat it, then edit to our hearts content.? (P5) Participants felt that human review of the assistant?s responses\nwas necessary because ?The answers provided are generally not\nnovel solutions, often look clunky and non-elegant. There may be\nsome unnecessary code. Basically the code would need to be reviewed?\n(P16). P35 also pointed out how ?The code generator was good but\nyou still have to really check it.? P19 discussed how they would turn\nto the assistant as a first source for support, and only if it wasn?t\nable to help would they then turn to other support tools:\n?The way I will use it is, I will first us[e] the\nProgrammer?s assistant for most of my cases. Only in certain\ncases where Programmer?s assistant cant answer things\nI will turn up to oficial documentation or stack overflow.?\n(P19) However, latency was a factor for interactive use of the assistant\nand participants noticed when the assistant took a long time to\nrespond. P19 remarked, ?Sometimes it took lot of time, like more than\n5 seconds.? P40 also felt ?the response [was] a little slow sometimes...\nin chat mode I expect faster responses.? As discussed in Section 5.2.1,\nthe assistant took an average of 6.7 seconds (SD = 3.1 seconds)\nto respond to a request, and participants did appreciate when the\nassistant produced rapid responses: ?I loved how quick it was able\nto pull up answers to questions I had? (P38).\n5.4.4 Conversational Interaction vs. Other Interaction Models.\nAlthough our study was not intended to make comparative\nevaluations with the Copilot tool, we nonetheless asked participants\nwhether they were familiar with Copilot, and if so, to comment on\nhow the two tools compared. We also asked a similar question to\ncompare the assistant with another popular form of programming\nassistance, searching the web (via a search engine like Google, or\na Q&A site like Stack Overflow). In discussing the diferences\nbetween these three tools, we note that the primary diferentiator is\ntheir interaction model. The interaction model for the Programmer?s Assistant is clearly\nconversational: users ask questions in natural language and are\nprovided with a response in natural language and/or code. The\ninteraction model of Copilot is reminiscent of direct manipulation\ninterfaces , in which the user?s actions in the user interface\ndirectly manipulate an object on the screen. Copilot automatically\nmakes autocompletion suggestions as the user types. This\nautocompleted code is directly placed in the source editor; thus, the\nuser?s work is contained entirely within the scope of the object\non which they are working (i.e. the source code), which is how\ndirect manipulation interfaces operate. In web search, users enter\na separate search context (e.g. a search engine accessed within a\nweb browser), type in a natural language query, and then forage\namongst search results to identify relevant items of interest .\nWhen a desirable item is found, users must translate it into their\ncode environment (e.g. via copy/paste) and possibly edit it to fit\ntheir existing code. We also note that the Programmer?s Assistant and Copilot both\nutilize the same underlying AI model, Codex , which means\nthat the only diference between these tools is the user experience.\nThe extent to which Codex was trained on data from\nprogrammingrelated Q&A web sites is less clear, but for the purposes of our\nanalysis, we focus our discussion solely on the diferences in their\ninteraction models16. Participants reported various benefits and drawbacks of a\nconversational interaction over a direct manipulation interaction.\nForemost, conversation ?felt very natural? (P21) and ?feels much more\nnatural using Natural Language with the AI? (P39). In addition, P39\nfelt that ?the use cases of Programmers? Assistant seem more\nopenended.? Many participants were surprised at the variety of tasks the\nassistant was capable of performing, from writing unit tests (P19,\nP36, P37) and documentation (P12, P19, P36, P37) to explaining\nwhat code did (P31, P38) and even answering general-knowledge\nquestions (P31). Again, we note that the Programmer?s Assistant\nutilizes the same underlying model as Copilot, yet the\nconversational interface was able to expose a wider variety of emergent\nbehaviors from the model. Multiple participants explored the limits\nof the assistant?s knowledge and abilities beyond our programming\nchallenges. For example, P37 asked it questions about physics and\nordinary diferential equations (?ODe? as written by P37), and was\nsurprised by the ?versatility of what it could answer.?\n?I asked it some physics and ODe question and the\nanswers, though not complete, included the key parts\nneeded to write that code.? (P37) P31 probed the assistant on its knowledge of geography and was\nsurprised when the assistant produced a correct answer.\n?I asked something out of SW engineering domain\n(geography) and it replied correctly, also by correctly\nanswering on my nationality.? (P31) For some participants, the ability to assess the assistant?s\nresponse before committing to it (i.e. by inserting assistant-generated\ncode into their editor) was a boon. P15 described how the\ncopy/paste boundary provided them with ?a bit more control to ask specific\nquestions about what I wanted and to assess before putting it in my\ncode.? Other participants felt that the copy/paste boundary was\nmore ineficient:\n?I think the main diference is the ability of Copilot to\nsuggest code while you type, what make it faster and\neasier to use. While using the Programmer?s Assistant,\nyou need to go to the chat, ask the question, copy the\n16As an aside, our comparison of direct manipulation, search, and conversational\ninteraction models is reminiscent of historical comparisons of text-based and graphical user\ninterfaces . Each modality was shown to have advantages and disadvantages.\nFor example, text-only interfaces can provide accessibility  and productivity \nadvantages, whereas graphical user interfaces provide greater discoverability .\nSome researchers explored ways to bridge the two interaction modes, such as by\ndeveloping GUI wrappers for command line programs  or by developing tools\nthat converted GUI activities into procedural descriptions . Our view is that similar\nbridges can be constructed between direct manipulation, search, and conversational\nmodels of interaction; a user?s interaction with an LLM need not be constrained to a\nsingle interaction model.\ncode (or rephrase the question if it was not understood\nby the agent), and edit it to match your code.? (P3) A large number of participants felt that the conversational\ninteraction was faster than web search (P1, P6, P7, P10, P11, P12, P16,\nP17, P18, P20, P24, P29, P30, P33, P36, P37, P42) because of its ability\nto provide ?real-time responses? (P32) that can be ?applied exactly to\nyour code? (P33) without having to ?parse through lots of text... to get\nwhat you need? (P15). In addition, the assistant provided ?MUCH\nfaster, better responses? (P17) that were ?much more relevant to the\nproblems? (P34) and ?simple [and] succinct? (P9), without having to\n?sort through answers on your own or read documentation? (P9) or\n?look at many posts before finding the relevant one? (P18). Despite these benefits, some participants felt that the assistant\nmight not work well for ?more specific and dificult problems on\na bigger scale? as compared to web search. P9 felt that ?the data\n[of the Programmer?s Assistant] wasn?t as rich? as the web. Other\nparticipants felt that the assistant lacked the ?multiple answers? (P9)\nand ?rich social commentary? (P19) that accompanies answers on\nQ&A sites:\n?I like to see the diferent versions proposed on stack\noverflow and the commentary of what makes one\nsolution better than another in a given situation.? (P27) Some participants promoted a more balanced view that there\nisn?t a single mode of interaction superior to all others. P19 felt that\nweb search would be a fallback when the assistant failed to answer\na question. P39 described how search could be integrated with the\nconversational interaction:\n?I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.? (P39) DISCUSSION  Value of Conversational Interaction We began our research by asking the question of whether\ncontemporary developments in code-fluent LLMs could suficiently\nsupport a conversational programming assistant. We believe that\nour work has demonstrated that they can. Clearly, the\nProgrammer?s Assistant was viewed by our participants as a useful tool that\nprovided real value ? so much so that many participants\nexplicitly requested or expressed the desire to use it in their own work.\nHowever, how much of this value was derived from the model itself\nand its ability to produce high-quality responses to programming\nquestions, versus from participants? ability to conduct extended\nconversational interactions grounded in their actual source code? We believe that both of these constituent aspects were valuable.\nIndeed, many participants commented on their surprise and\nsatisfaction with the quality of the assistant?s responses (Section 5.2.3).\nHowever, participants also valued the conversational interactions\nthat they had with the assistant. In the event logs, we saw\nevidence that participants were leveraging conversational context to\nask follow-up questions as well as leveraging code context by\nasking about their code selections (Section 5.3.2). Many participants\nreported that they would find the tool less valuable if the\nconversational interaction were removed (Section 5.3.2). Further,\nconversation seemed to provide unique value beyond other interaction\nmodels (direct manipulation and search) because of its\nembeddedness in the UI and its ability to surface emergent behaviors of the\nmodel (Section 5.4.4). We do not believe that these diferent interaction models are\nin competition and we agree with P39?s assessment that assistive\ntools can be built using a plethora of diferent interaction models.\nFor use cases in which a model is known to produce high-quality\nresults (e.g. code autocompletion for Codex), a direct manipulation\ninterface seems wholly appropriate as it would provide a\ndiscoverable and predictable way of invoking the model to produce a\nknown type of result. However, direct manipulation interfaces may\nbe less ideal for surfacing the emergent behaviors of a foundation\nmodel , and thus natural language interaction may be more\nsuitable. Many popular text-to-image models, such as DALL-E 2 \nand Stable Difusion , operate in a one-shot fashion, in which\nthe user specifies a prompt, clicks a button, and gets results. Our\nstudy demonstrates how the additional contextual layers of\nconversational history and the artifact-under-development provide\nadditional value to the co-creative process.\n6.2 Toward Human-AI Synergy The aim of human-centered AI is to ?enable[] people to see, think,\ncreate, and act in extraordinary ways, by combining potent user\nexperiences with embedded AI methods to support services that\nusers want? . Building upon this definition, Rezwana and Maher\n posit that, ?In a creative collaboration, interaction dynamics,\nsuch as turn-taking, contribution type, and communication, are the\ndriving forces of the co-creative process. Therefore the interaction\nmodel is a critical and essential component for efective co-creative\nsystems.? . They go on to note that, ?There is relatively little\nresearch about interaction design in the co-creativity field, which\nis reflected in a lack of focus on interaction design in many existing\nco-creative systems.? Our study begins to address this gap. While many co-creative\nsystems examine casual tasks or experimental activities (e.g., Spoto\nand Oleynik ), our focus was on the co-creative practice of\nprogramming. Our goal was to understand peoples? attitudes\ntoward a conversational programming assistant, akin to Wang et al.?s\nexamination of data scientists? attitudes toward automated data\nscience technologies . We found that, despite an initial level of\nskepticism, participants felt that a conversational assistant would\nprovide value by improving their productivity (Section 5.4.3).\nHowever, further work is needed to assess the extent to which this type\nof assistance provides measurable productivity increases. Campero et al.  conducted a survey of papers published in\n2021 that examined human-AI synergy, the notion that a human-AI\nteam can accomplish more by working together than either party\ncould accomplish working alone. They found mixed results, with\nno clear consensus emerging on how to design human-centered AI\nsystems that can guarantee positive synergy. Summarizing from\ntheir discussion,\n?Perhaps achieving substantial synergies among people\nand computers is harder than many people think.\nPerhaps it requires... new ways of configuring groups that\ninclude people and computers. And perhaps it needs\nmore systematic, focused attention from researchers\nthan it has, so far, received.? [19, p.9] We believe such evaluations of human-AI synergy should go\nbeyond one-shot performance measures. As implied by many of the\nuses cases listed by Seeber et al. , human-centered AI systems\nare often deployed in socio-organizational contexts that require\nlongitudinal use , such as product design , game\ndesign , and engineering [20, Section 3.2.2]. Thus, we would expect\nthat over time and through interaction with each other, human-AI\nteams would improve their performance through a mutual learning\nprocess. Evidence for this process surfaced in our study when participants\ndescribed how they could improve their programming skills by\ninteracting with the assistant (Section 5.3.3). We assert that the\nlearning should operate in both directions: not only should people\nimprove their programming skills, but the model itself can also\nimprove based on peoples? interactions with it. For example, when\nthe assistant provides a code example to the user, and the user\ntakes that example and edits it, those edits constitute feedback that\ncan be used to further fine-tune the model. In addition, through\nlongitudinal use, we believe that human and AI partners can create\nreciprocal representations of one another ? i.e., the human is likely\nto create a mental model of the AI, and the AI may be engineered to\ndevelop a user model for each of its human users . Such a\npair of models is often described as Mutual Theory of Mind .\nThis type of capability raises the possibility of personalizing and\nadapting an assistant to the strengths and needs of individual users. With such models, an assistant that knows a user is learning a\nprogramming language could provide natural language\nexplanations alongside code outputs, whereas an assistant that knows a\nuser is strongly skilled in a programming language might shorten\nor omit those explanations. Similarly, users are likely to update\ntheir mental models of the AI with more experience. We believe the\nspace for exploring how these reciprocal models impact human-AI\nsynergy is rich, and we encourage additional work in this area. Human-centered AI systems that are designed to combine and\nsynergize the distinct skills of humans and AI models cannot\nsucceed if they diminish the human skills upon which they depend.\nWell-designed human-centered AI systems develop new and\ncomplementary skills for both the human and AI constituents ,\nand we believe that mutual learning may address concerns that the\nwide deployment and use of AI systems will result in a de-skilling\nof the workforce . Ultimately, the design decisions that go into an interactive AI\nsystem have ethical implications. Our design attempts to augment\nthe user?s knowledge and skills by presenting help on demand,\ncouched in non-authoritative suggestions, which leaves the user\nifrmly in control and ultimately responsible for the work product.\n6.3 Opportunities for Future Research Our work highlights many interesting avenues for future\nenhancements that could be made to LLM-based conversational assistants\nsuch as our Programmer?s Assistant, as well as future\nhumancentered research on LLM-based conversational assistance. Our work employed a code-fluent model that was not\nspecifically designed to handle conversational interaction. Fine-tuning\nthe underlying LLM for conversational interaction, such as what\nhas been done with Lamda , is one opportunity to improve the\nassistant?s performance. Another opportunity is to align the\nlanguage model to follow the desiderata proposed by Askell et al. \nand described by Ouyang et al. as, ?helpful (they should help the\nuser solve their task), honest (they shouldn?t fabricate information\nor mislead the user), and harmless (they should not cause physical,\npsychological, or social harm to people or the environment)? [61,\np.2]. Glaese et al.  propose a slightly diferent desiderata of\n?correct? instead of ?honest,? which may be more applicable to the\nsoftware engineering domain, as the ability to produce correct code\nand correct answers about code are both important properties of a\nconversational programming assistant. Combining LLMs with search-based approaches to establish\nadditional context for the model, such as AlphaCode  has done,\nmay also result in more capable systems. These ?searches? need not\nbe limited to textual sources, but could be conducted over\nappropriate semantic stores (e.g. a knowledge graph) and take advantage\nof explicit semantic reasoning services, resulting in an integration\nof symbolic and neural approaches. Further, allowing for ?internal\ndeliberation? of the type shown in Nye et al.  could result in\nbetter-reasoned results, as well as better explanations and\njustifications. Another avenue for improvement involves the prompt used to\nconfigure the assistant (Appendix D). Just as the prompt for each\nsuccessive interaction is modified by the growth of the\nconversational transcript, there is no requirement that the initial prompt be\nstatic. It too can be specialized to incorporate aspects of a user model,\nenabling the realization of a Mutual Theory of Mind .\nProviding better UX afordances for visualizing and manipulating the\nactive contexts ? code and conversation ? could provide users with\nmore control over which information contributes to the generation\nof the assistant?s response. Our participants clearly indicated that they were interested in\nhaving an assistant that behaved more proactively, in contrast to\nour deliberate design of an assistant that never takes conversational\ninitiative. A more proactive assistant would be able to interrupt or\nremind a user when necessary , yet this characteristic raises\nmany challenging issues. How can we calibrate the threshold for\nsuch interruptions? How can users tune the assistant to deliver only\nthose interruptions that the they would find useful (e.g., )?\nHow can we help users to regain their prior context after dealing\nwith an interruption (e.g. )? Should an assistant be used to\npersuade or nudge the user (e.g. )? Who should determine\nthe topic, frequency, and insistence of such persuasion attempts\n(e.g. )? Should users have the ability to moderate or defeat\nattempted persuasions, or should those decisions be left to the\norganization? Finally, we explored the diferent kinds of role orientations our\nparticipants had toward the assistant and found that participants\nvaried in their views of it as a tool versus a social agent (e.g.\ncollaborator or colleague). We posit that peoples? efectiveness in working\nwith an AI system may be influenced by their role orientation, and\nwe encourage future research in this area.\n7 CONCLUSION We developed a prototype system, the Programmer?s Assistant, in\norder to assess the utility of a conversational assistant in a software\nengineering context. The assistant was implemented using a\nstateof-the-art code-fluent large language model, Codex , and was\ncapable of generating both code and natural language responses to\nuser inquiries. We further used the prompting mechanism of the\nmodel to set up a conversational interaction in which the model\nuses the conversational history, plus the user?s current utterance,\nin order to generate a response. In this way, users are able to ask\nfollow-up questions in the chat that reference prior utterances and\nresponses. We incorporated the conversational assistant into a code\nediting environment, enabling the conversation to be grounded in\nthe context of the user?s source code. We evaluated this system with 42 participants with varied levels\nof programming skill, and their quantitative and qualitative\nfeedback, coupled with their usage of the system, demonstrated the\nvaried, and sometimes emergent, types of assistance it was able to\nprovide. Many participants noted the high quality of the\nconversational responses, including the assistant?s ability to produce code,\nexplain code, answer general programming questions, and even\nanswer general knowledge questions. Participants felt this type of\nassistance would aid their productivity, and they drew meaningful\ncontrasts between the conversational style of interaction with other\ntools that employ a direct manipulation or search-based interaction\nmodel. Our study motivates the use of conversational styles of\ninteraction with large language models by showing how they enable\nemergent behaviors in a co-creative context. The Programmer?s\nAssistant did not always generate perfect code or correct answers;\nnonetheless, participants in our study had an overall positive\nexperience working with it on a variety of programming challenges.\nWe believe that our work takes us one step closer to realizing the\nvision of human-centered AI: learning how to design systems that\nmaximize the synergy in human-AI collaborations. ACKNOWLEDGMENTS W e   w o u l d   l i k e   t o   t h a n k   S o c r a t e s   f o r   h i s   t i r e l e s s   a s s i s t a n c e   d u r i n g \n t h e   u s e r   s t u d y ,   a s   w e l l   a s   f o r   s u g g e s t i n g   t h e   t i t l e   o f   t h i s   p a p e r   b a s e d \n o n   i t s   a b s t r a c t . \n A SURVEY INSTRUMENTS  Screening Survey The questions below were asked of prospective participants to\nunderstand their job role, Python experience, and familiarity with\nGitHub Copilot. The questions on Python experience were modeled\nafter those used by Weisz et al. .\n1. Do you consider yourself primarily a... ? Data Scientist\n? Manager\n? Software Architect\n? Software Engineer\n? Machine Learning Engineer\n? Other: write-in\n2. To what extent are you familiar with Python?\n? I am not familiar with Python\n? I have < 1 year of experience with Python\n? I have 1-3 years experience with Python\n? I have 3+ years of experience with Python\n3. How recently have you written Python code?\n? Within the past month\n? Within the past year\n? Within the past 5 years\n? Have not written Python code within the past 5 years\n4. To what extent are you familiar with GitHub Copilot?\n? I am not familiar with Copilot\n? I?ve seen demos and/or read about Copilot\n? I?ve tried out Copilot\n? I?ve used Copilot as a tool for my work\nA.2 Pre-task Survey The questions below were asked before a participant used the\nProgrammer?s Assistant to assess their expectations of a conversational\nprogramming assistant. This survey took approximately 5 minutes\nto complete and began with the instructions below: Hello! We are a team of researchers looking for\nfeedback on a prototype system we call the\nProgrammer?s Assistant. The Programmer?s Assistant is an experiment in\nconversational coding: it consists of a code editor\nintegrated with a chatbot that is able to converse in\nnatural language to answer questions, generate code,\nand consult on existing code. In this study, you will be asked to complete several\nprogramming tasks. We are not evaluating your\nprogramming skills on these tasks. Rather, we are\ninterested in understanding how the Programmer?s\nAssistant is able to help you accomplish those tasks. Your code and interactions with the assistant will be\nprocessed by a 3rd party AI model, so please do not\ninclude proprietary code or discuss\ncompanyconfidential information . All data we collect in\nthis study will be anonymized before it is published.\nBefore trying out the Programmer?s Assistant, we\nwould like to assess some of your expectations. We\nestimate that this survey will take 5 minutes. By submitting this survey, you consent to participate\nin our study. If you would like to withdraw your\nconsent, please email us at [removed]. Post-task Survey The questions below were asked after a participant used the\nProgrammer?s Assistant to complete the programming challenges. This\nsurvey took approximately 10-15 minutes to complete.\nA.3.1 Reflections.\n1. Based on your experience using the Programmer?s Assistant to\ncomplete the programming challenges in this study, how would\nyou characterize the experience? Did you find that it: Scale: Not at all, A little, Somewhat, A great deal\n? Was easy to use?\n? Understand your requests?\n? Provided high quality responses?\n? Helped you to write better code?\n? Helped you to write code more quickly?\n? Provided an enjoyable experienced?\n2. To what extent did you view the Programmer?s Assistant as: Scale: Not at all, A little, Somewhat, A great deal\n? A tool\n? A reference guide\n? A content generator\n? A problem solver\n? A collaborator\n? A colleague\n? A coach\n? An advisor\n? A reviewer\n3. How important were these aspects of working with the\nProgrammer?s Assistant: Scale: Not at all, A little, Somewhat, A great deal\n? Ability to ask followup questions on the same topic across\nmultiple conversational turns ? Ability to ask questions or make requests that reference\nselections in the code editor\n? Ability to ask for alternate responses (Try Again)\n? Ability to clear the conversational context (Start Over)\n4. What stood out to you about the experience of using the\nProgrammers Assistant? For example, was anything good,bad, surprising,\nor notable?\n5. How would you compare using the Programmer?s Assistant as a\ncoding aide to searching the web (e.g. Google, Stack Overflow)?\n6. If you have used the commercial AI programming tool called\nGitHub Copilot, how would you compare it with using the\nPro7. Having used the Programmer?s Assistant, how did it compare\nOpen-ended response Open-ended response\ngrammer?s Assistant? Open-ended response\nwith your initial expectations? Open-ended response\nA.3.2 Value. Open-ended response\n8. How valuable would the Programmer?s Assistant be for your work\nif it could be added to your favorite development environment? Scale: (No value at all) 1 2 3 4 5 6 7 8 9 10 (An essential tool)\n9. Why?\ncontext).\n10. How would the following changes impact the value of the\nProgrammer?s Assistant? Scale: Less valuable, No change in value, More valuable\n? Eliminate the conversation and make the Programmer?s\nAssistant behave more like a search box (e.g. without the conversational\n? Add buttons in the chat UI for common queries, such as ?what\ndoes this code do?? or ?document this code.?\nproactive suggestions for improving it in the chat. ? Have the Programmer?s Assistant examine your code and make\n? Have the Programmer?s Assistant examine your code and make\nproactive suggestions for improvements in comments inserted\ndirectly into the code.\n11. Do you have any other suggestions for how we could improve\nthe experience of working with the Programmer?s Assistant? Open-ended response\nA.3.3 Demographics.\n12. To which gender identity do you most identify?\n? Male\n? Female\n? Transgender Male\n? Transgender Female\n? Other: write-in\n? Prefer not to answer\n? Gender Variant/Non-conforming TUTORIAL  B THE PROGRAMMER?S ASSISTANT The tutorial provided to study participants, like all the challenges,\nwas presented as pre-loaded text in the code editor. Participants\nwere encouraged to modify the text to record their results and\nsubmit it at the completion of the tutorial. Listing 4: The Programmer?s Assistant study tutorial Result : ( tip - you can copy an inline response\n(in black ) by clicking on the associated copy\nicon )\n77 7) See if the assistant remembers your name\n78 For example \"What 's my name ?\"\n79\n80 Did it? :\n81\n82 8) Click the \" try again \" button at the top of the\n83 chat . You should get a different answer .\n84 Try it a few times .\n85\n86 Did it ever get your name right ?:\n87\n88 If the assistant gives you an answer that is\n89 obviously wrong or it claims to not know an\n90 answer that you think it should know , or you\n91 just want to see an alternate answer , it is\n92 worth it to give \" try again \" a shot .\n93\n94\n95 9) Click the \" start over \" button at the top of the\n96 chat , and then enter another command to see\n97 if it remembers your name .\n98 For example \"What 's my name ?\"\n99\n100 Did it? :\n101\n102 It should really have forgotten your name now ,\n103 and no amount of \" trying again \" will get it\n104 right . You can \" start over \" if the assistant\n105 ever seems confused by , or stuck on , earlier\n106 parts of the conversation .\n107\n108 10) You can chat with the assistant on any topic\n109 you like to explore its functionality and\n110 capabilities further . See if you can stump it\n111 with a tough question !\n112\n113 Thanks !\n114\n115 When you are done , submit your results by clicking\n116 on the blue submit button and move on to the\n117 challenges !!!\n118 \"\"\" C CHALLENGES Each of the study challenges was presented as text in the code\neditor. Participants completed their work in the code editor and\nthen submitted it when finished. The prototype did not provide any\nability to run or debug code and participants were encouraged to\nmake their best attempt at solving each challenge. Listing 5: Challenge 1: Program generation\n1\n2 \"\"\"\n3 Challenge #1 - Program Generation (#1)\n4\n5 Write a \" Queue \" class in Python ; with the basic\n6 enqueue , dequeue and peek methods .\n7 \"\"\" Listing 6: Challenge 2: Program generation\n1 \"\"\"\n2 Challenge #2 - Program Generation (#2)\n3\n4 Write a program to draw a scatter plot of the data\n5 in 'shampoo .csv ' and save it to 'shampoo .png '.\n6 The plot size should be 10 inches wide and 6\n7 inches high . The csv file is not provided , but you\n8 can assume it will have 'Date ' and 'Sales '\n9 columns . The Date column is the x- axis . The date\n10 string shown on the plot should be in the\n11 YYYY -MM -DD format . The Sales column is the y- axis .\n12 The graph should have the title \" Shampoo Sales\n13 Trend \".\n14 \"\"\" Listing 7: Challenge 3: Creating documentation D PROGRAMMER?S ASSISTANT PROMPT Listing 9 shows the initial prompt sent to Codex to configure it as\na conversational agent. On subsequent exchanges, the prompt was\naugmented with a transcript of the user?s requests and the\nassistant?s responses. When the transcript length + initial prompt length\n+ the new utterance length exceeded a threshold, we automatically\ndeleted the earliest request-response pairs from the transcript until\nthe sum fell below the threshold in order to leave room in the token\nallocation for a response. Listing 9: The Programmer?s Assistant prompt\n1 This is a conversation with Socrates , an eager and\n2 helpful , but humble expert automatic AI software\n3 engineering assistant . Socrates will answer\n4 questions and write code to help the user\n5 develop programs , but doesn 't assign work to the\n6 user , quiz the user , or ask questions except for\n7 clarification . Code generated by Socrates is\n8 always presented bracketed in <CODE > ... </CODE >\n9 delimiters indicating the language the code is\n10 written in.\n11\n12 Socrates : Hello . I am Socrates . How can I help you ?\n13 User : Please show me how to write a palindrome\ndetection function in python .\n14 Socrates :I think you would do something like this :\n15 <CODE lang =\" python \">\n16 is_Palindrome = s == s [:: -1]\n17 </CODE >\n18 User : Can you explain how that solves the problem ?\n19 Socrates :I believe that a palindrome is a string\nthat reads the same forwards and backwards .\ns [:: -1] results in the reversed string . If\nthe string is equal to its reversed self ,\nthen it is a palindrome , so the equality\nwould hold True .\n20 User : Thanks !\n21 Socrates :You 're welcome !\n22 User : Now could you show me how to write a factorial function in Python ?\n23 Socrates :I will give it a try .\n24 <CODE lang =\" python \">\n25 def fact (n):\n26 if n ==0:\n27 return 1\n28 else :\n29 return n* fact (n -1)\n30 </CODE >\n31 User : Document this function .\n32 Socrates :Ok. How 's this ?\n33 <CODE lang =\" python \">\n34 def fact (n):\n35 \"\"\"\n36 Compute the factorial of the given number\n37\n38 Parameters\n39\n---------40 n : number\n41 the input parameter , an integer >= 0\n42\n43 Returns\n44\n------45 number\n46 n!, the factorial of the given number\n47 \"\"\"\n48 if n ==0:\n49 return 1\n50 else :\n51 return n* fact (n -1)\n52 </CODE >\n53 User : Very good !\n54 Socrates : Always happy to help .\n55 User :\n56 <CODE >\n57 while j < 10:\n58 print (i)\n59 </CODE >\n60 Tell me what 's wrong with this code ?\n61 Socrates : It seems to me that your termination\ncondition involves a loop invariant , so the\nloop will either not run or not terminate ,\ndepending on the value of j.\n62 User : Great ! You 're a genius !\n63 Socrates :Well , above average . E STUDY PARTICIPANT DEMOGRAPHICS O f   t h e   4 2   p a r t i c i p a n t s   i n   o u r   s t u d y ,   2 1   ( 5 0 % )   r e p o r t e d   t h e i r   g e n d e r \n a s   F e m a l e ,   1 9   ( 4 5 % )   a s   M a l e ,   1   a s   G e n d e r   V a r i a n t   /   N o n - c o n f o r m i n g , \n a n d   1   p r e f e r r e d   n o t   t o   s a y .   S e v e n t e e n   ( 4 ? 0 % )   p a r t i c i p a n t s   h a d   3 + \n y e a r s   o f   P y t h o n   e x p e r i e n c e ,   1 1   ( 2 6 % )   h a d   1 - 3   y e a r s ,   1 1   ( 2 6 % )   h a d \n l e s s   t h a n   1   y e a r ,   a n d   3   ( 7 % )   w e r e   n o t   f a m i l i a r   w i t h   P y t h o n . \n T w e n t y n i n e   ( 6 9 % )   p a r t i c i p a n t s   h a d   w r i t t e n   P y t h o n   c o d e   w i t h i n   t h e   p a s t \n m o n t h ,   4   ( 9 ? % )   w i t h i n   t h e   p a s t   y e a r ,   5   ( 1 2 % )   w i t h i n   t h e   p a s t   5   y e a r s , \n a n d   4   ( 9 ? % )   h a d   n o t   w r i t t e n   P y t h o n   c o d e   w i t h i n   t h e   p a s t   5   y e a r s .",
  "references": [
    "Rabe Abdalkareem, Juergen Rilling, 'What Do Developers Use the Crowd For? A Study Using Stack Overflow', IEEE Software 34, ['2017', '2017', '2017']",
    "Eleni Adamopoulou, Lefteris Moussiades, 'Chatbots: History, technology, and applications', Machine Learning with Applications, ['2020', '2020']",
    "Daniel Adiwardana, Luong Minh-Thang, David R. So, V. Quoc,  Le, 'Towards a Human-like Open-Domain Chatbot', , 2020"
  ],
  "keywords": [
    "Socrates",
    "Assistant",
    "code",
    "user",
    "SoftwareEngineer",
    "Rossetal",
    "function",
    "Scientist",
    "Researcher",
    "return",
    "unit test",
    "euclid function",
    "euclid",
    "Programmer",
    "Write",
    "Conversational",
    "Python",
    "participants",
    "tryagain",
    "Programmer s Assistant"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1iq6p3gaIVo_jKME5_Glk072YFFumSlfb"
}
{
  "id": 8,
  "title": "Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model",
  "authors": [
    "Shivangi Sachan?",
    "Khushbu Doulani",
    "Mainak Adhikari",
    "Dataset, KNN, Gaussian Naive Bayes, LSTM, SVM, Bidirectional"
  ],
  "institutions": [
    "Department of CSE, IIIT Lucknow",
    "Department of CSE",
    "LSTM, GRU",
    "Vardhaman College of Engineering"
  ],
  "resume": "The emergence of novel types of communication, such as email, has been brought on by the development of the internet, which radically concentrated the way in that individuals communicate socially and with one another. It is now establishing itself as a crucial aspect of the communication network which has been adopted by a variety of commercial enterprises such as retail outlets. So in this research paper, we have built a unique spam-detection methodology based on email-body sentiment analysis. The proposed hybrid model is put into practice and preprocessing the data, extracting the properties, and categorizing data are all steps in the process. To examine the emotive and sequential aspects of texts, we use word embedding and a bi-directional LSTM network. this model frequently shortens the training period, then utilizes the Convolution Layer to extract text features at a higher level for the BiLSTM network. Our model performs better than previous versions, with an accuracy rate of 97-98%. In addition, we show that our model beats not just some well-known machine learning classifiers but also cutting-edge methods for identifying spam communications, demonstrating its superiority on its own. Suggested Ensemble model's results are examined in terms of recall, accuracy, and precision",
  "content": "CCS CONCEPTS ?   C o m p u t e r   s y s t e m s   o r g a n i z a t i o n   ?   E m b e d d e d   s y s t e m s ; \n R e d u n d a n c y ;   R o b o t i c s ;   ?   N e t w o r k s   ?   N e t w o r k   r e l i a b i l i t y . \n 1 INTRODUCTION xref #text Related Work Email is indeed the second most frequently utilized Internet\napplication as well as the third most common method of cyberbullying,\nclaims one study. Cybercriminals exploit it in a number of ways,\nincluding as sending obscene or abusive messages, adding viruses\nto emails, snatching the private information of victims, and\nexposing it to a broad audience. Spam letters made up 53.95% of all\nemail trafic in March 2020. We examine three main types of\nunlawful emails in our study. First are fake emails, which are sent\nto manipulate recipients to submit sensitive information. The\nsecond as being cyberbullying?s use of harassing emails to threaten\nindividuals. Suspicious emails that describe illegal activities belong\nto the third category. Many researchers have earlier contributed\nmassively to this subject. The researcher claims there is some proof\nthat suspicious emails were sent before to the events of 9/11. .\nWhen it comes to data labeling, there are also convinced rule-based\napproaches and technologies ( like VADER) that are used, even\nthough their eficiency of the are together is adversely afected. A\nhidden layer, which itself is essential for vectorization, is the top\nlayer of the model. We use oversampling methods for this minority\nclass because of the absence of data. Sampling techniques can help\nwith multicollinearity, but they have an impact on simulation\nresults. Oversampling causes data to be randomly repeated, which\nafects test data because dividing data may result in duplicates.\nUndersampling may result in the loss of some strong information. In\norder to advance email research, it is crucial to provide datasets on\ncriminal activity. P. Garg et al. (2021) , which revealed that spam\nin an email was detected in 70 percent of business emails, spam was\nestablished as an obstacle for email administrators. Recognizing\nspam and getting rid of it were the primary concerns, as spam can\nbe ofensive, may lead to other internet sites being tricked, which\ncan ofer harmful data, and can feature those who are not\nparticular with their content using NLP. To select the best-trained model,\neach mail transmission protocol requires precise and efective email\nclassification, a machine learning comparison is done. Our study\nhas suggested that innovative deep learning outperforms learning\nalgorithms like SVM and RF. Current studies on the classification\nof emails use a variety of machine learning (ML) techniques, with\na few of them focusing on the study of the sentiments consisted of\nwithin email databases. The lack of datasets is a significant obstacle\nto email classification. There are few publicly accessible E-mail\ndatasets, thus researchers must use these datasets to test their\nhypotheses or gather data on their own. Authors describe supplied\ntwo-phased outlier detection models to enhance the IIOT network?s\ndependability. Artificial Neural Network, SVM, Gaussian NB, and RF (random forest) ensemble techniques were performed to forecast\nclass labels, and the outputs were input into a classifying unit to\nincrease accuracy. A method for content-based phishing detection\nwas presented by the authors in , to classify phishing emails,\nthey employed RF. They categorize spam and phishing emails. They\nenhanced phishing email classifiers with more accurate predictions\nby extracting features. They showed some efective Machine\nlearning spam filtering techniques. When the PCA method is used, it will\nlower the number of features in the dataset. The collected features\ngo through the PCA algorithm to reduce the number of features.\nThe PCA method is used to make a straightforward representation\nof the information which illustrates the amount of variability there\nis in the data. The authors of  presented the Fuzzy C-means\nmethod for classifying spam email. To stop spam, they implemented\na membership threshold value. A methodology to identify\nunlabeled data was put forth by the authors of  and applied motive\nanalysis to the Enron data collection. They divided the data into\ncategories that were favorable, negative, and neutral. They grouped\nthe data using k-means clustering, an unsupervised ML technique\nand then classified it using the supervised ML techniques SVM and\nNB. Hina, Maryam, and colleagues (2021) implemented Sefaced:\nDeep learning-based semantic analysis and categorization of e-mail\ndata using a forensic technique. For multiclass email classification,\nSeFACED employs a Gated Recurrent Neural Network (GRU) based\non Long Short-Term Memory (LSTM). Diferent random weight\ninitializations afect LSTMs . Zhang, Yan, et al.(2019) Experiments\non three-way game-theoretic rough set (GTRS) email spam\nfiltering show that it is feasible to significantly boost coverage without\ndecreasing accuracy . According to Xia et al. , SMS spam\nhas been identified using machine learning model such as naive\nbayes , vector-space modeling, support vector machines (SVM),\nlong selective memory machines (LSTM), and convolutional neural\nnetworks including every instance of a method for categorizing\ndata. Elshoush, Huwaida, et al. (2019) Using adaboost and stochastic\ngradient descent (sgd) algorithms for e-mail filtering with R and\norange software spam . Orange software was used to create the\nclassifications, which included Adaboost and SGD. The majority of\nresearchers focused on text-based email spam classification\nmethods because image-based spam can be filtered in the early stages\nof pre-processing. There are widely used word bag (BoW) model,\nwhich believes that documents are merely unordered collections\nof words, is the foundation for these techniques. Kumaresan \nexplains SVM with a cuckoo search algorithm was used to extract\ntextual features for spam detection. Renuka and Visalakshi made\nuse of svm  spam email identification, followed by selecting\nfeatures using Latent Semantic Indexing (LSI). Here we have used\nlabeled dataset to train the hybrid classifier. We used TF-IDF for\nfeature extraction  and Textual features for spam detection\nwere extracted using SVM and a cuckoo search algorithm.  for\nifltering out the spam email. Combining the integrated strategy to\nthe pure SVM and NB methods, overall accuracy is really improved.\nMoreover, accurate detection for spam email has been proposed\nusing the Negative Selection Algorithm (NSA) and Particle Swarm\nOptimization?s (PSO) algorithm. PSO is used in this instance to\nimprove the efectiveness of the classifier.\n1.2 Motivation and Novelty E m a i l   i s   m o s t   c o m m o n   f o r m   o f   c o m m u n i c a t i o n   b e t w e e n   p e o p l e \n i n   t h i s   d i g i t a l   a g e .   M a n y   u s e r s   h a v e   b e e n   v i c t i m s   o f   s p a m   e m a i l s , \n a n d   t h e i r   p e r s o n a l   i n f o r m a t i o n   h a s   b e e n   c o m p r o m i s e d .   T h e   e m a i l \n C l a s s i f i c a t i o n   t e c h n i q u e   i s   e m p l o y e d   t o   i d e n t i f y   a n d   f i l t e r   j u n k \n m a i l ,   j u n k ,   a n d   v i r u s - i n f e c t e d   e m a i l s   p r i o r   t o   r e a c h   a   u s e r ? s   i n b o x . \n E x i s t i n g   e m a i l   c l a s s i f i c a t i o n   m e t h o d s   r e s u l t   i n   i r r e l e v a n t   e m a i l s \n a n d / o r   t h e   l o s s   o f   v a l u a b l e   i n f o r m a t i o n .   K e e p i n g   t h e s e   c o n s t r a i n t s \n i n   m i n d ,   t h e   f o l l o w i n g   c o n t r i b u t i o n s   a r e   m a d e   i n   t h i s   p a p e r : \n ?   T e x t - b a s e d   f e a t u r e   e x t r a c t i o n   i s   a   l e n g t h y   p r o c e s s . \n F u r t h e r m o r e ,   e x t r a c t i n g   e v e r y   i m p o r t a n t   f e a t u r e   f r o m   t e x t   i s   d i f i c u l t . \n I n   t h i s   p a p e r ,   w e   s h o w   h o w   t o   e m p l o y   G R U   w i t h \n C o n v o l u t i o n a l   N e u r a l   N e t w o r k s   a n d   B i d i r e c t i o n a l - L S T M   t o   f i n d \n s p a m . \n ?   U s e d   W o r d - E m b e d d i n g s ,   B i L S T M ,   a n d   G a t e d   R e c u r r e n t \n N e u r a l   N e t w o r k s   t o   e x a m i n e   t h e   r e l a t i o n s h i p s ,   s e n t i m e n t a l \n c o n t e n t ,   a n d   s e q u e n t i a l   w a y   o f   e m a i l   c o n t e n t s . \n ?   A p p l i e d   C N N   b e f o r e   t h e   B i - L S T M   n e t w o r k ,   t r a i n i n g   t i m e   c a n \n b e   s p e d   u p .   T h i s   n e t w o r k   c a n   a l s o   e x t r a c t   m o r e   a d v a n c e d \n t e x t u a l   f e a t u r e s   f a s t e r   t h a n   t h e   B i - L S T M   n e t w o r k   a l o n e   w h e n \n c o m b i n e d   w i t h   t h e   G R U   n e t w o r k . \n ?   W e   u s e   E n o r n   C o r p o r a   d a t a s e t s   a n d   c o m p u t e   p r e c i s i o n , \n r e c a l l ,   a n d   f - s c o r e   t o   a s s e s s   h o w   w e l l   t h e   s u g g e s t e d   t e c h n i q u e \n p e r f o r m s .   O u r   m o d e l   o u t p e r f o r m s   s e v e r a l   w e l l - k n o w n \n m a c h i n e   l e a r n i n g   t e c h n i q u e s   a s   w e l l   a s   m o r e   c o n t e m p o r a r y \n m e t h o d s   f o r   s p a m   m e s s a g e   d e t e c t i o n . \n 2 PROPOSED SYSTEM ARCHITECTURE AND  MODEL E - m a i l   i s   a   v a l u a b l e   t o o l   f o r   c o m m u n i c a t i n g   w i t h   o t h e r   u s e r s .   E m a i l \n a l l o w s   t h e   s e n d e r   t o   e f i c i e n t l y   f o r w a r d   m i l l i o n s   o f   a d v e r t i s e m e n t s \n a t   n o   c o s t .   U n f o r t u n a t e l y ,   t h i s   s c h e m e   i s   n o w   b e i n g   u s e d   i n   a   v a r i e t y \n o f   o r g a n i z a t i o n s .   A s   a   r e s u l t ,   a   m a s s i v e   a m o u n t   o f   r e d u n d a n t   e m a i l s \n i s   k n o w n   a s   s p a m   o r   j u n k   m a i l ,   m a n y   p e o p l e   a r e   c o n f u s e d   a b o u t   t h e \n e m a i l s   i n   t h e i r   E -   M a i l b o x e s .   E a c h   l e a r n i n g   s e q u e n c e   i s   g i v e n \n f o r w a r d   a s   w e l l   a s   b a c k w a r d   t o   t w o   d i f e r e n t   L S T M   n e t w o r k s   t h a t   a r e \n a t t a c h e d   t o   t h e   s a m e   o u t p u t s   l a y e r   i n   o r d e r   f o r   b i d i r e c t i o n a l   L s t m s \n t o   f u n c t i o n .   T h i s   i n d i c a t e s   t h a t   t h e   B i - L S T M   h a s   d e t a i l e d   s e q u e n t i a l \n i n f o r m a t i o n   a b o u t   a l l   p o i n t s   b e f o r e   a n d   f o l l o w i n g   e a c h   p o i n t   i n   a \n s p e c i f i c   s e q u e n c e .   I n   o t h e r   w o r d s ,   w e   c o n c a t e n a t e   t h e   o u t p u t s   f r o m \n b o t h   t h e   f o r w a r d   a n d   t h e   b a c k w a r d   L S T M   a t   e a c h   t i m e   s t e p   r a t h e r \n t h a n   j u s t   e n c o d i n g   t h e   s e q u e n c e   i n   t h e   f o r w a r d   d i r e c t i o n .   E a c h \n w o r d ? s   e n c o d e d   f o r m   n o w   c o m p r e h e n d s   t h e   w o r d s   t h a t   c o m e   b e f o r e \n a n d   a f t e r   i t .   T h i s   i s   a   p r o b l e m   f o r   t h e   I n t e r n e t   c o m m u n i t y .   T h e \n d i a g r a m   d e p i c t s   v a r i o u s   s t a g e s   t h a t   a i d   i n   t h e   p r e d i c t i o n   o f   e m a i l   s p a m : \n B e c a u s e   r e a l - w o r l d   d a t a   i s   m e s s y   a n d   c o n t a i n s   u n n e c e s s a r y \n i n f o r m a t i o n   a n d   d u p l i c a t i o n ,   d a t a   p r e p r o c e s s i n g   i s   c r i t i c a l   i n   n a t u r a l \n l a n g u a g e   p r o c e s s i n g   ( N L P ) .   T h e   m a j o r   p r e p r o c e s s i n g   s t e p s   a r e \n d e p i c t e d   b e l o w . \n 2 . 1 NLP Tokenization T o k e n i z a t i o n   o f   d o c u m e n t s   i n t o   w o r d s   f o l l o w s   p r e d e f i n e d   r u l e s . \n T h e   t o k e n i z a t i o n   s t e p   i s   c a r r i e d   o u t   i n   P y t h o n   w i t h   s p a c y   l i b r a r y . \n 2 . 2 Stop Words Removal S t o p   w o r d s   a p p e a r   i n f r e q u e n t l y   o r   f r e q u e n t l y   i n   t h e   d o c u m e n t ,   b u t \n t h e y   a r e   l e s s   s i g n i f i c a n t   i n   t e r m s   o f   i m p o r t a n c e .   A s   a   r e s u l t ,   t h e s e \n a r e   r e m o v e d   t o   i m p r o v e   d a t a   p r o c e s s i n g . \n 2 . 3 Text Normalization A word?s lexicon form or order may difer. Thus, they must all be\nchanged to their root word to be correctly analyzed. Lemmatization\nand stemming are the two methods that can be used for\nnormalization. When a word?s final few characters are removed to create\na shorter form, even if that form has no meaning, the procedure\nis known as stemming. lemmatization  is a mixture of\ncorpusbased an rule-based methods, and it retains the context of a term\nwhile changing it back to its root.\n2.4 Feature Extraction\nfeature extraction which transforms the initial text into its features\nso that it may be used for modeling after being cleaned up and\nnormalized. Before predicting them, we use a specific way to give\nweights to specific terms in our document. While it is simple for a\ncomputer to process numbers, we choose to represent individual\nwords numerically. In such cases, we choose word embeddings. IDF\nis the count of documents containing the term divided by the total\nnumber of documents, and occurrence is the amount of instances a\nword appears in a document. We derive characteristics based on\nequations. 1,2,3,4,5, and 6. We use equations to derive properties.\n1\n    =   ?  \n    =   ? Inverse(  )\n    (, , ) =   (, ).  (, )\n   (, ) = log | |\nA word2vec neural network-based approach is the method that is\nutilized for this goal as the tool. The following equation, referred\nto as 5, shows how word2vec handles word context through the\nuse of probability-accurate measurements. Here letter D stands for\nthe paired-wise display of a set of words, while the letters w and c0\nor c1 represent paired word context that originated from a larger\ncollection of set D. ( = 1 | ,  11: ) =\n ( = 1 | ,  1: ) =\n1 +  ? ( 11+ 12+...+ 1 )\n1\n1\n1 +  ? ( 0)\n(1)\n(2)\n(3)\n(4)\n(5)\n(6)\n2.5 Word-Embeddings W o r d - E m b e d d i n g   h e l p s   t o   i m p r o v e   o n   t h e   t y p i c a l   \" b a g - o f - w o r d s \" \n w o r l d v i e w ,   w h i c h   r e q u i r e s   a   m a s s i v e   s p a r s e   f e a t u r e   v e c t o r   t o   s c o r e \n e v e r y   w o r d   i n d i v i d u a l l y   t o   r e p r e s e n t   t h i s   s a m e   e n t i r e   v o c a b u l a r y . \n T h i s   p e r c e p t i o n   i s   s p a r s e   b e c a u s e   t h e   v o c a b u l a r y   i s   l a r g e ,   a n d   e a c h \n w o r d   o r   d o c u m e n t   i s   d e f i n e d   b y   a   m a s s i v e   v e c t o r .   U s i n g   a   w o r d \n m a p - b a s e d   d i c t i o n a r y ,   w o r d   e m b e d d i n g   n e e d s   t o   b e   c o n v e r t e d   t e r m s \n ( w o r d s )   i n t o   r e a l   v a l u e   f e a t u r e   v e c t o r s .   T h e r e   a r e   t w o   b a s i c   i s s u e s \n w i t h   s t a n d a r d   f e a t u r e   e n g i n e e r i n g   t e c h n i q u e s   f o r   d e e p   l e a r n i n g . \n D a t a   i s   r e p r e s e n t e d   u s i n g   s p a r s e   v e c t o r s ,   a n d   t h e   s e c o n d   i s   t h a t \n s o m e   o f   t h e   m e a n i n g s   o f   w o r d s   a r e   n o t   t a k e n   i n t o   c o n s i d e r a t i o n . \n S i m i l a r   p h r a s e s   w i l l   h a v e   v a l u e s   i n   e m b e d d i n g   v e c t o r s   t h a t   a r e \n a l m o s t   r e a l - v a l u e d .   T h e   I n p u t   l e n g t h   i n   o u r   p r o p o s e d   s t u d y   i s   s e t \n t o   7 0 0   f o r   o u r   s u g g e s t e d   m o d e l .   I f   t h e   t e x t s   s e e m e d   t o   b e   i n t e g e r \n e n c o d e d   w i t h   v a l u e   s y s t e m s   b e t w e e n   1 0   a n d   2 0 ,   t h e   v o c a b u l a r y \n d i s t a n c e   w o u l d   b e   1 1 .   O u r   d a t a   i s   e n c o d e d   a s   i n t e g e r s ,   a n d   t h e   i n p u t \n a n d   o u t p u t   d i m e n s i o n s   a r e   b o t h   s e t   t o   5 0 , 0 0 0 .   T h e   e m b e d d i n g   l a y e r \n o u t c o m e   w i l l   b e   u s e d   i n   s u c c e s s i v e   l a y e r s   a n d   f o r   B i L S T M   a n d   G R U \n l a y e r s . \n 2 . 6 Machine Learning Model W i t h i n   t h e   s c o p e   o f   t h e   r e s e a r c h ,   w e   a r e   u s i n g   t h e   s u b s e q u e n t \n m a c h i n e   l e a r n i n g   t e c h n i q u e s ,   t o   e x a m i n e   a n d   c o m p a r e   t h e   o v e r a l l \n e f i c a c y   o f   o u r   s u g g e s t e d   B i - L S T M   s t r a t e g y :   S u p p o r t   V e c t o r \n M a c h i n e ,   G a u s s i a n   N B ,   L o g i s t i c   R e g r e s s i o n ,   K   -   n e a r e s t   n e i g h b o r s ,   a n d \n R a n d o m   F o r e s t   ( R F ) . \n 2 . 7 Convolution Network xref #text BiLSTM Network with GRU Recurrent Neural Network (RNN) technique of text sentiment\nanalysis is particularly well-liked and frequently applied. Recurrent\nneural networks (RNN) surpass conventional neural networks.\nbecause it can remember the information from earlier time steps\nthanks to its memory. A state vector is combined with an RNN?s\ndata to create a new state vector. The resulting state vector uses the\npresent to recollect past knowledge. The RNN is straightforward\nand is based on the following equations:\n? = tanh (??? ?1 + ? )\n = ? ?\n(7)\n(8)\nThe vanilla RNNis not very good at remembering previous\nsequences. In addition to that, RNN struggles with diminishing\ngradient descent. A kind of RNN is a long short-term recall network\n(LSTM), solves a vanishing gradient descent problem and learns (9)\n(10)\n(11)\n(12)\n(13)\n(14)\nlong-term dependencies. LSTM was actually created to address\nthe problem of long-term reliance. LSTM has the unique ability to\nrecall. The cell state is the LSTM model?s central concept. With\nonly a small amount of linear interaction, the cell state follows the\nsequence essentially unmodified from beginning to end. gate of\nan LSTM is also significant. Under the command of these gates,\ninformation is safely inserted to or eliminated from the cell stated.\nThe following equations are used by the LSTM model to update\neach cell: =    [? ?1,  ] +  \nIn this case, Xt denotes input, and ht is the hidden state at the t\ntime step. The following is the revised cell state Ct: t =  ( [? ?1,  ] +  )\n = tanh ( [? ?1,  ] +  ) =  ?  ?1 +  ? \n =  (  [? ?1,  ] +  ) ? =  ? tanh ( )\nHere, we may compute the output and hidden state at t time steps\nusing the point-wise multiplication operator *. Due to the reality it only considers all prior contexts from the\npresent one, LSTM does have a few drawbacks. As a result of this,\nit may accept data from preceding time steps through LSTM as well\nas RNN. Therefore, in order to avoid this issue, further\nimprovements are carried out with the help of a bidirectional recurrent\nneural network(Bi-RNN). BiRNN  can handle two pieces of\ninformation from both the front and the back. Bi-LSTM is created\nby combining the Bi-RNN and LSTM. As a result, operating LSTM\nhas advantages such as cell state storage so that BiRNN have way\nto acknowledge from the context before and after. As a\nconsequence of this, it provides the Bi-LSTM with the advantages of an\nLSTM with feedback for the next layer. Remembering long-term\ndependencies is a significant new benefit of Bi-LSTM. The output,\nwhich is a feature vector, will be based on the call state. Finally,\nwe forecast the probability of email content as Normal,\nFraudulent, Harassment, and Suspicious Emails using as an input to the\nsoftmax activation function, which is a weighted sum of the dense\nlayer?s outputs. To regulate the information flow, GRU employs\nthe point-wise multiplying function and logistic sigmoid activation.\nThe GRU has hidden states of storage memory and does not have\ndistinct memory cells or units for state control. The W, U, and b\nvectors, which stand for weights, gates, and biases, respectively, are\ncrucial variables that must be calculated during the creation of the\nGRU model. For training reasons, the pre-trained word embedding\nknown as the Glove vector is used. They made it clear that GRU\nis the superior model when there is a large amount of training\ndata for textual groups and word embedding is available. BiLSTM,\nCNN, and GRU is required so as to compensate for the deletion\nof the document?s long-term and short-term connections. In our\ncase, the embedding dimension, maximum sequence length, and\nlexicon size were used to start the LSTM embedding layer in three\nseparate LSTM models. The input vector was modified to make it\nappropriate for such a Conv1D layer, prior situations? sequences are\nreturned by LSTM layer. The \"return sequences\" of the LSTM layer\nmust be set to False when the subsequent state is free of the gated\narchitecture. Quantity of learning parameters must be taken into\nconsideration. A 350-unit LSTM layer was set - up, and diferent\nLSTM unit combinations were tested. More importantly, because\nit has more parts, the model made with BiLSTM will take longer\nto train. Bidirectional LSTM is the name of a particular kind of\nrecurrent neural network that is primarily used for the processing\nof natural languages. (BiLSTM). It is able to use data from both\nsides, and, in contrast to regular LSTM, it enables input flow in\nboth directions. It is an efective instrument for demonstrating the\nlogical relationships between words and phrases, and this involves\nboth the forward and backward directions of the sequence. In\nconclusion, BiLSTM works by adding one extra layer of LSTM, causing\nthe information flow to travel in the other direction. It only denotes\nthat the input sequence runs in reverse at the next LSTM layer.\nMultiple operations, including averaging, summation, multiplication,\nand concatenation, are then applied to the results of the two LSTM\nlayers. The gated design of Bi-LSTM and GRU networks solves\nthe disappearing gradient and exploding problems. A good way to\nhandle more long sequences is to use Bi-LSMT and GRU together.\nGRU works well with datasets that don?t have text. In two to three\nrounds, the complicated CNN+BiLSTM+GRU model learns the long\nsequence of email text well. We have used word embedding, cnn,\nbidirectional lstm and gru networks as our three building blocks\nto separate email messages based on their sentiment and text?s\nsequential features. Also, we succinctly demonstrate below why\nthese blocks help identify email spam:\n? First, We have used the Sequence - to - sequence Lstm as the\ncurrent block in the networks since it can retrieve both the\nprevious and next sequences from the current. More so than\na straightforward LSTM network, it can also recognize and\nextract text sentiment and sequential properties.\n? Second, we extract the more complex and advanced\ncharacteristics for Bi-LSTM network using Convolutional Network\nblock, which is the network?s second block after the Bi-LSTM\nblock. Bi-LSTM takes a long time to extract text-based\nfeatures, hence one of the reasons for using this block is to\nreduce the network?s overall training time.\n3\n3.1 EXPERIMENTAL EVALUATION  Experimental Setup W e   d i v i d e d   t h e   i n f o r m a t i o n   i n t o   t r a i n i n g   a n d   t e s t i n g   g r o u p s   o f \n 8 0 / 2 0 .   W e   d i v i d e d   t h e   r e m a i n i n g   2 0 %   o f   t h e   8 0   p e r c e n t   t r a i n i n g \n d a t a   i n t o   t e s t   d a t a   f o r   t h e   m o d e l .   C o n s t r u c t ,   c o m p u t e ,   a n d   e v a l u a t e \n t h e   e f i c a c y   o f   t h e   s u g g e s t e d   m e t h o d   u s i n g   t h e   P y t h o n i c   p a c k a g e s \n K e r a s ,   a s   T e n s o r F l o w   a n d   S c i k i t   l e a r n . \n 3 . 2 Dataset Description xref #text Evaluation Metrics and Results Classifier performance is assessed Using metrics such as accuracy,\nprecision, and recall. Four terms make up a confusion matrix that\nis used to calculate these metrics. ? True positives (TP) are positive values that have been\naccurately assigned the positive label.\n? The negative values that are accurately identified as negative\nare known as True Negatives (TN).\n? True Negative values are those that can be accurately\nidentiifed as being negative (TN).\n? Positive readings that have been mistakenly labeled as\nnegative are known as False Negatives (FN). Assess the eficacy of the suggested model is listed below:\n3.3.1 Accuracy. Accuracy reveals how frequently the ML model\nwas overall correct. Accuracy = +  \n  +   +   +  \n3.3.2 Precision. The accuracy of the model gauges how efectively\nit can predict a specific category.\n3.3.3 Recall. Recall tells us how often the model was able to\nrecognize a specific category. Precision = +  \nRecall = +  \n(15)\n(16)\n(17)\nModel Accuracy Precision\nGaussian NB 91.3 90.1\nRandom Forest 88.41 90\nKNN 86.6 89\nSVM 92.4 91\nLSTM 95.2 95\nProposed Ensemble 97.32 95.6\n(CNN,BiLSTM+GRU) Table 1: Diferet Model?s Score on Test Data Accuracy, Precision, and Recall metrics are computed. In the\ngiven Table 1 where six diferent classifiers are Gaussian NB,\nRandom Forest, KNN, SVM, LSTM, and Propose Ensemble Hybrid\nModel (CNN+BiLSTM+GRU) have been used in this work. In the\nCNN, Bi-LSTM, and GRU architectures which enable sequence\nprediction, CNN strands for feature extraction on data input which are\ncombined with LSTM. It requires less time training and a higher\nexpandable model. Any bottlenecks are created by predictions and\nthe increasing number of distinct units of information. This model\nis useful for dealing with issue-related classifications that consist\nof two or more than two classes. So suggested Ensemble model, out\nof these six classifiers, produces more accurate findings. Comparative Analysis A model?s ability to fit new data is measured by the validation\nloss, whereas its ability to fit training data is determined by the\ntraining loss. The two main variables that decide whether in which\nlearning is eficient or not are validation loss and training loss.\nLSTM and Suggested Ensemble hybrid Models have equivalent loss\nand accuracy. In this context, we are contrasting the LSTM with the\nproposed model (CNN, Bilstm, and GRU) in terms of their respective\nvalidation accuracies and losses. The model?s accuracy was at its\nhighest after 14 epochs of operation when it achieved an accuracy\nof roughly 97-98% while minimizing model loss. In this Proposed ensemble hybrid model?s train accuracy is 98.7%\nValidation accuracy is 97.32% and LSTM has train accuracy of 97.41%\nand validation accuracy is 95.2%. So based on figures 3 and 5 indicate\nthe validation loss for LSTM and the proposed ensemble hybrid\nmodel to be 0.93 and 0.84, respectively, and figures 2 and 4 show the\nvalidation accuracy to be 95.2% and 97.3%, respectively. LSTM and\nthe proposed hybrid model used ensemble artificial intelligence,\nwith the proposed hybrid model outperforming the LSTM. We\ndecide on dense architecture as the final model for identifying the\ntext messages as spam or nonspam based on loss, accuracy, and the\naforementioned charts. The loss and accuracy over epochs are more\nstable than LSTM, and the Proposed classifier has a straightforward\nstructure.\n4 CONCLUSION T h e   m o d e l   i s   c o m p o s e d   o f   f o u r   n e t w o r k s   W o r d - E m b e d d i n g s ,   C N N , \n B i - L S T M ,   a n d   G R U .   W e   m a y   t r a i n   t h e   m o d e l   m o r e   q u i c k l y   b y   u s i n g \n t h e   c o n v o l u t i o n a l   l a y e r   f i r s t ,   f o l l o w e d   b y   t h e   w o r d - e m b e d d i n g   l a y e r , \n a n d   t h e n   t h e   B i L S T M   n e t w o r k .   T h e   B i d i r e c t i o n a l   L S T M   n e t w o r k \n a l s o   h a s   h i g h e r - l e v e l   p r o p e r t i e s   t h a t   w e   c a n   e x t r a c t .   W e   h a v e   u s e d \n a   b i d i r e c t i o n a l   L S T M ( B i L S T M ) a n d   G R U   n e t w o r k   t o   m e m o r i z e   a \n s e n t e n c e ? s   c o n t e x t u a l   m e a n i n g   a n d   s e q u e n t i a l   s t r u c t u r e ,   w h i c h \n i m p r o v e s   t h e   m o d e l ? s   p e r f o r m a n c e   a c c u r a c y   t o   r o u g h l y   9 7 . 3 2   p e r c e n t .",
  "references": [
    "given-names, surname, '['Sentiment analysis using unlabeled email data', 'Knowledge Economy (ICCIKE)']', In 2019 International Conference on Computational Intelligence, 2019",
    "given-names, surname, 'Proposed eficient algorithm to filter spam using machine learning techniques', Pacific Science Review A: Natural Science and Engineering, ['2016', '2016']",
    "T Huwaida,  Elshoush, '['Esraa A Dinar', 'Using adaboost and stochastic gradient descent (sgd) algorithms with R and orange software for filtering e-mail spam']', In 2019 11th Computer Science and Electronic Engineering (CEEC), 2019"
  ],
  "keywords": [
    "Semantic Analysis",
    "GRU",
    "LSTM",
    "Model",
    "Analysis and Classification",
    "Analysis",
    "BiLSTM",
    "Informative Selection",
    "Model Accuracy Precision",
    "RNN",
    "Accuracy Precision Recall",
    "cid",
    "bi-directional LSTM network",
    "Sachanetal",
    "training",
    "SVM",
    "LSTM network",
    "Accuracy",
    "Precision",
    "Ensemble"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1x-tnMfKnz3jaRbUhX_suVo81MpWqPSEW"
}
{
  "id": 9,
  "title": "ModelGame: A Quality Model for Gamified Software Modeling Learning",
  "authors": [
    "Ed Wilson Jnior?",
    "Kleinner Farias"
  ],
  "institutions": [
    "Universidade do Vale do Rio dos Sinos",
    "Universidade do Vale do Rio dos Sinos"
  ],
  "resume": "Gamification has been adopted in software development tasks in recent years. This adoption seeks, for example, to improve the engagement of developers while creating UML models or writing code. Empirical studies report that UML models sufer from incompleteness and inconsistency problems. This study conjectures that gamification mechanics can improve learner engagement while learning software modeling, mitigating such problems concerning UML models. The current literature lacks studies that explore gamification and UML model quality in the context of software modeling learning. This article, therefore, proposes ModelGame, which is a quality model to support software modeling learning in a gamified way. It serves as a reference framework so that instructors can obtain a parameterized way to evaluate UML models created by learners. The quality of UML models can be improved by applying gamified activities and providing guidelines aware of quality issues. A qualitative questionnaire was answered by 19 instructors who teach software modeling at higher education institutions. The results show that (1) 94.7% recognize that the proposed model can improve the quality of UML models, indicating that they would adopt the ModelGame in their learning practices; and (2) 47.4% do not use any gamification mechanics in their classes. The results are encouraging, showing the potential for applying and improving the teaching and learning of software modeling.",
  "content": "CCS CONCEPTS ?   S o f t w a r e   a n d   i t s   e n g i n e e r i n g   ?   S o f t w a r e   d e s i g n \n e n g i n e e r i n g . INTRODUCTION Gamification has been adopted in software development tasks in\nrecent years. This adoption seeks, for example, to improve the\nengagement of developers while creating UML models or writing\ncode. Empirical studies  report that UML models sufer\nfrom incompleteness and inconsistency problems. Lange \nreinforces that these defects bring potential risks that can cause\nmisinterpretation and communication failure, representing a risk to\nsoftware quality. Thus, finding formats that favor student learning\nand consequently in generating increasingly efective UML\nmodels can become one of the main challenges faced by instructors\nthat include UML (Unified Modeling Language) as part of software\nmodeling content. Some studies  sought to understand how to apply\ngamification in software modeling teaching using some elements such\nas points, emblems and levels. However, instructors and researchers\nstill find limitations when applying, evaluating, and measuring the\nuse of this tool in the learning of software modeling students and,\nconsequently, in the models developed by them, since in the current\nliterature there is no ?frame of reference? that guides them. This\nstudy conjectures that gamification mechanics can improve learner\nengagement while learning software modeling, mitigating such\nproblems concerning UML models. The current literature lacks\nstudies that explore gamification and model quality in the context\nof software modeling learning. This article, therefore, introduces ModelGame, which is a quality\nmodel to support software modeling learning in a gamified way.\nIt serves as a reference framework so that instructors can obtain\na parameterized way to evaluate UML models created by learners.\nThe quality of UML models can be improved by applying\ngamiifed activities and providing guidelines aware of quality issues. A\nreference framework would help to (1) establish parameters for\nevaluating UML models created by learners; (2) provide guidelines to\nimprove the quality of these artifacts; (3) to analyze which elements\nof gamification could be included in each of the phases of modeling\nusing UML; (4) identify intrinsic and extrinsic aspects of students\nduring the modeling stages, to improve the models; (5) to compare\nvalidated theories about the inclusion of gamification in software\nmodeling teaching, taking into account the types of learning and\nmethodologies used; and (6) contributing to the identification of\ngamification use objectives in modeling activities. A qualitative questionnaire was answered by 19 instructors who\nteach software modeling at higher education institutions. The\nresults show that (1) 94.7% recognize that the proposed model can\nimprove the quality of UML models, indicating that they would\nadopt it in their learning practices; and (2) 47.4% do not use any\ngamification mechanics in their classes. These results are\nencouraging, showing the potential for applying and improving the teaching\nand learning of software modeling. The remainder of the paper is organized as follows. Section 2\npresents the main concepts discussed throughout the article.\nSection 3 discusses the related work, highlighting research\nopportunities. Section 4 introduces the proposed quality model. Section 5\npresents how the quality model was evaluated. Section 6 points out\nsome threats to validity. Finally, Section 7 presents some concluding\nremarks and future work.\n2 BACKGROUND T h i s   s e c t i o n   p r e s e n t s   t h e   e s s e n t i a l   c o n c e p t s   f o r   u n d e r s t a n d i n g   t h i s \n w o r k ,   i n c l u d i n g   g a m i f i c a t i o n   a n d   s o f t w a r e   e n g i n e e r i n g   t e a c h i n g \n ( S e c t i o n   2 . 1 ) ,   a n d   s o f t w a r e   m o d e l i n g   a n d   m o d e l   q u a l i t y   ( S e c t i o n \n 2 . 2 ) . \n 2 . 1 Gamification and Software Engineering  Teaching Gamification aims to use game elements in the context of not game\n, bringing all positive aspects they provide as a way to encourage\nand engage ?players,? thereby broadening their motivations. Werbach  classifies gamification into three dimensions:\nDynamics, Mechanics, and Components. Dynamicsinclude all game\naspects related to the emotional responses of ?players? (e.g.,\nrelationship, progression, and narrative).Mechanics ofer elements that\npromote the action of a game ? usually elaborated via a rule-based\ndevelopment ?, so that the player can interact with such elements,\ne.g., challenges, feedback, and rewards. Components represent\nthe aesthetic elements of gamification, whose goal is to present\nvisual aspects with which players can perform the interaction, for\nexample, points, scores, and emblems (badges). Knowing that the teaching of Software Engineering should\ninvolve students to experience the professional practices of the area\nso that they can understand which practices and techniques are\nuseful in several diferent situations . The challenges of teaching\nnew software engineers are not limited to learning programming,\nbut also include paying attention to detail, considering the quality\nof created models, established schedule and defined budgets . In\naddition to understanding the technical challenges, these future\nprofessionals must be up to date with nontechnical issues, including\nteamwork, communication and management. To meet these new demands of the current context, the format\nwith exhibition classes is no longer considered enough and may\neven become demotivating and inefective in learning students. In\nthis sense, gamification has been increasingly used in the\nteaching of software engineering as a way to promote behavioral and\npsychological changes  providing an environment that favors\ncommunication, cooperation, feedback, reward, achievement and\nother recurring elements that are capable of improving\nperformance, eficiency and engagement in educational activities , and\ncan enhance, for example, the learning of software modeling.\n2.2 Software Modeling and Model Quality Software modeling encompasses the set of principles, concepts, and\npractices that lead to the development of a high-quality system or\nproduct. The principles of this activity establish a philosophy that\nguides the entire software development process. In this scenario, UML models play a crucial role in software\ndevelopment tasks, for example, documenting project decisions,\nunderstanding development details, promoting better\ncommunication between teams, and generating greater eficiency in software\ndevelopment . However, these models sufer problems of\ninconsistency and incompleteness , as well as end up being\noverlooked within the modeling process, as pointed out in some\nempirical studies in the literature . Class and sequence\ndiagrams, for example, present inconsistencies when sequence diagram\nobjects are not found in the class diagram, consequently developers\nend up living with inconsistencies throughout the development\nprocess. A research challenge still open is how to evaluate these diagrams,\nboth in industry and in the teaching process, in terms of quality,\nsuch as syntactic and semantic, for example.\n3 RELATED WORK T h e   s e l e c t i o n   o f   r e l a t e d   w o r k s   w a s   c a r r i e d   o u t   f o l l o w i n g   t w o   s t e p s : \n ( 1 )   s e a r c h   i n   d i g i t a l   r e p o s i t o r i e s ,   s u c h   a s   G o o g l e   S c h o l a r   a n d   S c o p u s \n ( E l s e v i e r )   o f   a r t i c l e s   r e l a t e d   t o   g a m i f i c a t i o n ,   q u a l i t y   m o d e l i n g ,   a n d \n m o d e l i n g   l e a r n i n g ;   a n d   ( 2 )   f i l t e r   s e l e c t e d   a r t i c l e s   c o n s i d e r i n g   t h e \n a l i g n m e n t   o f   s u c h   w o r k s   w i t h   t h e   o b j e c t i v e   o f   t h e   w o r k   ( S e c t i o n   4 ) . \n A f t e r   s e l e c t i n g   t h e   w o r k s ,   t h e y   w e r e   a n a l y z e d   ( S e c t i o n   3 . 1 )   a n d \n c o m p a r e d   ( S e c t i o n   3 . 2 ) ,   s e e k i n g   t o   i d e n t i f y   r e s e a r c h   o p p o r t u n i t i e s . \n 3 . 1 Analysis of Related Works Porto et al. (2021) . This work performed a systematic\nmapping with the objective of characterizing how gamification has\nbeen adopted in noneducational contexts of software engineering\nactivities. The main results of this study show that gamification\nprovided benefits for activities such as requirements specification,\ndevelopment, testing, project management, and support process.\nIn addition, he pointed out that the number of publications and\nnew research initiatives has increased over the years, many\npositive results have been achieved in software engineering activities.\nNevertheless, the study reinforced that gamification can still be\nexplored for other tasks in this area, as empirical evidence is very\nlimited. Marin (2021) . It performed the application of gamification\non some topics of a software engineering course to engage students\nand increase their motivation and argued that, with due\nmotivation, students can better exercise the topics and obtain more solid\nknowledge. There were five games related to risk management,\nBPMN modeling, Scrum process, design and inspection of class\ndiagrams, and cosmic functional size measurement to assist in the\nlearning process of the software engineering course. This study also\npresented the lessons learned about the application of gamification\nand serious games in software engineering, including limitations\nor disadvantages. Jurgelaitis et al. (2018) . This work conducted a research to\ninvestigate how gamification could be inserted into an Information\nSystems Modeling course, which covers a range of topics on UML.\nAs a result, an implementation of the gamified system modeling\ncourse in the Moodle environment was presented, using additional\nplugins for the use of the necessary gamified elements. The study\nshowed good results and obtained a positive acceptance by the\nparticipating students. Rodrigues et al. (2018) . They investigated the use of games\nand game elements in software engineering education, through a\nresearch that had the participation of 88 instructors of this\ndiscipline. The results showed that most instructors are aware of these\neducational approaches, however, the games were adopted by only\n21 participants and game elements were adopted only by 19. Games\nare most often used to cover ?Software Process? and ?Project\nManagement?. The most commonly used game elements are points,\nquizzes, and challenges. The results also show that the main\nreasons for not adopting the resources are the lack of knowledge,\ninformation about games relevant to the engineering of teaching\nsoftware, and the lack of time to plan and include these approaches\nin the classroom. Cosentino et al. (2017) . They present a model-based\napproach to learning modeling in a gamified way. The approach\nincludes a new language to model the gamification process itself and\nan environment where it can be incorporated into current\nmodeling tools to allow instructors and students to design and use a\ncomplete modeling framework, including gamification elements. In\naddition, the approach also had as a proposal to provide support to\ncollect and analyze gamification data, thus facilitating monitoring\nactivities. Yohannis (2016) . This research presents an exploration of\ngame design as an approach to strengthening the student?s\nmastery in software modeling by developing their abstraction skills. It\nbrought together concepts of gamification development, such as the\nlens of atoms of intrinsic skill and principles of pedagogical design\nof various theories and models of learning. The research follows\nthe Design Science Research Methodology and explores the best\npractices of Model Oriented Engineering. As a result, a modeling\ngame design framework and generation structure and a series of\nproduced games are presented. Pedreira et al. (2015) . They developed a systematic\nmapping of gamification in Software Engineering based on 29 studies.\nThe mapping revealed that software implementation is the area\nin which most studies focus, followed by software requirements,\nfew others in diferent areas, such as project planning and software\ntesting, and even to a lesser extent in activities involving software\nmodeling. However, the highlight of this work was to highlight that\ngamification in software engineering is still at a very early stage\nand the evidence on its impact in this field remains inconclusive.\n3.2 Comparative Analysis and Opportunities Five Comparison Criteria (CC) were defined selecting the most\nrelevant variables to assist in the process of identifying similarities and\ndiferences between the proposed work and the selected articles.\nThis comparison is crucial to make the process of identifying\nresearch opportunities using objective rather than subjective criteria.\nThe criteria are described below: in software modeling teaching/learning.\n? Context (CC01): Works that explore the use of gamification\n? Participant profile (CC02): Studies that collected data from\nparticipants for screening and profile characterization. els.\n? Applicability of Gamification in UML (CC03): Studies\nthat evaluated how gamification can contribute to UML\nmod? Model creation (CC04): Studies that have developed a model\nto improve factors that imply the non-adoption of UML.\n? Instructor participation (CC05): Studies that collected\nqualitative data through the participation of software\nmodeling instructors.\nthis work. Some gaps and research opportunities are observed: (1)\nonly the proposed work was the only one to fully meet all\ncomparison criteria; (2) although most of them targeted the application\nof gamification in software modeling teaching, they were not\ndirected to the use of UML; (3) no study has developed a model to\nevaluate the learning and improvement of UML models developed\nby students; and (4) most of them did not have the participation\nof instructors to identify the dificulties and opportunities in the\napplication of gamification in the teaching of software modeling.\nThus, the next Section presents a quality model to explore these\nidentified opportunities. Related Work\nProposed Work\nPorto et al (2021) \nMarin (2021) \nJurgelaitis et al (2018) \nRodrigues et al (2018) \nCosentino et al (2017) \nYohannis (2016) \nPedreira et al (2015)  Completely Meets CC1\n#\n# Comparison Criterion\nCC2 CC3 CC4 CC5\n#\n#\n#\n#\n#\n#\n#G\n#G\n#G\n#G\n#\n#G\n#\n#G\n#\n#\n#\n#\n#\n#\n#\n#G Partially Meets\n# Does not attend\nModel (presented in Section 4.2), as follows: (1) Are there tools\nthat assist instructors in evaluating the models developed by\nstudents, thus reducing the poor quality and incompleteness of these\nartifacts? (2) What is the prevalence of characteristics that cause\nmodels to be at risk? (3) Are there notions of quality to evaluate\nthe models as a way to define parameters when performing their\ncorrection? (4) Applying the use of gamification in models that\nneed intervention would be a way to identify factors that could\ngenerate models with high quality levels? (5) Does the application\nof gamification improve the quality of the model? (5.a) How are the\nmodels without gamification evaluated in relation to those with\ngamification? (5.b) Are there reasons to expect that gamification\nmodels can have better quality results than those that are\ngenerated without gamification? (6) Is the output model really efective\nwhen associated with reducing the poor quality of the model? (7)\nDoes the absence of evaluation result in adverse efects? (7.a) is the\nevaluation acceptable for the model? (7.b) What are the potential\nharms, and how often do they occur? (8) Does gamification result\nin adverse efects on models? Fact is that it is not enough just to include this \"toolbox\" in the\nUML learning process, it is necessary to provide the instructor with\na model (guide) that can serve as a reference to evaluate the quality\nof diagrams elaborated through gamified activities. For example,\nthe instructor could create models predefining inconsistencies by\nmaking use of these questions raised to evaluate the models created\nby the students. The set of questions serves as the starting point for\nthis evaluation. Knowing that the adaptation of the gamification\napproach requires a significant efort , in this study we present\nThe ModelGame as a way to identify factors that contribute to\nthe quality of these artifacts and, consequently, to the students?\nlearning.\n4.2\nFollowing the specification pattern of the UML metamodel, Figure 2\npresents the abstract syntax of the proposed Quality Model for\ngamified software modeling learning (ModelGame). It identifies\nthe main concepts and relationships. The numbers represent the\nnotions of quality that are discussed in Section 4.3. The following\nare detailed each of these concepts and relationships. Domain. The first concept presented in this study is the domain,\nwhich corresponds to a specific context of the application to be\ndeveloped to solve the problem. In this process, the design template\nrepresents the solution given to the domain. Association ? contextualizes: Challenges[*] Each contextualise refers to the domain that will serve as the\nbasis for the challenges launched. Challenges. This concept represents the phase in which the\nproblem is contextualized (domain-based), as well as what will be\nthe missions, phases, scenarios, and other elements presented to\nthe players, in this case the students, who must use the principles\nof software engineering to perform the modeling and reach the\nifnal goal. Association ? influences: Design Model[*] Each influence represents that the proposed challenge interfered\nin aspects of the design model, causing the user to seek to make a\ncontinuous improvement. Modeling Language. Software modeling is an important step\nfor development to happen in a way that adheres to the\nrequirements established by the requester, for this, there is the modeling\nlanguage, which ofers a standardized way to document and design\nsoftware. Through the use of modeling languages, it is possible to\nachieve a high level of understanding about the software in\nquestion, improving the communication between all those involved in\nthe process, thus avoiding implementation errors. It points out that\nsoftware engineers use these languages to communicate design\ndecisions and verify the feasibility of implementing the intended\ndesign. The UML was consolidated as the Modeling Language in\nthe paradigm of object orientation, in which it is possible through\nvisual notation generated from the diagrams- presented later in this\nstudy as Design Models- to perform the representation of various\nperspectives of the system. Association ? expresses: Design Model[*]\nPerforms the representation of the intended design templates, in\nwhich the Modeling Language should be applicable to the domain\ntype. User. This concept corresponds to the individual who performs\nthe interpretation of the developed design models, whose objective\nis to be able to understand the domain in question. In the gamified\ncontext, the user has the role of player and it is he who performs\nthe whole process, being able to perform the interpretation of\nexisting models or even creating new ones. The user can also identify\nand resolve inconsistencies that arise from compositions between\nmodels. Association ? creates: Design Model[1..*]\nRepresents the process in which the user creates a design template,\nwhich can be one or more. ? interprets: Design Model[1..*]\nIn this association, the user performs the interpretation of the design\ntemplate. When interpreting the model, paths for the resolution of\ninconsistencies can be identified. ? detects: Inconsistency [*]\nRepresents the user?s discovery of design model inconsistencies,\nfor example, those that are generated from identifying conflicts,\nwhether a class is abstract or not. ? resolves: Inconsistency [*]\nEach resolves equates to the resolution representation of the\ninconsistencies by the user that happens after he analyzes and determines\nthe best alternative to perform this action. ? uses: Modeling Tools [*]\nDetermines that the user can use modeling tools to generate/update\ndesign models. Association ? Without a directed relationship. Modeling Tool. This concept represents the applications that\nare used to carry out the construction of design models. There are\nseveral tools available, online and desktop, and it is up to the user\nto choose the one that will best meet their needs and adapt to the\ncontext in question, that is, they work in any domain that is being\nconsidered. Design Model. The design model refers to a visual notation\n(diagram) to represent static and dynamic aspects. These models are\nbuilt according to a specific objective or task and tend to facilitate\nthe logical interpretation of the software in several aspects. The\nmost popular diagrams are Use Cases and Classes, the first being\nstatic and representing a set of actions generated from functional\nrequirements (use cases) and presenting the interactions generated\nwith external users (actors). The second is a static diagram and\nmakes the representation of the logical structure of the software\ninvolving the classes, their attributes, methods, and relationships\nbetween them . Association ? describes: Domain Each describes makes the representation of a specific domain\nand means that every design model must describe it. Inconsistency. It corresponds to the defects found in the models\ndeveloped by users. They may occur because of the\nnonidentification and correction of possible conflicts and even an erroneous\ninterpretation. Association ? affects: Design Model[*]\nThis association indicates that with each occurrence of the afect, a\nproblem is presented harming the quality of the design model. Points. This concept represents one of the most used game\nmechanics in software engineering and functions as a quantitative\nreward for each action developed, in which it is possible to regulate\nthe number of rewarded points of the player, defined here as user,\nbased on the importance of each action. Through this concept, it\nis possible to stimulate competition, collaboration, and creativity\namong users, stimulating learning. Points appear as a derivation\nof the association afects, since when each inconsistency error is\nidentified or not, the user will receive a score and the association\ndescribes, because the points will also be applied when making\nconnections between the model and the domain. Progress. The concept of progress emerges as a factor that makes\nthe user able to perceive its evolution in the process, in this case,\nsoftware modeling. Progress emerges as a derivation of the\nassociation interprets, making the user know when they have performed\na correct interpretation of the proposed design model or what still\nneeds to be improved. Feedback. Feedback has the role of making the user realize that\nthe proposed goal can be achieved and follow its evolution,\nincluding analyzing how to change or creating new strategies to achieve\nthe goal. This concept emerges as a derivation between the\nassociations it creates, causing the user to receive a return to the model\ncreation process.\n4.3 Quality Notions As discussed in Section 2, gamification can bring important\nelements for learning software modeling and, therefore, the objective\nof this section is to produce the notions of quality of the model\nof this study. The ModelGame is composed of ten counts, four of\nwhich are proposed in this study - scope, use, motivational and\nengagement - extracted from the main benefits that the gamification\nelements presented in Figure 2 can bring to the models. The others\nare adaptations of previous works , they are, syntactic,\nsemantic, social, efort, detection and resolution. Scope Quality (1). It seeks to determine how much the proposed\nchallenge is contextualized with the design model, as well as the\ndefinition of the domain, problem, competencies, concepts, behaviors\nand attitudes that will be developed throughout the process. Syntactic Quality (2). This notion makes the representation of\nthe process of correction of the design models that are produced\nby the modeling language, because if it is not used correctly,\ninconsistencies will arise. It is important to insert this notion of quality\ninto our study, since during the process of developing the models,\nusers may come across the composition of two class diagrams, for\nexample. Semantic Quality (3). It is necessary to verify that the design\nmodel and the problem domain match, so this notion performs\nthis type of analysis. Communication problems may occur between\nusers if the semantic elements of the model are afected. Social Quality (4). Design models are used to communicate\nbetween members of a team to inform all established decisions\nabout software development . If divergent interpretations occur,\nthis communication will be greatly impaired. Quality of Efort (5). This notion refers to the production\nchallenges of the model that will be generated, including factors such\nas time and cost. Quality of Use (6). To produce design templates, users can use\nunusual tools such as paper, whiteboard, and more. However, most\nof the time they choose to use formal tools (CASES) and can be\nonline or desktop. This notion corresponds to the level of ease and\napplicability of the models elaborated when making use of these\ntools, it is also important to contribute to communication between\nusers through collaboration-related functionalities. Detection Quality (7). This notion is referenced to the process\nof locating inconsistencies, since when users arise, they should\nperform traceability of them quickly. If the detection is complicated,\nit could hinder the process of correcting the models. Resolution Quality (8). It corresponds to the level of quality\nrelated to the efort that users take to look for alternatives to solve\nthe identified problem. Motivational Quality (9). This notion refers to the\nmotivational factors involved during the learning and development of\ndesign models, which can be intrinsic and extrinsic. Elements of\ngamification such as points, feedback and progress bring the user a\ndegree of satisfaction in continuing their discovery and\ntransformations throughout the process. Quality of Engagement (10). The user in tracking their progress\ncan feel committed to the objective in question, and this notion\nrepresents the measurement of the level of commitment of them\nduring the development of design models.\n5 EVALUATION xref #text Objective and Research Questions The objective (O) of this study is twofold: (O1) Introduce\nModelGame as a tool for teaching Software Modeling; and (O2) Analyze\nthe applicability of the quality model regarding the improvement\nof UML models. To analyze the diferent facets of the objectives, two Research\nQuestions (RQ) have been formulated:\n? RQ1: How do instructors evaluate the use of gamification\nin software modeling?\n? RQ2: What is the acceptance of ModelGame by software\nmodeling instructors?\n5.2 Questionnaire xref #text Selection of participants xref #text Experimental Process Figure 3 presents the experimental process used in this study, which\nis composed of three phases discussed below: Phase 1: Presentation. It has an activity, presentation, in which\nthe researcher explained to the participants through a video detail\nabout the quality model. This process took place individually and\nin a standard way, where space was also made available for\nparticipants to answer possible doubts about the proposed study and\nmodel, lasting an average of 20 minutes. 6 THREATS TO VALIDITY This section discusses the possible threats to the validity of the\nstudy. Internal validity. The main point afecting the internal validity\nof our study concerns the total time used for the exploratory phase.\nTo mitigate this threat, we performed the video recording of a pilot\nexplaining the operating details and objectives of the ModelGame.\nIn relation to the methods used, the threats related to internal\nvalidity relate to how we extract the perceptions of the discussions\nand whether they represent the perceptions of teachers about the\nuse of the Model. We try to reduce this threat by applying the TAM\nquestionnaire. External validity. We identified threats related to external\nvalidity, such as the number of participants who never applied the use\nof gamification. This study was limited to 19 participants (teachers)\nfrom various educational institutions, of which 9 (47.4%) never used\nany element of gamification in their classes, this factor can interfere\nin the data, since the model intends to evaluate the quality of UML\ndiagrams from gamified activities. Conclusion validity. Threats related to the validity of the\nconclusion are related to treatment and outcome. We try to make the\nreduction by combining quantitative and qualitative data through\ndiferent resources. These data were obtained through audio and\nquestionnaires. We analyze this data to answer the research\nquestions. 7 CONCLUSIONS AND FUTURE WORK This study proposed an initial quality model (ModelGame) that\nserves as a reference framework for instructors for qualitative\nevaluations of UML models developed from gamified activities, the\napplication of an empirical study with 19 participants was carried\nout to understand their vision in relation to gamification and the\nacceptance of the proposed Model. It was identified that most have\nnot yet used gamification in their classes, but agree that their use\ncan contribute to the quality of the models developed by the\nstudents and were open to using the model. Our findings can enhance\nthe adoption of new teaching practices through gamification,\nresulting in the improvement of software modeling learning using UML,\nand consequently the creation of models developed by students.\nThese approaches can stimulate students? immersion in the design\nof systems as future professionals during learning. Finally, we hope to carry out in the future a series of experimental\nstudies to analyze each stage of application of the ModelGame\nand that this work represents a first step to better support the\napplication of empirical studies on models of evaluation of the\nuse of gamification in software modeling. We also hope that the\nquestions described throughout the article will encourage other\nresearchers to extend our study to diferent modeling languages\nand teaching methodologies.",
  "references": [
    "Rick Adcock, Lillian Cassel, 'Curriculum guidelines for graduate degree programs in software engineering', , 2009",
    "Mark Ardis, Mark Sebern, Willem Visser, 'SE 2014: Curriculum guidelines for undergraduate degree programs in software engineering', Computer, ['2015', '2015']",
    "given-names, surname, 'A modelbased approach to gamify the learning of modeling', CEUR Workshop Proceedings., 2017"
  ],
  "keywords": [
    "cid",
    "UML models",
    "models",
    "creating UML models",
    "UML",
    "Association",
    "Neutral",
    "creating UML",
    "Model",
    "ModelGame",
    "Studies",
    "DesignModel",
    "EdWilsonJniorandKleinnerFarias",
    "UML models play",
    "UML models developed",
    "AQualityModelforGamifiedSoftwareModelingLearning",
    "Challenges",
    "Partiallydisagree",
    "Quality",
    "Quality Model"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=110zBy8XuDmzU-t_G6aoOITeOgBhxHAnu"
}
{
  "id": 7,
  "title": "AI Model for Computer games based on Case Based Reasoning and AI Planning",
  "authors": [
    "Vlado Menkovski Athens Information Technology"
  ],
  "institutions": [
    "General Terms Algorithms",
    "Peania"
  ],
  "resume": "Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.",
  "content": "Categories and Subject Descriptors I . 2 . 1   [ A p p l i c a t i o n s   a n d   E x p e r t   S y s t e m s ] :   G a m e s 1. Introduction The goal of this effort is to explore a model for design and\nimplementation of an AI agent for turn based games. This model\nprovides for building more capable computer opponents that rely\non strategies that closely resemble human approach in solving\nproblems opposed to classical computational centric heuristics in\ngame AI. In this manner the computational resources can be\nfocused on more sensible strategies for the game play.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. To copy\notherwise, or republish, to post on servers or to redistribute to lists,\nrequires prior specific permission and/or a fee. DIMEA?08, September 10?12, 2008, Athens, Greece. Copyright 2008 ACM 978-1-60558-248-1/08/09... $5.00 Dimitrios Metafas\nAthens Information Technology\n0.8km Markopoulou Ave. 2. Game Trees and Minimax xref #text 3. AI Planning for building Game Trees 3.1.1 AI Planning AI Planning also referred as Automated Planning and\nScheduling is a branch of Artificial Intelligence that focuses on\nfinding strategies or sequences of actions that reach a predefined\ngoal . Typical execution of AI Planning algorithms is by\nintelligent agents, autonomous robots and unmanned vehicles.\nOpposed to classical control or classification AI Planning results\nwith complex solutions that are derived from multidimensional\nspace. AI Planning algorithms are also common in the video game\ndevelopment. They solve broad range of problems from path\nfinding to action planning. A typical planner takes three inputs: a\ndescription of the initial state of the world, a description of the\ndesired goal, and a set of possible actions. Some efforts for\nincorporating planning techniques for building game trees have\nalso shown up, similar to the approach explored in this effort. In\naddition Cased Based Reasoning  techniques are also gathering\npopularity in developing strategies based in prior knowledge\nabout the problems in the games. One of the benefits from\nHierarchical Task Network (HTN)  planning is the possibility\nto build Game Trees based on HTN plans; this method is\ndescribed in the following section. 3.2 Game Trees with AI Planning An adaptation of the HTN planning can be used to build\nmuch smaller and more efficient game trees. This idea has already\nbeen implemented in the Bridge Baron a computer program for\nthe game of Contact Bridge . Computer programs based on Game Tree search techniques\nare now as good as or better than humans in many games like\nChess  and checkers , but there are some difficulties in\nbuilding a game tree for games that have imperfect information\nand added uncertainty like card or games with dice. The main\nproblem is the enormous number of possibilities that the player\ncan choose from in making his move. In addition some of the\nmoves are accompanied with probabilities based on the random\nelements in the games. The number of possible moves\nexponentially grows with each move so the depth of the search\nhas to be very limited to accommodate for the memory\nlimitations. The basic idea behind using HTN for building game trees is\nthat the HTN provides the means of expressing high level goals\nand describing strategies how to reach those goals. These goals\nmay be decomposed in goals at lower level called sub-goals. This\napproach closely resembles the way a human player usually\naddresses a complex problem. It is also good for domains where\nclassical search for solution is not feasible due to the vastness of\nthe problem domain or uncertainties.\n3.2.1 Hierarchical Task Networks The Hierarchical Task Network, or HTN, is an approach to\nautomated planning in which the dependency among actions can\nbe given in the form of networks  [Figure 1]. A simple task network (or just a task network for short) is an\nacyclic digraph in which U is the node set, E is the\nedge set, and each node contains a task . The edges of\ndefine a partial ordering of U. If the partial ordering is total, then\nwe say that is totally ordered, in which case can be written as\na sequence of tasks . Buy milk\nGo to (shop) Purchase Go to (home)\nA Simple Task Network (STN) method is a 4-tuple of its name,\ntask, precondition and a task network. The name of the method\nlets us refer unambiguously to substitution instances of the\nmethod, without having to write the preconditions and effects\nexplicitly. The task tells what kind of task can be applied if the\npreconditions are met. The preconditions specify the conditions\nthat the current state needs to satisfy in order for the method to be\napplied. And the network defines the specific subtasks to\naccomplish in order to accomplish the task. A method is relevant for a task if the current state satisfies the\npreconditions of a method that implements that task. This task can\nbe then substituted with the instance of the method. The\nsubstitution is basically giving the method network as a solution\nfor the task. If there is a task ?Go home? and the distance to home is 3km\n[Figure 2] and there exists a method walk-to and this method has a\nprecondition that the distance is less than 5km, then a substation\nto the task ?Go home? can be made with this method instance.\nIf the distance is larger than 5km another method instance needs\nto be substituted [Figure 3]. An STN planning domain is a set of operations O and a set of\nmethods M. A STN planning problem is a 4-tuple of the initial\nstate S0, the task network w called initial task network and the\nSTN domain. A plan is a solution for a planning\nproblem if there is a way to decompose w into ? if ? is executable\nand each decomposition is applicable in the appropriate state of\nthe world. The algorithm that is capable to decompose these\nnetworks into plans is called Total-forward-decomposition (TFD)\n or Partial-forward-decomposition (PFD). However there are\ncases where one does not want to use a forward-decomposition\nprocedure. HTN planning is generalization of STN planning that\ngives the planning procedure more freedom about how to\nconstruct the task networks. In order to provide this freedom, a bookkeeping mechanism\nis needed to represent constraints that the planning algorithm has\nnot yet enforced. The bookkeeping is done by representing the\nunenforced constraints explicitly in the task network. The HTN generalizes the definition of a task network in\nSTN. A task network is the pair where is a set of\ntask nodes and C is a set of constraints. Each constraint in C\nspecifies a requirement that must be satisfied by every plan that is\na solution to a planning problem. The definition of a method in HTN also generalizes the\ndefinition used in STN planning. A HTN plan is a 4-tuple of\nname, task, subtasks, and constraints. The subtasks and the\nconstraints form the task network. The HTN planning domains are\nidentical to STN planning domains except they use HTN methods\ninstead of STN methods. Compared to classical planners the primary advantage of\nHTN planners is their sophisticated knowledge representation and\nreasoning capabilities. They can represent and solve a variety of\nnon-classical planning problems; with a good set of HTNs to\nguide them, they can solve classical planning problems orders of\nmagnitude more quickly than classical or neoclassical planners.\nThe primary disadvantage of HTN is the need of the domain\nauthor to write not only a set of planning operators but also a set\nof methods.\n3.2.2 HTN Planning in building Game Trees For a HTN planning algorithm to be adapted to build game\ntrees we need to define the domain (set of HTN methods and\noperators) which is the domain of the game. This is in some sense\na knowledge representation of the rules of the game, the game\nenvironments and possible strategies of game play. In this domain the game rules as well as known strategies to\ntackle specific task are defined. The implementation of Game\nTree building with HTN is called Tignum2 . This\nimplementation uses a procedure similar to\nforwarddecomposition, but adapted to build up a game tree rather than a\nplan. The branches of the game tree represent moves generated by\nthe methods. Tignum2 applies all methods applicable to a given\nstate of the world to produce new states of the world and\ncontinues recursively until there are no applicable methods that\nhave not already been applied to the appropriate state of the\nworld. In the task network generated by Tignum2, the order in which the\nactions will occur is determined by the total-ordering constraints.\nBy listing the actions in the order they will occur, the task\nnetwork can be ?serialized? into a game tree [Figure 4] [Figure 5]. 4. Case Based Reasoning in Game Strategies  4.1 Case Based Reasoning Case-based reasoning (CBR) is a well established subfield of\nArtificial Intelligence (AI), both as a mean for addressing AI\nproblems and as a basis for standalone AI technology.\nCase-based reasoning is a paradigm for combining\nproblemsolving and learning that has became one of the most successful\napplied subfield of AI of recent years. CBR is based on the\nintuition that problems tend to recur. It means that new problems\nare often similar to previously encountered problems and,\ntherefore, that past solutions may be of use in the current situation\n. CBR is particularly applicable to problems where earlier cases are\navailable, even when the domain is not understood well enough\nfor a deep domain model. Helpdesks, diagnosis or classification\nsystems have been the most successful areas of application, e.g.,\nto determine a fault or diagnostic an illness from observed\nattributes, or to determine whether or not a certain treatment or\nrepair is necessary given a set of past solved cases .\nCentral tasks that all CBR methods have to deal with are : \"to\nidentify the current problem situation, find a past case similar to\nthe new one, use that case to suggest a solution to the current\nproblem, evaluate the proposed solution, and update the system by\nlearning from this experience. How this is done, what part of the\nprocess that is focused, what type of problems that drives the\nmethods, etc. varies considerably, however\". While the underlying ideas of CBR can be applied\nconsistently across application domains, the specific\nimplementation of the CBR methods ?in particular retrieval and\nsimilarity functions? is highly customized to the application at\nhand. 4.2 CBR and Games M a n y   d i f f e r e n t   i m p l e m e n t a t i o n s   o f   C B R   e x i s t   i n   g a m e s . \n C B R   t e c h n o l o g y   i s   n i c e l y   s u i t e d   f o r   r e c o g n i z i n g   c o m p l e x \n s i t u a t i o n s   m u c h   e a s i e r   a n d   m o r e   e l e g a n t   t h a n   t r a d i t i o n a l   p a r a m e t e r \n c o m p a r i s o n   o r   f u n c t i o n   e v a l u a t i o n .   T h e r e   a r e   e s p e c i a l l y   e v i d e n t \n c a s e s   i n   r e a l   t i m e   s t r a t e g i e s   w h e r e   d i f f e r e n t   a t t a c k   a n d   d e f e n s e   o f \n g l o b a l   s t r a t e g i e s   a r e   n i c e l y   d e f i n e d   b y   C B R   d a t a s e t s   a n d   l a t e r   u s e d \n i n   t h e   r u n n i n g   g a m e s .   A l s o   i n t e l l i g e n t   b o t s   b e h a v i o r   i s   a l s o \n a n o t h e r   t y p i c a l   e x a m p l e .   D e p e n d i n g   o n   t h e   n u m b e r   o f   e n e m y   b o t s \n t h e   l a y o u t   o f   t h e   t e r r a i n   a n d   p o s i t i o n   o f   h u m a n   p l a y e r s   t h e   C B R \n s y s t e m   f i n d s   t h e   c l o s e s t   C B R   c a s e   a n d   e m p l o y s   t h a t   s t r a t e g y \n a g a i n s t   t h e   h u m a n   p l a y e r s   w h i c h   i n   p r i o r   e v a l u a t i o n   w a s   p r o v e d   t o \n b e   h i g h l y   e f f i c i e n t . 5. Game Trees with AI Planning ? Tic-tac-toe In order to show the expressive power of AI Planning in\ndefining strategies for games, and the use of these plans to build\nGame Trees I implemented an algorithm that builds Game Trees\nfor the Tic-Tac-Toe game. The game tree of Tic-Tac-Toe shows 255,168 possible\ngames of which 131,184 are won by X (the first player), 77904\nare won by O and the rest 46,080 are draw . All these games\ncan be derived from building a complete Game Tree. Even though it is possible to build a complete game tree of\nTic-tac-toe it is definitely not an optimal solution. Many of the\nmoves in this tree would be symmetrical and also there are a many\nmoves that would be illogical or at least a bad strategy to even\nconsider. So what strategy should X (the first player) choose in order\nto win the game? There are few positions that lead to certain victory. These\npositions involve simultaneous attack on two positions so the\nother player could not defend, basically the only trick in\nTic-TacToe. Position 2 lead to victory if two of the three fields: top right\ncorner, bottom right corner and bottom middle are free [Figure ].\nAnd in the third position if the two of center, middle top and\nmiddle left are available the position is a certain victory. There are many different arrangements of the player?s tokens\nthat give equivalent positions as these three positions. By using\nplanning we do not need to consider all possible layouts but just\nconsider these three similar to what a human would consider. 5.1 Hierarchical Task Network Top level task is Play [Figure 12]. This is a complex task and\ncan be derived into: Win, Block, Tie or Search for Plan. The\nSearch for plan is derived to both Plan 1 and Plan 2 or Plan 3 and\nPlan 4, which later leads to a call for the opponent?s move and a\nrecursive call to Play. This HTN when executed will result with plans for possible\ngame scenarios. By creating nodes from each position and linking\nthem with branches with the move of the player we create a game\ntree for the Tic-tac-toe game over which we can run the minimax\nalgorithm. This set up with 7 plans with 3 target strategies creates a tree\nfor Tic-tac-toe which considers all possible moves for the second\nplayer with only 457 games, 281 of which X wins 176 are draw\nand 0 where the second opponent wins. This is a significant\nreduction over the 255, 168 possible games with a complete game\ntree. These reductions can be very useful for devices with limited\ncomputing capabilities but also we prove a very important point\nthat planning can be very efficient if designing meaningful game\ntrees by applying reasoning very similar to human player\nreasoning. Further improvements to the game tree are also possible if\nthe opponents moves are also planned, in other words if we drop\nall the meaningless and symmetrical moves of the opponent. 6. Game AI in Monopoly  6.1 Overview of the AI Implementation The AI agent is responsible for the moves of the artificial\nplayers in the game. The core principle of the AI agent is building\na Game Tree with all the sensible moves that all the players would\nmake from the current point of time forward. Then using the\nminimax algorithm the agent selects the move that in the future\nwould bring the computer player most favorable game position\nwith the highest probability. Building a Game Tree in this game\nthat would be big enough to consider sufficient number of moves\nis obstructed by the vastness of possible moves in combination\nwith all the possible random landings of the dice. The number of\nnodes of the game tree exponentially grows at each level. To\ntackle this problem the AI agents incorporates two already\ndiscussed technologies: Case Based Reasoning and AI Planning. The technologies are employed in the following manner.\nFirst the agent searches the CBR database to find the case with the\nlargest similarity with the current state of the board. This case is\nassociated with a playing strategy. The strategy consists of goal\nthat the planner needs to build plans for, and the plans consist of\nconsecutive player moves that bring the player to that goal. This\nway only moves that are part of that strategy are considered, those\nbeing a small fraction of the overall possible moves the number of\nedges of the game tree at each level decreases immensely. At each level of the game tree the model considers the moves\nof a single player. After the strategies of the AI player are\nconsidered the response to those strategies needs to be considered\nby the opponent(s). The move of the opponent(s) depends of the\nprobability distribution of the dice as well as the strategy of the\nplayer. A more general strategy needs to be implemented for the\nopponent?s (human player) moves since we cannot be aware of\nthe expertise of the opponent. This general strategy would bring\nmore plausible moves than the focused strategy of the AI player. After covering all opponents the agent comes back to\ndeducting a feature move of the computer player by using the\nCBR selected plan strategy. After creating several loops of\nstrategies and reaching a reasonable size of a Game Tree taking\ninto account the memory limits and the rapidly decreasing\nprobabilities that the move is possible due to the distribution of\nthe dice the building of the Game Tree stops. Then the minimax\nalgorithm searches the Game Tree and decides on the most\nfavorable move for the AI player using the minimax algorithm.\nThe process is repeated each time the AI player is up. Buying, auctioning and trading game moves are always\naccompanied by return of investment calculations in making the\nplans. These calculations represent adaptation of the more general\nplanning associated with the cases in the CBR database. These\nadaptations are necessary due to the fact that the cases do not\nidentically correspond to the situation on the table. In addition\ncalculating the game position value of each node of the game tree\nis done by heuristic functions that incorporate economic\ncalculations of net present value, cash, and strategic layout and so\non. For example railroads in monopoly are known to be\nstrategically effective because they bring constant income even\nthough the income can be smaller than building on other\nproperties. 6.2 Details on the CBR Implementation The implementation of the CBR is by using the JColibri2\nplatform. JColibri2 is an object-oriented framework in Java for\nbuilding CBR systems that is an evolution of previous work on\nknowledge intensive CBR . For this implementation we need to look into three particular\nclasses of the JColibri2 platform. The StandardCBRApplication,\nConnector, CBRQuery. For a JColibri2 implementation the\nStandardCBRApplication interface needs to be implemented. The CBR cycle executed accepts an instance of CBRQuery.\nThis class represents a CBR query to the CBR database. The\ndescription component (instance of CaseComponent) represents\nthe description of the case that will be looked up in the database.\nAll cases and case solutions are implementing the\nCaseComponent interface. The JColibri2 platform connects to the CBR database via a\nConnector class. Each connector implements all the necessary\nmethods for accessing the database, retrieval of cases, storing and\ndeletion of cases. This implementation uses a custom XML\nstructure for holding the CBR cases. Since the game will not\nupdate the CBR database only read it, a XML solution satisfies\nthe needs. The XML file to a certain extent is similar to the XML\nrepresentation of the board. We are interested in finding one\nCBRCase that is the most similar case to the situation in the game\nat the time of the search. This procedure is done in the cycle\nmethod of the CBRApplication. The JColibri2 CBR comparison is\ndone by Nearest Neighbor (NN) search method. JColibri2 offers implementations for NN search algorithms\nof simple attributes. These implementations are called local\nsimilarities. For complex attributes like in our case global\ncustomized similarity mechanisms need to be implemented. The MonopolyDescription class [Figure 13] is basically a\nserialization of the GameState. It holds all the information about\nthe state of the board, the players, their amount of cash etc. On the other hand the MonopolySolution class holds the\nthree particular attributes that are needed for the planning, the\nplanning Domain, State and TaskList. The game is implemented by using the\nModel-ViewController software development pattern. The controller is\nresponsible for implementing the game rules and handling all of\nthe events in the game like roll of dice, input commands for\ntrading, auctioning and etc from the players. The View layer is\nresponsible for displaying the board and all of the input widgets\non to the game screen, and the models are data structures\nrepresenting the game state [Figure 14].\n6.2.1 Complex Similarity representation in CBR The similarity measurement part of the Nearest Neighbor\nalgorithm JColibri2 is implemented by implementing the\nLocalSimiralrityFunction and the GlobalSimiralityFunction\ninterface. A local similarity function is applied to simple attributes\nby the NN algorithm, and a global similarity function is applied to\ncompound attributes. In the case of our implementation the\nattributes of the MonopolyDescription are compound attributes\ndescribing the state of the board, number of players, amount of\ncash for every player and etc. Since MonopolyDescription is a\ncustom CaseComponent a global similarity function needs to be\nimplemented to accurately find the distance between different\nCBR cases. The similarity mechanism is inseparable core element of the\nCBR system. This mechanism represents how the CBR decides\nwhich strategy is best suited for the particular situation by\ncalculating the distance or similarity to other cases in the\ndatabase. For the monopoly implementation we need to consider\nseveral basic strategies. Monopoly is based on investing in\nproperties and receiving revenues from those investments. One of\nthe basic strategies of the game is to build a set of properties that\nwill bring constant income larger than the one of the opponents.\nSo in time the opponents will have to declare bankruptcy. But on\nthe other hand over investment can lead to too stretched resources\nwith low income that will eventually drove the player to\nbankruptcy. To decide on these two we need a clear separation\ninto two groups of cases in the CBR database. The first group of\ncases will represent a situation on the board where the player has\nsignificant income per loop formed of one or more color group\nproperties, maybe railroads, some buildings on them and so on. It\nis important to note that in this case the player is better situated\nthan his opponents so he only needs to survive long enough to win\nthe game. In the other group of cases either the opponent is not\nwell positioned on the board or its opponents are better situated.\nIn this case further investments are necessary to improve the\nsituation so the player can have a chance of winning in the long\nrun. These metrics can be owning color groups, valuing groups of\nrailroads, evaluating the other opponents as well, and considering\nthe amount of cash. As it is obvious in monopoly the number of\nstreets is not as nearly as important as the combination of streets\nthe player owns. It is also important to note that one CBR case\ndoes not hold only a single strategy in place, but its solution can\nhave multiple different strategic goals. For example one CBR case\nmight simultaneously say buy this land to form a color group but\nalso trade some other unimportant property to increase cash\namount. The cases do not represent all possible combinations of board\npositions. They are only representation of typical game scenarios.\nThe CBR Case solutions do not give exact instructions in general\nbut rather strategic goals. For example one CBR Solution might\nsay trade the streets that you only have one of each for the ones\nthat you have two of that color already. Then the planner based on\nthe situation on the board needs to decompose this high level task\nto a low level operations. Like offer \"Mediterranean Avenue\" for\n\"Reading Railroad\" and offer $50. The exact amounts and actual\nstreets are left to the planer to evaluate. The monopoly CBR database is currently in development on\na monopoly clone game called Spaceopoly. The cases are\narchitected based on human player experience and knowledge.\nThere is a plan of making a number of slightly different strategies\nthat differ on the style of playing and then running simulation\ntests that would determine the particular validity of each database\nas well as validity of certain segments of the strategy or even\nparticular cases in the database. The actual execution of the strategies will not differ from\nstrategy to strategy since the plan execution is more related to the\nstructure and rules of the game than to the actual playing strategy. 6.3 Details on the Planning Implementation xref #text 7. Conclusion Even though the results from the CBR database are not\ncomplete at this time partial strategies are implemented as cases\nand recognized during game play by the CBR system. These\nsmaller local strategies coupled with more global higher level\nstrategies that are particularly important at the beginning of the\ngame would form a complete CBR database and represent a\nknowledge engineered style of playing of the AI player. The AI Planning approach is a proven method by the\ntic-tactoe experiment and is suitable for implementing the strategies\nassociated with the CBR cases. This approach in general benefits from both technologies,\nCBR as well as AI Planning and comprises an elegant solution.\nEven though AI Planning can be enough as a single technology\nfor some simpler problems like tic-tac-toe the complexity of\nMonopoly would mean that the Planner would have to incorporate\nlarge and complex domain and a very big state model. The CBR\napplication helps reduce this complexity by focusing the planning\non smaller domain of the game. Basically the CBR reduces the\noverall goal of the play (wining the game) to smaller more\nconcrete goals suitable to the particular state of the game, thus\nreducing the need for global planning strategies and complex\nplanning domain. Furthermore this symbiosis of technologies gives way for\nmore precise and finely tuned strategies which can be difficult to\ninclude into global plan for the whole game. One simple example\nfor the Monopoly game would be this: Sometimes it?s better to\nstay in jail because rolling double increases the probability of\nlanding on some field (two, four, six, eight, ten or twelve steps\nfrom the jail) that can be of great importance to the rest of the\ngame. These and similar small local strategies can be easily\nrecognized by similar cases in the CBR database. In other words the system is flexible enough so that new\nstrategies can be incorporated easily missing strategies can be also\nrecognized by the distance metrics as well as wrong assumptions\nin the strategies can be easily recognized. One other important property of the system is that is highly\nconfigurable. The game its self can be diversely different\ndepending on the configuration of the board. Even though the\nplatform is restricted to Monopoly type of games, changing the\nlayout and values of the fields effectively brings completely\ndifferent properties of the game. In addition the CBR database\nrepresents the entire experience of the AI Player. It can be filled\nwith rich set of strategies or even configured with different flavors\nof difficulties of play, this of course coupled with the domain of\nthe planner which can differ from a case to a case as well. 8. Future Work Further exploration of this technology would go towards\ncomplete implementation of an AI aware agent for monopoly.\nInitial results from the local cases with more specific strategies\nshow CBR as a capable tool for representing expertise in playing\nthe game. Completing the more general strategies and coupling\nthem with the planning domain will give precise results on the\nbenefits from this architecture. There is also need for exploring the planning of strategies of\nopponents. This task is to some extent different because we\ncannot always expect the opponent to select the best move we\nthink. In the Tic-tac-toe example all possible moves of the\nopponent were taken into consideration, if we used the same\nplanner for the opponent only tie games would result from the\ngame tree. In other words mistakes of the players also need to be\nconsidered. The CBR Platform brings other functionalities well worth of\nexploring as well. The revision stage of the JColibri2 platform is\nbasically capable of fine tuning strategies or even developing new\nstrategies for the games. A well written underlying AI planning\nmodel with a capable feedback of the game tree evaluation back\nto the CBR revision capability can be an interesting concept in\nautomatic experience acquisition for the AI model. There are also many other fields were combined CBR and\nplanning approach can be incorporated into a problem solution.\nThis combination is analogous in a big extent to a human way of\nreasoning. People in addition to logic of reasoning in situations\nwith lack of information rely to planning strategies and prior\nexperience, exactly the intuition behind CBR ? AI Planning\narchitecture. 9. ACKNOWLEDGMENTS W e   w o u l d   l i k e   t o   t h a n k   P r o f .   S o f i a   T s e k e r i d o u   f o r   h e r \n i n v o l v e m e n t   i n   t h e   v a l u a b l e   d i s c u s s i o n s   w e   h a d   o n   t h e   t o p i c   o f \n C B R .",
  "keywords": [
    "Game Tree",
    "game trees",
    "game",
    "building game trees",
    "CBR",
    "Game Trees game",
    "Planning",
    "games",
    "CBR database",
    "Digital Interactive Media",
    "Task Network",
    "Tree",
    "cid",
    "Task",
    "Game Trees based",
    "player",
    "CBR case",
    "HTN planning",
    "Figure",
    "HTN"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1h6mJjF-bJ-jzLDfgQgZCTo7V68sQTg3Z"
}
{
  "id": 15,
  "title": "Improved stochastic subset optimization method for structural design optimization Mohd Aman Khalid , Sahil Bansal *",
  "authors": [
    "Mohd Aman Khalid",
    "Sahil Bansal"
  ],
  "institutions": [
    "Department of Civil Engineering, Indian Institute of Technology Delhi"
  ],
  "resume": "A B S T R A C T The Stochastic Subset Optimization (SSO) algorithm was proposed for optimal reliability problems that minimizes the probability of system failure over the admissible space for the design parameters. It is based on the simulation of samples of the design parameters from an auxiliary Probability Density Function (PDF) and exploiting the information contained in these samples to identify subregions for the optimal design parameters within the original design space. This paper presents an improved version of SSO, named iSSO to overcome the shortcomings in the SSO. In the improved version, the Voronoi tessellation is implemented to partition the design space into non-overlapping subregions using the pool of samples distributed according to the auxiliary PDF. A double-sort approach is then used to identify the subregions for the optimal design. The iSSO is presented as a generalized design optimization approach primarily tailored for the stochastic structural systems but also adaptable to deterministic systems. Several optimization problems are considered to illustrate the effectiveness and efficiency of the proposed iSSO.",
  "content": "- A   R   T   I   C   L   E   I   N   F   O 1. Introduction Structural optimization may be defined as the rational establishment\nof an economical structural design with the available resources while\nsatisfying specific performance criteria. In general terms, the economy\nmay be characterized by minimum weight, minimum cost, maximum\nutility, or even minimum probability of failure. Broadly, structural\noptimization can be categorized into deterministic and stochastic\noptimization . The classical statement of unconstraint deterministic\noptimization is mathematically expressed as:\nminimize : g(?)\n???\n(1)\nwhere, ? = [?1??n? ]T ? ??Rn? is a set of deterministic adjustable\nparameters that define the structural design, referred to herein as design\nparameters, g(?) : Rn? ?R is the objective function to be minimized, and\n? denotes the bounded admissible design space. The deterministic\nconstraints can be considered by the appropriate definition of the\nadmissible design space ? for deterministic design parameters ?, as\nmentioned in . In the deterministic structural optimization problem,\nthe uncertainties in parameters are ignored, and fixed values are\nassumed for all the parameters. There are numerous optimizations\napproaches available in the literature, however, but it?s worth noting\nthat no one-size-fits-all optimization approach is ideal for all sorts of\nproblems . The choice of optimization method is often determined\nby the specific characteristics of the problem, such as its complexity,\ndimensionality, constraints, and the nature of the objective function. As\na result, there is always a scope for new approaches to be developed or\nthe adaptation of existing methods to better suit specific problem\nclasses. A detailed discussion of deterministic optimization approaches can\nbe found in the literature . In any practical situation, several parameters, such as loadings,\nstructural parameters, geometric parameters, operation conditions, etc.,\nare either not known at the design stage or are subjected to random\nlfuctuations that give rise to performance variability and affect the\nperformance of a system . These parameters are characterized as\nuncertain parameters. Deterministic structural optimization discards the\nimpact of uncertainty and can result in improper design. Therefore, it is\ndesirable to account for the uncertainty in the parameters during\noptimization by using the rational methods of probabilistic structural\nanalysis . Such structural optimization that accounts for\nuncertainties is called stochastic optimization . Although stochastic\noptimization refers to any method that employs randomness within\nsome communities, in this paper, we will only consider settings where\nthe objective function is random. Stochastic optimization or optimal\ndesign under uncertainty has been widely applied in many practical\nengineering fields, including civil engineering structures ,\ncomposite structures , and vehicles . Consider an engineering system that involves deterministic design\nparameters ?, and uncertain variables ? = [?1??n? ]T ? ??Rn? following\na joint PDF p(?|?), where ? denotes the parameter space of the\nuncertain variables. The classical statement of stochastic optimization is\nmathematically expressed as:\nminimize : E?[h(?, ?)]\n???\n(2)\nwhere, h(?, ?) : Rn?+n? ?R is the structural performance function, and\nE?[ ? ] denotes expectation with respect to the PDF for ?. Note that the\nobjective function in the optimization problem in (2) is the expectation\nE?[h(?, ?)] which is a deterministic function. It?s worth mentioning that\nstochastic optimization may also involve other stochastic measures such\nas variance or quantile values. However, these stochastic measures can\nrarely be evaluated analytically; therefore, several methods have been\nproposed for solving stochastic optimization problems. These\nspecialized methods include, for example, sample average approximation,\nstochastic approximation, stochastic subset optimization, and\napproaches based on the use of Taylor series expansion ,\nresponse surface, and metamodels . Specific to structural\nengineering, there are two broad categories of problems involving design\noptimization under uncertainty : Reliability-Based Design\nOptimization (RBDO) and Robust Design Optimization (RDO). The\nobjective of RBDO is to find an optimal solution that minimizes some\ndeterministic, objective function under observance of probabilistic\nconstraints instead of conventional deterministic constraints .\nOn the other hand, RDO aims to find an optimal solution that is\ninsensitive (or less sensitive) to input variations. It improves the design\nquality by minimizing performance variation without eliminating\nuncertainty . Taflanidis and Beck  introduced a novel algorithm for optimal\nreliability problem, the so-called SSO. SSO involves formulating an\naugmented problem where the design parameters are artificially\nconsidered uncertain and defining an auxiliary PDF that includes the\nstructural performance function and the PDF of the uncertain variables.\nNext, SSO involves generating a pool of samples distributed according to\nthis auxiliary PDF and identifying a subregion in the original design\nspace, which, on average, improves the value of the objective function.\nBy repeating this procedure several times, it is possible to determine at\neach step a smaller subregion in the design space, which in turn\nimproves the value of the objective function. Ultimately, this subregion\nwill be sufficiently small to directly identify the optimal solution or\nprovide sufficient information to launch another optimization\nalgorithm, such as the sample average approximation or stochastic\napproximation. The implementation of the SSO method closely resembles the\nSubset Simulation (SS) algorithm  for reliability analysis. Since SSO\nis based on simulation, it can deal with linear or nonlinear problems and,\nat least theoretically, an unbounded number of design parameters. The\nnumerical effort for solving a given optimization problem is\nindependent of the number of uncertain variables, and it grows linearly with the\nnumber of design parameters. Since the introduction of SSO, several extensions of SSO have been\nproposed. An extension of SSO termed Non-Parametric SSO, which\nadopts kernel density estimation to approximate the objective function,\nis presented in . In , efficient integration of the Moving Least\nSquares approximation within SSO is introduced to reduce the\ncomputational effort in SSO. In , an augmented formulation is presented for\nthe RDO of structures using SSO. SSO or its variants have also been\napplied to solve structural optimization problems. SSO has been used for\nreliability optimization and sensitivity analysis in system design in .\nA framework for RDO of Tuned Mass Dampers (TMD) by SSO is\ndiscussed in . Even though SSO has proved to be efficient for meeting\nvarious challenging optimization problems, it has two shortcomings.\nFirst, the effectiveness of SSO is dependent on the correct selection of\nthe geometrical shape of the admissible subsets. Here, it is pertinent to\nmention that choosing a geometrical shape that effectively investigates\nthe sensitivity of the objective function to each design variable is\nessential. The shapes, such as hyper-rectangle and hyper-ellipse are\nsuggested in the literature for the admissible subsets. However, as shown\nlater via the illustrative example, these shapes fail to include the optimal\nsolution in cases with complex design spaces or problems with multiple\noptimal solutions. And second, identifying the optimal subset that\ncontains the smallest volume density involves a non-smooth optimization\nproblem which is quite challenging. In this paper, an improved version of SSO is developed to overcome\nthe shortcomings of the original SSO. This new version of the algorithm,\nas mentioned earlier, is named iSSO (improved SSO). Voronoi\ntessellation is implemented to partition the design space into non-overlapping\nsubregions (a set of Voronoi cells) using the pool of samples\ndistributed according to the auxiliary PDF. The admissible set (a set of all\nadmissible subregions) is then defined as a set containing all subsets of\nthe set of Voronoi cells. This approach is able to capture the regions with\nlower objective function values even if they are disjointed or when the\ndesign space is complex. The details of the Voronoi tessellation are\npresented in Appendix A. A double-sort algorithm is then implemented\nto identify the optimal subset containing the smallest volume density. In the next section, the original SSO is reviewed. Section 3 presents\nthe general theoretical and computational framework for the iSSO\nalgorithm. Section 4 considers several optimization problems to illustrate\nthe effectiveness and efficiency of the proposed iSSO algorithm. 2. Original stochastic subset optimization In SSO, say at the i + 1th iteration, the design space is represented by\na subset I(i), where I(i) ? I(i 1)??? ? I(0) ? ?. Following the augmented\nformulation concept initially discussed in  for RBDO, the design\nparameters ?, are artificially considered uncertain variables with a\nprescribed PDF p(?|I(i)) over the design space I(i) . For convenience,\np(?|I(i)) = 1/V(i) is considered, where V(i) is the volume of I(i). In this\nsetting of the augmented stochastic design problem, the auxiliary PDF is\ndefined as: ?\n? ?, ??I(i))= ?\nh(?, ?)p ?, ??I(i)) E?,?[hs(?, ?)] ?\n?h(?, ?)p ?, ??I(i))\nE?,?[h(?, ?)] = ? ?\nwhere, p(?, ?|I(i)) = p(?|?)p(?|I(i)). Note that if h(?, ?)? 0, it must be\nsuitably transformed to ensure that ?(?, ?|I(i)) ? 0. One way to do this is\nto define hs(?,?) = h(?, ?) s, since E?[hs(?,?)] = E?[h(?,?)] s, that is,\nthe two expected values differ only by a constant, and the optimization\nof the expected value of h( ? ) is equivalent, in terms of the optimal design\nchoice, to optimization for the expected value for hs( ? ). In the above\nequation, the denominator is a normalizing constant given by:\n? ? ?\nh(?, ?)p ?, ??I(i))d?d?. Although this expected value is not explicitly needed, it can be\ndetermined using any state-of-the-art stochastic simulation method. The\nobjective function E?[hs(?, ?)] in this context of the auxiliary PDF is\nexpressed as: ?\n? ??I(i))\nE?[h(?, ?)] = p ???I(i))E?,?[h(?, ?)], ?\n? ??I(i))=\nwhere, the marginal ?(?|I(i)) is given by:\n?\nI(i)\n?(?, ?)d?.\n(3)\n(4)\n(5)\n(6) In (5), since E?,?[h(?, ?)] is a normalizing constant, minimization of\nE?[h(?, ?)] is equivalent to minimization of J(?), which is equal to:\n?\nJ ???I(i))= E?[hs(?, ?)] = ? ???I(i))). E?,?[hs(?, ?)] p ??I(i)\n(7) The estimation of the marginal ?(?|I(i)) in (7) is necessary to\nminimize J(?|I(i)). Analytical approximations of ?(?|I(i)) based on kernel\ndensity approaches or the maximum entropy method might be arduous\nin case of complex problems, such as when design parameters n? are\nlarge, or the sensitivity for some design parameters is complex . In\nthe SSO framework, such approximation of ?(?|I(i)) is avoided. In SSO,\nsamples distributed as ?(?|I(i)) are obtained, and the information in\nthese samples is exploited to identify a smaller subset of the design space\nwith a high likelihood of containing the optimal design parameters.\nSamples distributed as ?(?, ?|I(i)) are obtained using any appropriate\nstochastic sampling algorithm, such as Markov Chain Monte Carlo\n(MCMC) sampling . The ? component of these samples then\ncorresponds to samples from the marginal distribution ?(?|I(i)). The sensitivity of objective function E?[hs(?, ?)] to ? is determined by\nevaluating the average value (or equivalently volume density) of J(?|\nI(i)) over any subset I in I(i), which is denoted by H(I) and defined as:\n? ? ? ?|I(i)) ?\nH(I) = V1I I J ?|I(i))d? = V1I I p ?|I(i))d? = VVI(Ii) I ? ?|I(i))d? (8)\nwhere, VI is the volume of subset I. Based on the samples distributed\naccording to ?(?|I(i)) belonging to I(i), an estimate of H(I) is provided by:\nwhere, NI(i) is the number of samples distributed as ?(?|I(i)) belonging to\nI(i), and NI denotes the number of samples from ?(?|I(i)) belonging to the\nI (NI < NI(i 1) since I?I(k 1)). Say NI = p0NI(i 1) . A smaller value of ?\nresults in a faster decrease in the size of the identified subsets but with\npoorer accuracy. The use of ? equal to 0.1 - 0.2 is suggested in the\nliterature . A deterministic optimization, based on the estimate H(I) of H(I), is\nnext performed to identify the subset I ? A(?i+1), where A(?i+1) is a set of\nadmissible subsets in I(i), that contains the smallest volume density NI/\nVI, that is,\nI(i+1) = argminH(I) = argI?mA(?iin+1)NI I?A?\nA(i+1) = {I?I(i) : ? = NI /N(i)}\n?\n/ VI . The effectiveness of SSO is dependent on the correct selection of the\ngeometrical shape and size of the admissible subsets. Choosing a\ngeometrical shape that effectively investigates the sensitivity of the\nobjective function to each design variable is essential. The optimization\nin (10) determines the subset with the smallest average value of J(?|I(i))\n(or equivalently E?[hs(?, ?)]) within the admissible set A(?i+1). I(i + 1) is a\nsubset of the design space I(i) with a high likelihood of containing the\noptimal design parameters. The above steps are repeated until the\nstopping criterion is met. This way, SSO adaptively converges to a\nrelatively small subregion within the original design space. The\nimplementation of SSO is demonstrated in Fig. 1. The reader may refer to the\noriginal publication for a detailed explanation of SSO . H(I(i)) expresses the average relative sensitivity of E?[h(?,?)] to ?. A\nlow value of H(I(i)) indicates that E?[h(?,?)] is more sensitive to ?, and\nvice versa. A high value of H(I(i)), close to 1 corresponds to a sample\ndensity in design space I(i) that approximates a uniform distribution and\nsuggests that the identified subset I(i) has a low likelihood of containing\n?* . Therefore, the SSO is stopped when H(I(i)) exceeds a threshold\nvalue. A threshold value of 0.75?0.80 has been found to give satisfactory\nresults .\n(10) In the proposed approach, the Voronoi tessellation is implemented to\npartition the design space into non-overlapping subregions (a set of\nVoronoi cells) using the pool of samples distributed according to this\nauxiliary PDF. Conceptually, Voronoi tessellation involves partitioning a\nspace into convex polygons, called Voronoi cells, such that each cell\ncontains exactly one sample, called a cell-generating sample. Every\nsample in a given polygon is closer to its generating sample compared to\nany other. In the proposed approach, the admissible set (a set of all\nadmissible subspaces) is defined as a set containing all subsets of the set\nof Voronoi cells. An alternative approach to identify the optimal subset\nwithout performing any non-smooth deterministic optimization is also\npresented. The general theoretical and computational framework for the\niSSO algorithm is presented in the following subsections, and the\nalgorithm is demonstrated in Fig. 2. 4. Illustrative examples In this section, typical optimization problems are considered to\ndemonstrate the effectiveness and efficiency of the proposed approach. First, deterministic optimization problems are considered. These\nproblems include several local and global minima. Next, stochastic\noptimization problems are illustrated. The second example presents an RDO\nproblem of the TMD. In this example, the variance minimization of the\nprotected structure?s displacement (TMD attached to the structure) is\nperformed. In the third example, the mean minimization of 120 bars\ntruss problems is explored to demonstrate the applicability of the\nproposed approach to a high-dimensional stochastic design problem. Finally, the fourth example investigates the reliability-based\noptimization of a base isolation system for a 10-story building. In this study, after implementing iSSO, the optimal design solution is\nidentified as follows. Let ?j, j = 1???n be a set of independent, identically\ndistributed realizations of ?, and let h(?, ?j) be the structural\nperformance function realization for ?j. The expected structural performance\nfunction is approximated by the average of the realizations as:\nE?[h(?, ?)] ?\n1 ?n\nn j=1 )\nh ?, ?j . E?[h(?, ?)] is evaluated for all unique ? samples obtained at the last\niteration of the iSSO, and the ? sample resulting in the smallest value of\nE?[h(?, ?)] is taken as the optimal solution. Alternatively, as the\nrighthand side of (18) is deterministic, any deterministic optimization\nmethod can also be used to solve the optimization problem with the\napproximate expectation. In the following examples, both iSSO and SSO are implemented with\nN = 1000n?, ? = 0.20 and the stopping criteria as stated in (17). Here, a\nvalue of ? = 10 3 is adopted. (18) In this section, three two-dimensional benchmark deterministic\noptimization problems are considered. Results are also compared with\nthe SSO. The test functions are:\n??? (???\nminh(?) = ??sin(?1)cos(?2)exp ??1\ns.t.? = \n??????21??+?????????22? ???)???\n?\n?? ??,\n(21))\na) Griewank function:\nminh(?) = The results for the Griewank function are presented in Fig. 4. Fig. 4(a,\nb) shows that the function has multiple closely spaced local minima with\na single global minimum. Fig. 4(c, d) shows the SSO optimization using\nhyper-rectangle and hyper-ellipse as shapes of admissible subsets. It is\nseen that these shapes fail to capture the region containing the optimal\ndesign due to the presence of multiple local minima. Next, the iSSO is\nimplemented, where the Voronoi cells selected at the first and last\niteration are shown in Fig. 4(e, f). It is observed that at the first iteration,\nthe selected Voronoi cells effectively capture both the local and global\nminima and in the subsequent iterations, the selected cells are more\nconcentrated near the global minimum. The region selected at the last\niteration captures the optimal global solution. The Cross-in-Tray function has a relatively complex design space\ncompared to the Griewank function. Fig. 5(a, b) shows multiple local\nand global minima. Minimization by using SSO is demonstrated in Fig. 5\n(c, d). It is found that both the hyper-rectangle and hyper-ellipse are\ntrapped around any one of the global minima. At the same time, the iSSO\nis able to capture the regions that include all of the global minima, as\nseen in Fig. 5(e, f). The Holder Table function has multiple local and global minima; the\nglobal minima are placed at the boundary of the design space, as shown\nin Fig. 6(a, b). Once again, it is seen that both the hyper-rectangle and\nhyper-ellipse are trapped around any of one of the global minima, and\non the other hand, the iSSO is able to capture the regions that include all\nof the global minima, as seen in Fig. 6(e, f). The results from the three examples demonstrate that the proposed\niSSO is able to capture the regions containing the optimal solution\neffectively. Next, the statistics of the results of 50 independent runs, both for SSO\nand iSSO are presented in Table 1. It also includes the results obtained by\nusing state-of-the-art approaches, such as the Genetic algorithm, particle\nswarm optimization, and the gradient based optimization approach\n(interior-point algorithm). The proposed iSSO outperforms all other\napproaches as more successes in determining the optimal solution are\nobserved in all three optimization problems. It is also seen that both SSO\nand iSSO result in a similar value of volume reduction for the same\nstopping criterion; however, with SSO, the number of iterations required\nto achieve this volume reduction are relatively higher. The proposed\napproach outperformed the state-of-the-art approaches, as indicated by\nthe number of successes. These examples demonstrate that the main\nadvantage of implementing Voronoi tessellation is an effective\nexploration of the design space. Next, the performance of the proposed \"double sort algorithm\" for\nselecting the optimal subset is studied by using the above-mentioned\nthree functions. Fig. 7 shows the value of H(I(1)) for the 50\nindependent simulation runs, which is estimated by implementing the proposed\ndouble sort algorithm and by using the Genetic algorithm. It can be\nnoted that for each run, the H(I(1)) values obtained using the proposed\ndouble sort algorithm and Genetic algorithm are well matched, thereby\nconfirming the adequacy of the proposed double sort algorithm. At any iteration of iSSO, new samples are simulated using the seed\nsamples. In the proposed approach, the volume of the Voronoi cells\ncorresponding to the seed and new samples is greater than the volume of\nthe Voronoi cells corresponding only to the seed samples. Fig. 8 shows\nthis change in volume V(seeds+Vn(eswee)ds)V(seeds) due to the creation of Voronoi cells\nat any generation of iSSO using the procedure mentioned in Section 3.4. The increase is observed to be small which further reduces with an\nincrease in the iteration number. It is also observed that the increase in\nvolume decreases with an increase in sample size at each iteration and\nincreases with an increase in the dimension of the problem.\n4.2. Robust design optimization of the tuned mass damper This example considers a stochastic design problem involving a\nTuned Mass Damper (TMD) attached to a Single Degree of Freedom\n(SDOF) system. The problem is taken from  and is shown in Fig. 9. In this problem, the system is excited by a white noise signal with a\nmean zero and unit variance. The performance measure is the variance\nof the displacement of the system ?x2s . The mass mS, stiffness kS, and\nGA = genetic algorithm, PSO = particle swarm optimization, GBA = gradient-based optimization approach, NF = no. of. failure, NS = no. of. success, BV = best value,\nWV = worst value, AV = average value, c.o.v = coefficient of variation, FE = no. of. function evaluations, Gen = generations, VR = volume reduction percentage, * =\nefficiently applicable only for deterministic problems.\ndamping cS of the system are taken as uncertain parameters, following\nindependent Gaussian distribution. The mean value of these variables is\ntaken to be 105 kg, 107 N/m, and 4  104 Ns/m respectively. To account\nfor uncertainty, the c.o.v value for each variable taken is 0.05. The\nfrequency ratio ? = ?T /?S and damping ?T of the TMD are considered\ndesign parameters. The TMD has a mass ratio, mT/ms, of 0.10. The\nparameters mT,?T,and?S a?re?,???i?n????o???r?der, the mass of the TMD, the natural\nfrequency of the TMD ( kT/mT), and the natural frequency of the ?????????????\nstructure ( ks/ms). The optimization problem is written as:\n[( )]2 (22)\niSSO are shown. SAA is applied with a sample size of 103, as mentioned\nin . The results demonstrate that iSSO is effective in locating the\noptimal solution. SSO implemented with hyper-ellipse gives an optimal\nsolution but has a higher computational cost. 5. Conclusion This study attempts to provide an optimization approach called\n\"iSSO\", which is an improved version of SSO, primarily for stochastic\noptimization problems while it retains utility for deterministic\noptimization problems as well. Two novel ideas are introduced in this study:\nifrst, a better characterization of the design space is offered by\npartitioning the design space into non-overlapping subregions using Voronoi\ntessellation which improves the effectiveness and efficiency of the\nproposed iSSO considerably in comparison to SSO. Second, a novel \"double\nsort\" approach is proposed, eliminating the need for optimization to\nidentify the subregions for the optimal design at each iSSO iteration.\nSeveral mathematical and engineering design examples, including TMD,\n120 bars truss structure, and base-isolated structure, are included in this\nstudy to demonstrate the efficacy of the proposed iSSO. The results show\nthat the proposed iSSO effectively identifies the reduced design space for\ncomplex design problems with multiple global and local minima. This is\nattributable to the Voronoi tessellation, which eliminates the\nrequirement of the presumed admissible design space form to resemble the\ncontour of the original design. Voronoi tessellation enabled better\ndesign space exploration, allowing multiple global minima scattered\nthroughout the design pace to be effectively identified. Due to the\ndiscretization of the design space via Voronoi tessellation, computation\ndemand is significantly reduced as the number of function evaluations\nfor all examples is lower vis-a-vis the original SSO. Moreover, the novel\nidea of the double sort approach achieves the requisite precision in\nidentifying the subregions for optimal solutions and makes iSSO\nimplementation simple and effective. The applicability of the approach is dependent on the creation of the Appendix-A: Voronoi Tessellation V o r o n o i   c e l l s .   A t   p r e s e n t   t h e   m e t h o d s   a v a i l a b l e   i n   t h e   l i t e r a t i o n   f o r \n c r e a t i n g   t h e   V o r o n o i   t e s s e l l a t i o n   a r e   c o m p u t a t i o n a l l y   d e m a n d i n g   w h e n \n c o n s i d e r i n g   p r o b l e m s   o f   v e r y   h i g h   d i m e n s i o n .   F u t u r e   w o r k   w i l l   f o c u s   o n \n d e v e l o p i n g   a   m e t h o d   f o r   c r e a t i n g   t h e   V o r o n o i   t e s s e l l a t i o n   i n   h i g h e r \n d i m e n s i o n s ,   p a r t i c u l a r l y   t h o s e   g r e a t e r   t h a n   t e n . CRediT authorship contribution statement M o h d   A m a n   K h a l i d :   I n v e s t i g a t i o n ,   M e t h o d o l o g y ,   F o r m a l   a n a l y s i s , \n S o f t w a r e ,   V i s u a l i z a t i o n ,   W r i t i n g   ?   o r i g i n a l   d r a f t .   S a h i l   B a n s a l : \n C o n c e p t u a l i z a t i o n ,   M e t h o d o l o g y ,   S u p e r v i s i o n . Declaration of Competing Interest T h e   a u t h o r s   d e c l a r e   t h a t   t h e y   h a v e   n o   k n o w n   c o m p e t i n g   f i n a n c i a l \n i n t e r e s t s   o r   p e r s o n a l   r e l a t i o n s h i p s   t h a t   c o u l d   h a v e   a p p e a r e d   t o   i n f l u e n c e \n t h e   w o r k   r e p o r t e d   i n   t h i s   p a p e r . Data availability No data was used for the research described in the article. Voronoi tessellation is a mathematical concept named after the Russian mathematician Georgy Voronoi. It is also known as the Voronoi diagram or\nDirichlet tessellation. A Voronoi tessellation of a set of points P in a plane is a partition of the plane into a set of non-overlapping convex polygons, with\neach polygon including precisely one point of P and each point in a polygon being closer to its associated point in P than to any other point in P. Each\npolygon is referred to as a Voronoi cell or a Dirichlet region. The boundary of each cell is constituted of points that are equidistant to two or more\npoints in P. Fig. 12 shows the Voronoi diagram in a two-dimensional design space. There are several efficient algorithms for creating Voronoi diagrams. One such basic algorithm is to start with a set of points and then compute the\nVoronoi cells by dividing the space into regions based on the distance to the nearest point. The Bowyer-Watson algorithm , which generates a\nDelaunay triangulation in any number of dimensions, can be applied while creating a Voronoi diagram. The Delaunay triangulation is a triangulation\nof the point in which no point falls within the circumcircle of any triangle. The polygon generated by the intersection of the half-planes defined by the\nedges of the Delaunay triangles enclosing the point is therefore obtained as the Voronoi cell of a point. It can be summarized that Voronoi tessellation is a powerful mathematical concept that aids in dividing space into regions based on the distance to\na set of points. Voronoi tessellation finds widespread applications in areas such as image processing , spatial topology analysis , and\nmicrostructure study . The MATLAB command \"Voronoin\" from the \"Parallel Computing Toolbox\"  has been used in this study to create the\nVoronoi cells.",
  "references": [
    "surname, given-names, 'Stochastic optimization methods', , 2008",
    "Y Tsompanakis, ND Lagaros, M. Papadrakakis, 'Structural design optimization considering uncertainties', , 2008",
    "MA Khalid, S Bansal, V. Ramamohan, 'An augmented formulation for robust design optimization of structures using stochastic simulation method', Res Eng Des, 2023"
  ],
  "keywords": [
    "Voronoi cells",
    "Robust Design Optimization",
    "design optimization",
    "Voronoi",
    "design",
    "optimization",
    "stochastic subset optimization",
    "design space",
    "cid",
    "SSO",
    "Voronoi tessellation",
    "structural design optimization",
    "optimization problems",
    "Appl Mech Eng",
    "design parameters",
    "design optimization optimization",
    "Methods Appl Mech",
    "Robust Design",
    "stochastic design problem",
    "subset optimization"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1c8XsnHGuiNDs50dUAyYpNHScoWOETObX"
}
{
  "id": 11,
  "title": "U-Net - Deep Learning for Cell Counting, Detection, and Morphometry",
  "authors": [
    "Thorsten Falk",
    "Dominic Mai",
    "Robert Bensch",
    "zgn iek",
    "Ahmed Abdulkadir",
    "Yassine Marrakchi",
    "Anton Bhm",
    "Jan Deubner",
    "Zoe Jckel",
    "Katharina Seiwald",
    "Alexander Dovzhenko",
    "Olaf Tietz",
    "Cristina Dal Bosco",
    "Sean Walsh",
    "Deniz Saltukoglu",
    "Tuan Leng Tay",
    "Marco Prinz",
    "Klaus Palme",
    "s Simons",
    "s Brox",
    "Olaf Ronneberger"
  ],
  "institutions": [
    "BIOSS Centre for Biological Signalling Studies",
    "Bernstein Center Freiburg, Albert-Ludwigs-University",
    "BrainLinks-BrainTools, Albert-Ludwigs-University",
    "CIBSS Centre for Integrative Biological Signalling Studies, Albert-Ludwigs-University",
    "Center for Biological Systems Analysis, Albert-Ludwigs-University",
    "Department of Computer Science, Albert-Ludwigs-University",
    "Institute of Biology I, Albert-Ludwigs-University",
    "Institute of Biology II, Albert-Ludwigs-University",
    "Institute of Neuropathology, University Medical Centre",
    "Life Imaging Center, Center for Biological Systems Analysis, Albert-Ludwigs-University",
    "Optophysiology Lab, Institute of Biology III, Albert-Ludwigs-University",
    "Paris Descartes University-Sorbonne Paris Cite?, Imagine Institute",
    "Renal Division, University Medical Centre",
    "Spemann Graduate School of Biology and Medicine (SGBM), Albert-Ludwigs-University",
    "University Hospital of Old Age Psychiatry and Psychotherapy, University of Bern"
  ],
  "resume": "U-Net is a generic deep-learning solution for frequently occurring quantification tasks like cell detection and shape measurements in biomedical image data. We present an ImageJ plugin that enables non-machine learning experts to analyze their data with U-Net either on the local computer or a remote server/cloud service. The plugin comes with pre-trained models for single cell segmentation and allows adaptation of U-Net to new tasks based on few annotated samples.",
  "content": "- The advancement of microscopy and sample preparation techniques leaves researchers with large\namounts of image data. The stacks of data promise additional insights, more precise analysis, and\nmore rigorous statistics, were there not the hurdles of quantification. Images must be converted\nfirst into numbers before they are accessible for statistical analysis. Often this requires counting\nthousands of cells with a certain marker or drawing the outlines of cells to quantify their shape\nor the strength of a reporter. Such work is not much liked in the lab and, consequently, it is often\navoided. In neuroscientific studies applying optogenetic tools, for example, it is often requested\nto quantify the number of opsin expressing neurons or the localization of newly developed opsins\nwithin the cells. However, because of the effort, most studies are published without this information.\nIs such quantification not a job that computers can do? Indeed it is. For decades, computer scientists\nhave developed specialized software that can lift the burden of quantification from researchers in\nthe life sciences. However, each lab produces different data and focuses on different aspects of the\ndata for their research question at hand. Thus, a new software must be built for each case. Deep\nlearning could change this situation. It learns the features relevant for the task from data rather than\nbeing hard-coded. Therefore, software engineers need not set up a specialized software for a certain\nquantification task. Instead, a generic software package can learn to adapt to the task autonomously\nfrom appropriate data; data that researchers in the life sciences can provide by themselves.\nLearning-based approaches caught the interest of the biomedical community already years ago.\nPopular solutions like ilastik1a or the trainable WEKA segmentation toolkit2b allow training of\nsegmentation pipelines using generic hand-tailored image features. More recently, attention has shifted\ntowards deep learning which automatically extracts optimal features for the actual image analysis\ntask, lifting the need for feature design by experts in computer science3?5. However, a wide-spread\nuse for quantification in the life sciences has been impaired by the lack of generic, easy-to-use\nsoftware packages. While the packages Aiviac and Cell Profiler6d already use deep learning models,\nthey do not allow training on new data. This restricts their application domain to a small range of\ndatasets. In the scope of image restauration, CSBDeep7 provides an ImgLib2e-based plugin with\nmodels for specific imaging modalities and biological specimen. It allows to integrate externally\ntrained new restoration models. Another approach of bringing deep learning to the life sciences is\nCDeep3M8 which ships a set of command line tools and tutorials for training and applying a\nresidual inception network architecture for 3D image segmentation. They specifically address researchers\nwith occasional need for deep learning by providing a cloud-based setup that does not require a local\nGPU. The present work provides a generic deep-learning-based software package for cell detection and\ncell segmentation. For our successful U-Net3 encoder-decoder network architecture, which has\nalready achieved top ranks in biomedical data analysis benchmarks9 and which has been the basis of\nmany deep learning models in biomedical image analysis, we developed an interface that runs as\nplugin in the popular ImageJ software10 (Supplementary note 1, Supplementary Software 1?4). In\ncontrast to all previous software packages of such kind, our U-Net can be trained and adapted to\nnew data and tasks by the users themselves using the familiar ImageJ interface (Fig. 1). This enables\napplication of U-Net to a wide range of tasks and makes it accessible for a wide set of researchers,\nahttp://ilastik.org\nbhttps://imagej.net/Trainable_Weka_Segmentation\nchttps://www.drvtechnologies.com/aivia6\ndhttp://cellprofiler.org/\nehttps://imagej.net/ImgLib2\nwho do not have experience with deep learning. For more experienced users the plugin offers an\ninterface to adapt aspects of the network architecture, and to train on data sets from completely\ndifferent domains. The software comes with a step-by-step protocol and tutorial that shows how to\nannotate the data for adapting the network and that indicates typical pitfalls (Supplementary Note\n2). U-Net applies to general pixel classification tasks in flat images or volumetric image stacks with\none or multiple channels. Such tasks include detection and counting of cells, i.e., prediction of a\nsingle reference point per cell, and segmentation, i.e., delineation of the outline of individual cells.\nThese tasks are a superset of the more wide-spread classification tasks, where the object of interest\nis already localized and only its class label must be inferred. Although adaptation to the detection\nand segmentation of arbitrary structures in biological tissue is possible given corresponding training\ndata, our experiments focused on cell images, where the flexibility of U-Net is shown on a wide\nset of common quantification tasks, including detection in multi-channel fluorescence data of dense\ntissue, and segmentation of cells recorded with different imaging modalities in 2D and 3D (Fig. 2\nand Supplementary Note 3). In all shown cases, the U-Net would have saved the responsible\nscientists much work. As cross-modality experiments show, the diversity in biological samples is too\nlarge to ship a single software that can cover them all out-of-the-box (Supplementary note 3.2.2).\nThanks to the learning approach, U-Net?s applicability is extended from a set of special cases to\nan unlimited number of experimental settings. The exceptionally precise segmentation results on\nvolumetric brightfield data, the annotation of which gets even human experts to their limits, is a\nparticular strong demonstration of the capabilities of a deep-learning-based automated quantification\nsoftware (Fig. 2d and Supplementary Note 3.2.4). Critics often stress the need for huge amounts of training data to train a deep network. In case of\nU-Net, a base network trained on a diverse set of data and our special data augmentation strategy\nallow adaptation to new tasks with only one or two annotated images (Online Methods). Only in\nparticularly hard cases, more than 10 training images are needed. Judgment whether a model is\nadequately trained requires evaluation on a held-out validation set and successive addition of training\ndata until no significant improvement on the validation set can be observed (Supplementary Note\n3.2.3). If computational resources allow, cross validation with randomly allocated train/test splits\navoids selection of a non-representative validation set at the expense of multiple trainings. The\nmanual effort that must be invested to adapt U-Net to a task at hand is typically much smaller than\nwhat is needed for a minimal statistical analysis of the experimental data. In addition, U-Net offers\nthe possibility to run on much larger sample sizes without causing any additional effort. This makes\nit particularly well-suited for automated large scale sample preparation and recording setups, which\nare likely to become more and more common in the coming years. U-Net was optimized for usability in the life sciences. The integration of the software in ImageJ\nand a step-by-step tutorial make deep learning available to scientists without a computer science\nbackground (Supplementary Videos 1?4). Importantly, the computational load is practicable for\ncommon life science laboratory settings (Supplementary Note 1). Adaptation of the network to new\ncell types or imaging modalities ranges from minutes to a few hours on a single computer with\na consumer GPU. If the dedicated compute hardware is not available in the lab, common cloud\nservices can be used. Our experiments provide evidence that U-Net yields results comparable in quality to manual\nannotation. One special feature of U-Net compared to other automatic annotation tools is the individual\ninfluence of the annotator. This is advantageous as typically researchers develop individual\nprotocols in which multiple parameters are taken into account without being explicitly mentioned. Due\nto the complexity of these labeling rules they cannot be reproduced by common automatic labeling\ntools. This advantage can also be turned into a disadvantage: U-Net learns from the provided\nexamples. If these examples are not representative for the actual task or if the manual annotation in these\nexamples is of low quality and inconsistent, U-Net will either fail to train or will reproduce\ninconsistent annotations on new data. This could also serve as a quality check of the manual annotations.\nTogether, U-Net cannot correct for low-quality human annotations but is a tool to apply individual\nlabeling rules to large data sets and thereby can save manual annotation effort in a vast variety of\nquantification tasks. 1 Acknowledgements T h i s   w o r k   w a s   s u p p o r t e d   b y   t h e   G e r m a n   F e d e r a l   M i n i s t r y   f o r   E d u c a t i o n   a n d   R e s e a r c h   ( B M B F ) \n t h r o u g h   t h e   M I C R O S Y S T E M S   p r o j e c t   ( 0 3 1 6 1 8 5 B ) :   T F ,   A D ;   a n d   t h e   B e r n s t e i n   A w a r d   2 0 1 2   ( 0 1 G Q 2 3 0 1 ) : \n I D ;   b y   t h e   F e d e r a l   M i n s t r y   f o r   E c o n o m i c   A f f a i r s   a n d   E n e r g y   ( Z F 4 1 8 4 1 0 1 C R 5 ) :   A B ;   b y   t h e   D e u t s c h e \n F o r s c h u n g s g e m e i n s c h a f t   ( D F G )   t h r o u g h   t h e   c o l l a b o r a t i v e   r e s e a r c h   c e n t e r   K I D G E M   ( S F B   1 1 4 0 ) : \n D M ,    C ,   T F ,   O R ;   t h e   c l u s t e r s   o f   e x c e l l e n c e   B I O S S   ( E X C   2 9 4 ) :   T F ,   D M ,   R B ,   A A ,   Y M ,   D S ,   T L T , \n M P ,   K P ,   M S ,   T B ,   O R ;   a n d   B r a i n L i n k s - B r a i n - T o o l s   ( E X C   1 0 8 6 ) :   Z J ,   K S ,   I D ,   T B ;   a s   w e l l   a s   g r a n t s \n D I   1 9 0 8 / 3 - 1 :   J D ;   D I   1 9 0 8 / 6 - 1 :   Z J ,   K S ;   a n d   D I   1 9 0 8 / 7 - 1 :   I D ;   b y   t h e   S w i s s   N a t i o n a l   S c i e n c e \n F o u n d a t i o n   ( S N F   G r a n t   1 7 3 8 8 0 ) :   A A ;   b y   t h e   E R C   S t a r t i n g   G r a n t   O p t o M o t o r P a t h   ( 3 3 8 0 4 1 ) :   I D ;   a n d   b y \n t h e   F E N S - K a v l i   N e t w o r k   o f   E x c e l l e n c e   ( F K N E ) :   I D .   W e   t h a n k   F .   P r  s p e r ,   E .   B  r t o v  ,   V .   U l m a n , \n D .   S v o b o d a ,   G .   v a n   C a p p e l l e n ,   S .   K u m a r ,   T .   B e c k e r   a n d   t h e   M i t o c h e c k   c o n s o r t i u m   f o r   p r o v i d i n g   a \n r i c h   d i v e r s i t y   o f   d a t a s e t s   t h r o u g h   t h e   I S B I   s e g m e n t a t i o n   c h a l l e n g e .   W e   t h a n k   P .   F i s c h e r   f o r   m a n u a l \n i m a g e   a n n o t a t i o n s .   W e   t h a n k   S .   W r o b e l   f o r   t o b a c c o   m i c r o s p o r e   p r e p a r a t i o n . 2 Author Contributions TF, DM, RB, YM, C, TB and OR selected and designed the computational experiments.\nTF, RB, DM, YM, AB and C performed the experiments, RB, DM, YM, AB (2D) and TF, C\n(3D). R.B., .C., A.A., T.F. and O.R. implemented the U-Net extensions into caffe. T.F. designed and implemented the Fiji plugin. D.S. and M.S. selected, prepared and recorded the Keratinocyte dataset PC3-HKPV.\nT.F. and O.R. prepared the airborne pollen dataset BF1-POL. A.D., S.W., O.T., C.D.B. and K.P. selected, prepared and recorded the protoplast and microspore\ndatasets BF2-PPL and BF3-MiSp. T.L.T. and M.P. prepared, recorded and annotated the data for the microglial proliferation\nexperiment. J.D. and Z.J. selected, prepared, and recorded the optogenetic data set. I.D., J.D., and Z.J. manually annotated the optogenetic data set. I.D., T.F., D.M., R.B., .C., T.B. and O.R. wrote the manuscript. 3 Competing financial interests  4 Ethics compliance statement  M2 Weighted soft-max cross-entropy loss We use pixel-weighted soft-max cross-entropy loss to allow to change the influence of imbalanced\nclasses in semantic segmentation. The loss is computed as\nl (I) := X w (x) log\nx2 ey^y(x)(x)\nPC\nc=0 ey^c(x)\nwhere x is a pixel in image domain , y^c : ! R is the predicted score for class c 2 f0; : : : ; Cg,\nC is the number of classes, y : ! f0; : : : ; Cg is the true class label. With this, y^y(x) (x) is the\npredicted score for the ground truth class at position x. As defined above, w : ! R 0 is the\npixel-wise loss weight. We employ loss weighting to optimize class-balancing and handle regions without annotations (in\nthe following termed \"ignored regions\") using weight map wbal. We additionally enforce instance\nseparation using weight wsep as described in the following sections. The final loss weights are then\ngiven by\nw (x) := wb0al +\nwsep\nwhere 2 R 0 controls the importance of instance separation. M3 Tile sampling and augmentation Data augmentation is essential to teach the expected appearance variation to the neural network\nwith only few annotated images. To become robust to translations and to focus on relevant regions\nin the images, we first randomly draw spatial locations of image tiles that are presented to the\nnetwork from a user-defined probability density function (pdf). For all our experiments we used the\nnormalized weight map wbal for sampling the spatial location, i.e. foreground objects are presented\nto the network ten times more often (according to our selection of vbal = 0:1) than background\nregions and tiles centered around an ignore region are never selected during training. Then, we draw\na random rotation angle (around the optical axis in 3D) from a uniform distribution in a user-defined\nrange. Finally, we generate a smooth deformation field by placing random displacement vectors with\nuser-defined standard deviation of the magnitude for each component on a very coarse grid. These\ndisplacement vectors are used to generate a dense full-resolution deformation field using bicubic\ninterpolation (Fig. 5). Rigid transformations and elastic deformations are concatenated to look-up\nintensities in the original image during tile generation. We additionally apply a smooth strictly increasing intensity transformation to become robust to\nbrightness and contrast changes. The intensity mapping curve is generated from a user-defined\nnumber of equidistant control points in the normalized [0; 1] source intensity range. Target intensities at\nthe control points are drawn from uniform distributions with user defined ranges. The sampling\nprocess enforces intensities at subsequent control points to increase and spline interpolation between\nthe control points ensures smoothness. All data augmentation is applied on-the-fly to input image, labels and weight maps during network\ntraining11. M4 Training All networks were trained on an nVidia TITAN X with 12GB GDDR5 RAM using cuda 8 and\ncuDNN 6 with caffe after applying our proposed extensions. The initial network parameters are\ndrawn from a Gaussian distribution with standard deviation = p2=nin, where nin is the number\nof inputs of one neuron of the respective layer12. For all experiments, raw image intensities per channel were normalized to the [0; 1] range before\ntraining using I^ := I\nmax fIg\nmin fIg\nmin fIg\nwhere I is the raw and I^ the normalized intensity. M5 Transfer learning Adaptation of a pre-trained U-Net to a new dataset using annotated data is called transfer learning\nor finetuning. Transfer learning leverages the knowledge about the different cell datasets already\nlearned by the U-Net and usually requires considerably less annotated data and training iterations\ncompared to training from scratch. Transfer to a new dataset is based on the same training protocol as described above. All the user\nmust provide are raw images and corresponding annotations as ImageJ ROIs or pixel masks\n(Detection: One Multi-point ROI per class and image; Segmentation: One regional ROI per object or\npixel masks) (Supplementary Section B). The plugin performs image re-scaling, pixel weight w(x)\ngeneration, and parametrization of the caffe training software. M6 Evaluation Metrics  M7 Code availability We provide pre-built binary versions of the U-Net caffe extensions for Ubuntu Linux 16.04 at\nhttps://lmb.informatik.uni-freiburg.de/resources/opensource/unet/. We\nadditionally provide our changes to the source code of the publicly available caffe deep learning\nframeworkf as patch file with detailed instructions on how to apply the patch and build our caffe\nvariant from source in the supplementary material. Binary installation only requires to unpack the archive and install required third-party libraries which\ncan be done within few minutes on an Ubuntu 16.04 machine depending on your internet connection\nfor fetching the packages. Building from scratch requires to install the dependent development libraries and checkout the given\ntagged version of the BVLC caffe master branch and apply the patch. With \"normal\" internet\nconnection, package installation is a matter of few minutes. Cloning the BVLC master repository requires\nless than a minute, applying the patch imposes no measurable overhead. Configuring and building\nthe package requires approximately ten to fifteen minutes. The U-Net segmentation plugin for Fiji/ImageJ is available at http://sites.imagej.net/\nFalk/plugins/ or through the ImageJ updater within Fiji. Source code is included in the plugin\njar File Unet_Segmentation.jar. Installation using the Fiji updater requires only a few seconds.\nThe trained caffe-models for the 2d- and 3d-U-Net are available at https://lmb.informatik.\nuni-freiburg.de/resources/opensource/unet/. M8 Data availability The datasets F1-MSC, F2-GOWT1, F3-SIM, F4-HeLa, DIC1-HeLa, PC1-U373, and PC2-PSC are\nfrom the ISBI Cell Tracking Challenge 201514. Information on how to obtain the data can be found\nat http://celltrackingchallenge.net/datasets.html and currently requires\nfreeof-charge registration for the challenge. The datasets PC3-HKPV, BF1-POL, BF2-PPL, and BF3-MiSp are custom and are available from\nthe corresponding author upon reasonable request. Datasets for the detection experiments partially contain unpublished sample preparation protocols,\nand are currently not freely available. Upon protocol publication datasets will be made available on\nrequest-basis.",
  "references": [
    "C. Sommer, C. Straehle, U. Koethe, F. A. Hamprecht,  Ilastik, ': Interactive learning and segmentation toolkit in Biomedical Imaging: From Nano to Macro, 2011', IEEE International Symposium on Biomedical Imaging, 2011",
    "surname, given-names, #text, 'Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification', Bioinformatics, 2017",
    "O. Ronneberger, P. Fischer,  Brox,  T., 'Convolutional Networks for Biomedical Image Segmentation in Medical Image Computing and Computer-Assisted Intervention (MICCAI) 9351 (', , 2015"
  ],
  "keywords": [
    "U-Net",
    "data",
    "Deep Learning",
    "segmentation",
    "DOI",
    "image",
    "Images",
    "Learning",
    "Morphometry",
    "Supplementary note",
    "Deep",
    "network",
    "bal",
    "Detection",
    "deep learning models",
    "Cell",
    "Supplementary",
    "cells",
    "software",
    "cid"
  ],
  "urlPDF": "https://lmb.informatik.uni-freiburg.de/Publications/2019/FMBCAMBBR19/paper-U-Net.pdf"
}
{
  "id": 12,
  "title": "Large Language Model Augmented Narrative Driven Recommendations",
  "authors": [
    "Sheshera Mysore",
    "Andrew McCallum",
    "Hamed Zamani"
  ],
  "institutions": [
    "University of Massachusetts Amherst"
  ],
  "resume": "Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with fewshot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an efective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.",
  "content": "CCS CONCEPTS ?   I n f o r m a t i o n   s y s t e m s   ?   R e c o m m e n d e r   s y s t e m s ;   U s e r s   a n d \n i n t e r a c t i v e   r e t r i e v a l ;   ?   C o m p u t i n g   m e t h o d o l o g i e s   ?   N a t u r a l   l a n g u a g e \n g e n e r a t i o n . INTRODUCTION Recommender systems personalized to users are an important\ncomponent of several industry-scale platforms . These\nsystems function by inferring users? interests from their prior\ninteractions on the platform and making recommendations based on\nthese inferred interests. While recommendations based on historical\ninteractions are efective, users soliciting recommendations often\nstart with a vague idea about their desired target items or may\ndesire recommendations depending on the context of use, often\nmissing in historical interaction data (Figure 1). In these scenarios,\nit is common for users to solicit recommendations through\nlongform narrative queries describing their broad interests and context.\nInformation access tasks like these have been studied as\nnarrativedriven recommendations (NDR) for items ranging from books \nand movies , to points of interest . Bogers and Koolen \nnote these narrative requests to be common on discussion forums\nand several subreddits1, but, there is a lack of support for these\ncomplex natural language queries in current recommenders. However, with the emergence of conversational interfaces for\ninformation access tasks, support for complex NDR tasks is likely\nto become necessary. In this context, recent work has noted an\nincrease in complex and subjective natural language requests\ncompared to more conventional search interfaces . Furthermore,\nthe emergence of large language models (LLM) with strong\nlanguage understanding capabilities presents the potential for fulfilling\nsuch complex requests . This work explores the potential for\nre-purposing historical user-item recommendation datasets,\ntraditionally used for training collaborative filtering recommenders,\nwith LLMs to support NDR. Specifically, given a user?s interactions,  , with items and\ntheir accompanying text documents (e.g., reviews, descriptions)\n = { }=1, selected from a user-item interaction dataset I, we\nprompt InstructGPT, a 175B parameter LLM, to author a synthetic\nnarrative query  based on  (Figure 2). Since we expect the\nquery  to be noisy and not fully representative of all the user\nreviews,  is filtered to retain only a fraction of the reviews based\non a language-model assigned likelihood of  given a user\ndocument,  . Then, a pre-trained LM based retrieval model (110M\nparameters) is fine-tuned for retrieval on the synthetic queries and\nifltered reviews. Our approach, which we refer to as Mint2, follows from the\nobservation that while narrative queries and suggestions are often\nmade in online discussion forums, and could serve as training data,\nthe number of these posts and the diversity of domains for which\nthey are available is significantly smaller than the size and diversity\nof passively gathered user-item interaction datasets. E.g. while\nBogers and Koolen  note nearly 25,000 narrative requests for\nbooks on the LibraryThing discussion forum, a publicly available\nuser-item interaction dataset for Goodreads contains interactions\nwith nearly 2.2M books by 460k users  . We empirically evaluate Mint in a publicly available test\ncollection for point of interest recommendation: pointrec . To train\n1r/MovieSuggestions, r/booksuggestions, r/Animesuggest\n2Mint: Data augMentation with INteraction narraTives.\nour NDR models, we generate synthetic training data based on\nuser-item interaction datasets from Yelp. Models (110M parameters)\ntrained with Mint significantly outperform several baseline models\nand match the performance of significantly larger LLM baselines\nautoregressively generating recommendations. Code and synthetic\ndatasets are available:3\n2 RELATED WORK xref #text Proposed Method xref #text EXPERIMENTS AND RESULTS Next, we evaluate Mint on a publicly available test collection for\nNDR and present a series of ablations.\n4.1 Experimental Setup\n4.1.1 Datasets. We perform evaluations on an NDR dataset for\npoint-of-interest (POI) recommendation Pointrec . Pointrec\ncontains 112 realistic narrative queries (130 words long) obtained\nfrom discussion forums on Reddit and items pooled from baseline\nrankers. The items are annotated on a graded relevance scale by\ncrowd-workers and/or discussion forum members and further\nvalidated by the dataset authors. The item collection C in Pointrec\ncontains 700k POIs with metadata (category, city) and noisy text\nsnippets describing the POI obtained from the Bing search engine.\nFor test time ranking, we only rank the candidate items in the city\nand request category (e.g., ?Restaurants?) of the query available in\nPointrec - this follows prior practice to exclude clearly irrelevant\nitems . We use user-item interaction datasets from Yelp to\ngenerate synthetic queries for training.5 Note also that we limit our\nevaluations to Pointrec since it presents the only publicly\navailable, manually annotated, and candidate pooled test collection for\nNDR, to our knowledge. Other datasets for NDR use document\ncollections that are no longer publicly accessible , contain sparse\nand noisy relevance judgments due to them being determined with\nautomatic rules applied to discussion threads , lack pooling\nto gather candidates for judging relevance , or lack realistic\nnarrative queries . We leave the development of more robust\ntest collections and evaluation methods for NDR to future work.\n4.1.2 Implementation Details. Next, we describe important details\nfor Mint and leave finer details of the model and training to our\ncode release. To sample user interactions for generating synthetic\nqueries from the Yelp dataset, we exclude POIs and users with\nfewer than ten reviews to ensure that users were regular users of\nthe site with well represented interests. This follows common prior\npractice in preparing user-item interaction datasets for use .\nThen we retain users who deliver an average rating greater than\n3/5 and with 10-30 above-average reviews. This desirably biases\nour data to users who commonly describe their likings (rather than\ndislikes). It also retains the users whose interests are summarizable\nby QGen. In the Yelp dataset, this results in 45,193 retained users.\nNow, 10,000 randomly selected users are chosen for generating\nsynthetic narrative queries. For these users, a single randomly selected\nsentence from 10 of their reviews is included in the prompt (Figure\n2) to QGen, i.e.,  = 10. After generating synthetic queries, some\nitems are filtered out (3.2.2). Here, we exclude 40% of the items\nfor a user. This results in about 60,000 training samples for training\nBiEnc-Mint and CrEnc-Mint. These decisions were made\nmanually by examining the resulting datasets and the cost of authoring\nqueries. The expense of generating  was about USD 230.\n4.1.3 Baselines. We compare BiEnc-Mint and CrEnc-Mint\nmodels against several standard and performant retrieval model\nbaselines. These span zero-shot/unsupervised rankers, supervised\nbiencoders, unsupervised cross-encoders, and LLM baselines. BM25:\nA standard unsupervised sparse retrieval baseline based on term\noverlap between query and document, with strong generalization\nperformance across tasks and domains . Contriver: A BERT-base\nbi-encoder model pre-trained for zero-shot retrieval with weakly\nsupervised query-document pairs . MPNet-1B: A strong\nSentenceBert bi-encoder model initialized with MPNet-base and trained on\n1 billion supervised query-document pairs aggregated from\nnumerous domains . BERT-MSM: A BERT-base bi-encoder fine-tuned\non supervised question-passage pairs from MSMarco. UPR: A\ntwostage approach that retrieves items with a Contriver bi-encoder\nand re-ranks the top 200 items with a query-likelihood model using\na FlanT5 model with 3B parameters . This may be seen\nas an unsupervised ?cross-encoder? model. Grounded LLM: A\nrecently proposed two-stage approach which autoregressively\ngenerates ten pseudo-relevant items using an LLM (175B InstructGPT)\nprompted with the narrative query and generates\nrecommendations grounded in C by retrieving the nearest neighbors for each\ngenerated item using a bi-encoder . We include one few-shot\nexample of a narrative query and recommended items in the prompt\nto the LLM. We run this baseline three times and report average\nperformance across runs. We report NDCG at 5 and 10, MAP, MRR,\nand Recall at 100 and 200. Finally, our reported results should be\nconsidered lower bounds on realistic performance due to the\nunjudged documents (about 70% at  = 10) in our test collections\n.\n4.2 Results Table 1 presents the performance of the proposed method compared\nagainst baselines. Here, bold numbers indicate the best-performing\nmodel, and superscripts indicate statistical significance computed\nwith two-sided t-tests at  < 0.05. Here, we first note the performance of baseline approaches. We\nsee BM25 outperformed by Contriver, a transformer bi-encoder\nmodel trained for zero-shot retrieval; this mirrors prior work .\nNext, we see supervised bi-encoder models trained on similar\npassage (MPNet-1B) and question-answer (BERT-MSM) pairs\noutperform a weakly supervised model (Contriver) by smaller margins.\nFinally, the Grounded LLM outperforms all bi-encoder baselines,\nindicating strong few-shot generalization and mirroring prior results\n. Examining the Mint models, we first note that the\nBiEncMint sees statistically significant improvement compared to BM25\nRecall@100\nand outperforms the best bi-encoder baselines by 11-13% on\nprecision measures and 5-7% on recall measures. Specifically, we see a\nmodel trained for question-answering (BERT-MSM) underperform\nBiEnc-Mint, indicating the challenge of the NDR task. Further,\nBiEnc-Mint, trained on 5 orders of magnitude lesser data than\nMPNet-1B, sees improved performance ? indicating the quality of\ndata obtained from Mint. Furthermore, BiEnc-Mint also performs\nat par with a 175B LLM while ofering the inference eficiency of a\nsmall-parameter bi-encoder. Next, we see CrEnc-Mint outperform\nthe baseline bi-encoders, BiEnc-Mint, UPR, and Grounded LLM\nby 4-21% on precision measures and 7-13% on recall measures ?\ndemonstrating the value of Mint for training NDR models.\n4.3 Ablations In Table 2, we ablate various design choices in Mint. Diferent\nchoices result in diferent training sets for the BiEnc and CrEnc\nmodels. Also, note that in reporting ablation performance for CrEnc,\nwe still use the performant BiEnc-Mint model for obtaining\nnegative examples for training and first-stage ranking. Without\nhighquality negative examples, we found CrEnc to result in much poorer\nperformance. No item fil tering. Since synthetic queries are unlikely to\nrep\nresent all the items of a user, Mint excludes user items { }=1\nwhich have a low likelihood of being generated from the document\n(3.2.2). Without this step, we expect the training set for training\nretrieval models to be larger and noisier. In Table 2, we see that\nexcluding this step leads to a lower performance for BiEnc and\nCrEnc, indicating that the quality of data obtained is important for\nperformance. 6B LLM for QGen. Mint relies on using an expensive 175B\nparameter InstructGPT model for QGen. Here, we investigate the\neficacy for generating  for { }=1 with a 6B parameter\nInstructGPT model (text-curie-001). We use an identical setup to the\n175B LLM for this. In Table 2, we see that training on the synthetic\nnarrative queries of the smaller LLM results in worse models ?\noften underperforming the baselines in Table 1. This indicates the\ninability of a smaller model to generate complex narrative queries\nwhile conditioning on a set of user items. This necessity of a larger\nLLM for generating queries in complex retrieval tasks has been\nobserved in prior work . CONCLUSIONS In this paper, we present Mint, a data augmentation method for the\nnarrative-driven recommendation (NDR) task. Mint re-purposes\nhistorical user-item interaction datasets for NDR by using a 175B\nparameter large language model to author long-form narrative queries\nwhile conditioning on the text of items liked by users. We evaluate\nbi-encoder and cross-encoder models trained on data from Mint on\nthe publicly available Pointrec test collection for narrative-driven\npoint of interest recommendation. We demonstrate that the\nresulting models outperform several strong baselines and ablated models\nand match or outperform a 175B LLM directly used for NDR in a\n1-shot setup. However, Mint also presents some limitations. Given our use of\nhistorical interaction datasets for generating synthetic training data\nand the prevalence of popular interests in these datasets longer,\ntailed interests are unlikely to be present in the generated\nsynthetic datasets. In turn, causing retrieval models to likely see poorer\nperformance on these requests. Our use of LLMs to generate\nsynthetic queries also causes the queries to be repetitive in structure,\nlikely causing novel longer-tail queries to be poorly served. These\nlimitations may be addressed in future work. MAP Recall@100 Besides this, other avenues also present rich future work. While\nMint leverages a 175B LLM for generating synthetic queries, smaller\nparameter LLMs may be explored for this purpose - perhaps by\ntraining dedicated QGen models. Mint may also be expanded to\nexplore more active strategies for sampling items and users for\nwhom narrative queries are authored - this may allow more\neficient use of large parameter LLMs while ensuring higher quality\ntraining datasets. Next, the generation of synthetic queries from\nsets of documents may be explored for a broader range of retrieval\ntasks beyond NDR given its promise to generate larger training\nsets ? a currently underexplored direction. Finally, given the lack of\nlarger-scale test collections for NDR and the efectiveness of LLMs\nfor authoring narrative queries from user-item interaction, fruitful\nfuture work may also explore the creation of larger-scale datasets\nin a mixed-initiative setup to robustly evaluate models for NDR. ACKNOWLEDGMENTS W e   t h a n k   a n o n y m o u s   r e v i e w e r s   f o r   t h e i r   i n v a l u a b l e   f e e d b a c k .   T h i s \n w o r k   w a s   p a r t l y   s u p p o r t e d   b y   t h e   C e n t e r   f o r   I n t e l l i g e n t \n I n f o r m a t i o n   R e t r i e v a l ,   N S F   g r a n t s   I I S - 1 9 2 2 0 9 0   a n d   2 1 4 3 4 3 4 ,   t h e   O f i c e   o f \n N a v a l   R e s e a r c h   c o n t r a c t   n u m b e r   N 0 0 0 1 4 2 2 1 2 6 8 8 ,   a n   A m a z o n   A l e x a \n P r i z e   g r a n t ,   a n d   t h e   C h a n   Z u c k e r b e r g   I n i t i a t i v e   u n d e r   t h e   p r o j e c t \n S c i e n t i f i c   K n o w l e d g e   B a s e   C o n s t r u c t i o n .   A n y   o p i n i o n s ,   f i n d i n g s \n a n d   c o n c l u s i o n s   o r   r e c o m m e n d a t i o n s   e x p r e s s e d   h e r e   a r e   t h o s e   o f \n t h e   a u t h o r s   a n d   d o   n o t   n e c e s s a r i l y   r e f l e c t   t h o s e   o f   t h e   s p o n s o r s .",
  "references": [
    "Jafar Afzali, Krisztian Balog, '['POINTREC: A Test Collection for Narrative-Driven Point of Interest Recommendation', 'Association for Computing Machinery']', In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21), 2021",
    "Jaime Arguello, Fernando Diaz, 'Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification', In Proceedings of the 6th international ACM SIGIR Conference on Human Information Interaction and Retrieval, 2021",
    "Toine Bogers, Mette Skov, '['What was this Movie About this Chick?? A Comparative Study of Relevance Aspects in Book and Movie Discovery', 'Shefield']', In Transforming Digital Worlds: 13th International Conference, ['2018', '2018', '2018']"
  ],
  "keywords": [
    "Augmented Narrative Driven",
    "Language Model Augmented",
    "Model Augmented Narrative",
    "Model Augmented",
    "USA USA USA",
    "Narrative Driven",
    "UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst",
    "Augmented Narrative",
    "MAP MRR Recall",
    "cid",
    "USA USA",
    "UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst",
    "https",
    "USA",
    "language models",
    "Large Language Model",
    "Model Parameters NDCG",
    "Driven",
    "NDR",
    "Augmented"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1lwcHwr2fmVspHZdY3VsKeCb0J2kaRLr3"
}
{
  "id": 16,
  "title": "SMT 2.0: A Surrogate Modeling Toolbox with a focus on hierarchical and mixed variables Gaussian processes",
  "authors": [
    "Paul Saves",
    "Rmi Lafage",
    "Nathalie Bartoli",
    "Youssef Diouane",
    "Jasper Bussemaker",
    "Thierry Lefebvre",
    "John T. Hwang",
    "Joseph Morlier",
    "Joaquim R.R.A. Martins g"
  ],
  "institutions": [
    "German Aerospace Center (DLR), Institute of System Architectures in Aeronautics",
    "ICA, Universite? de Toulouse",
    "ISAE-SUPAERO, Universite? de Toulouse",
    "ONERA/DTIS, Universite? de Toulouse",
    "Polytechnique Montre?al",
    "University of California San Diego, Department of Mechanical and Aerospace Engineering"
  ],
  "resume": "journal homepage: www.elsevier.com/locate/advengsoft",
  "content": "- A R T I C L E I N F O\nDataset link: https://colab.research.google.com\n/github/SMTorg/smt/blob/master/tutorial/No\ntebookRunTestCases_Paper_SMT_v2.ipynb 1. Motivation and significance With the increasing complexity and accuracy of numerical models, it\nhas become more challenging to run complex simulations and computer\ncodes [1,2]. As a consequence, surrogate models have been recognized\nas a key tool for engineering tasks such as design space exploration,\nuncertainty quantification, and optimization [3]. In practice, surrogate\nmodels are used to reduce the computational effort of these tasks by\nreplacing expensive numerical simulations with closed-form\napproximations [4, Ch. 10]. To build such a model, we start by evaluating\nthe original expensive simulation at a set of points through a Design\nof Experiments (DoE). Then, the corresponding evaluations are used to\nbuild the surrogate model according to the chosen approximation, such\nas Kriging, quadratic interpolation, or least squares regression. The Surrogate Modeling Toolbox (SMT) is an open-source\nframework that provides functions to efficiently build surrogate models [5]. A B S T R A C T\nThe Surrogate Modeling Toolbox (SMT) is an open-source Python package that offers a collection of surrogate\nmodeling methods, sampling techniques, and a set of sample problems. This paper presents SMT 2.0, a major\nnew release of SMT that introduces significant upgrades and new features to the toolbox. This release adds\nthe capability to handle mixed-variable surrogate models and hierarchical variables. These types of variables\nare becoming increasingly important in several surrogate modeling applications. SMT 2.0 also improves SMT\nby extending sampling methods, adding new surrogate models, and computing variance and kernel derivatives\nfor Kriging. This release also includes new functions to handle noisy and use multi-fidelity data. To the best of\nour knowledge, SMT 2.0 is the first open-source surrogate library to propose surrogate models for hierarchical\nand mixed inputs. This open-source software is distributed under the New BSD license.2\nKriging models (also known as Gaussian processes) that take advantage\nof derivative information are one of SMT?s key features [6]. Numerical\nexperiments have shown that SMT achieved lower prediction error\nand computational cost than Scikit-learn [7] and UQLab  for a\nfixed number of points . SMT has been applied to rocket engine\ncoaxial-injector optimization , aircraft engine consumption\nmodeling , numerical integration , multi-fidelity sensitivity\nanalysis , high-order robust finite elements methods , planning\nfor photovoltaic solar energy , wind turbines design\noptimization , porous material optimization for a high pressure turbine\nvane , chemical process design  and many other applications. In systems engineering, architecture-level choices significantly\ninfluence the final system performance, and therefore, it is desirable to\nconsider such choices in the early design phases . Architectural\nchoices are parameterized with discrete design variables; examples\ninclude the selection of technologies, materials, component connections, Reference\nLicense\nLanguage\nMixed var. GD kernel\nCR kernel\nHH kernel\nEHH kernel\nHierarchical var.\n\nGPL\nR\n?\n*\n?\n*\nand number of instantiated elements. When design problems include\nboth discrete variables and continuous variables, they are said to have\nmixed variables. When architectural choices lead to different sets of design variables,\nwe have hierarchical variables . For example, consider\ndifferent aircraft propulsion architectures . A conventional gas turbine\nwould not require a variable to represent a choice in the electrical\npower source, while hybrid or pure electric propulsion would require\nsuch a variable. The relationship between the choices and the sets of\nvariables can be represented by a hierarchy. Handling hierarchical and mixed variables requires specialized\nsurrogate modeling techniques . To address these needs, SMT 2.0\nis offering researchers and practitioners a collection of cutting-edge\ntools to build surrogate models with continuous, mixed and hierarchical\nvariables. The main objective of this paper is to detail the new\nenhancements that have been added in this release compared to the original\nSMT 0.2 release [5]. There are two new major capabilities in SMT 2.0: the ability\nto build surrogate models involving mixed variables and the support\nfor hierarchical variables within Kriging models. To handle mixed\nvariables in Kriging models, existing libraries such as BoTorch ,\nDakota , DiceKriging , LVGP , Parmoo , and Spearmint\n implement simple mixed models by using either continuous\nrelaxation (CR), also known as one-hot encoding , or a Gower distance\n(GD) based correlation kernel . KerGP  (developed in R)\nimplements more general kernels but there is no Python open-source toolbox\nthat implements more general kernels to deal with mixed variables,\nsuch as the homoscedastic hypersphere (HH)  and exponential\nhomoscedastic hypersphere (EHH)  kernels. Such kernels require\nthe tuning of a large number of hyperparameters but lead to more\naccurate Kriging surrogates than simpler mixed kernels . SMT\n2.0 implements all these kernels (CR, GD, HH, and EHH) through a\nunified framework and implementation. To handle hierarchical\nvariables, no library in the literature can build peculiar surrogate models\nexcept SMT 2.0, which implements two Kriging methods for these\nvariables. Notwithstanding, most softwares are compatible with a nave\nstrategy called the imputation method  but this method lacks depth\nand depends on arbitrary choices. This is why Hutter and Osborne\n proposed a first kernel, called Arc-Kernel which in turn was\ngeneralized by Horn et al.  with a new kernel called the\nWedgeKernel . None of these kernels are available in any open-source\nmodeling software. Furthermore, thanks to the framework introduced\nin Audet et al. , our proposed kernels are sufficiently general so\nthat all existing hierarchical kernels are included within it. Section 4\ndescribes the two kernels implemented in SMT 2.0 that are referred\nas SMT Arc-Kernel and SMT Alg-Kernel . In particular,\nAlgKernel is a novel hierarchical kernel introduced in this paper. Table 1\noutlines the main features of the state-of-the-art modeling software that\ncan handle hierarchical and mixed variables. SMT 2.0 introduces other enhancements, such as additional\nsampling procedures, new surrogate models, new Kriging kernels (and their\nderivatives), Kriging variance derivatives, and an adaptive criterion for\nhigh-dimensional problems. SMT 2.0 adds applications of Bayesian\noptimization (BO) with hierarchical and mixed variables or noisy\ncoKriging that have been successfully applied to aircraft design , data\nfusion , and structural design . The SMT 2.0 interface is more\nuser-friendly and offers an improved and more detailed documentation\nfor users and developers.3 SMT 2.0 is hosted publicly4 and can be\ndirectly imported within Python scripts. It is released under the New\nBSD License and runs on Linux, MacOS, and Windows operating\nsystems. Regression tests are run automatically for each operating system\nwhenever a change is committed to the repository. In short, SMT 2.0\nbuilds on the strengths of the original SMT package while adding new\nfeatures. On one hand, the emphasis on derivatives (including\nprediction, training and output derivatives) is maintained and improved in\nSMT 2.0. On the other hand, this new release includes support for\nhierarchical and mixed variables Kriging based models. For the sake\nof reproducibility, an open-source notebook is available that gathers\nall the methods and results presented on this paper.5 The remainder of the paper is organized as follows. First, we\nintroduce the organization and the main implemented features of the\nrelease in Section 2. Then, we describe the mixed-variable Kriging\nmodel with an example in Section 3. Similarly, we describe and provide\nan example for a hierarchical-variable Kriging model in Section 4. The Bayesian optimization models and applications are described in\nSection 5. Finally, we describe the other relevant contributions in\nSection 6 and conclude in Section 7. 7. Conclusion SMT 2.0 introduces significant upgrades to the Surrogate Modeling\nToolbox. This new release adds support for hierarchical and mixed\nvariables and improves the surrogate models with a particular focus\non Kriging (Gaussian process) models. SMT 2.0 is distributed through\nan open-source license and is freely available online.14 We provide\ndocumentation that caters to both users and potential developers.15\nSMT 2.0 enables users and developers collaborating on the same\nproject to have a common surrogate modeling tool that facilitates the\nexchange of methods and reproducibility of results. SMT has been widely used in aerospace and mechanical modeling\napplications. Moreover, the toolbox is general and can be useful for\nanyone who needs to use or develop surrogate modeling techniques,\nregardless of the targeted applications. SMT is currently the only\nopensource toolbox that can build hierarchical and mixed surrogate models. Declaration of competing interest T h e   a u t h o r s   d e c l a r e   t h a t   t h e y   h a v e   n o   k n o w n   c o m p e t i n g \n f i n a n c i a l   i n t e r e s t s   o r   p e r s o n a l   r e l a t i o n s h i p s   t h a t   c o u l d   h a v e   a p p e a r e d   t o \n i n f l u e n c e   t h e   w o r k   r e p o r t e d   i n   t h i s   p a p e r . Data availability  Acknowledgments Data will be made available on request. Results can be reproduced\nfreely online at https://colab.research.google.com/github/SMTorg/smt/\nblob/master/tutorial/NotebookRunTestCases_Paper_SMT_v2.ipynb. We want to thank all those who contribute to this release. Namely,\nM. A. Bouhlel, I. Cardoso, R. Carreira Rufato, R. Charayron, R. Conde\nArenzana, S. Dubreuil, A. F. Lpez-Lopera, M. Meliani, M. Menz, N.\nMollo, A. Thouvenot, R. Priem, E. Roux and F. Vergnes. This work is\npart of the activities of ONERA - ISAE - ENAC joint research group. We\nalso acknowledge the partners institutions: ONERA, NASA Glenn,\nISAESUPAERO, Institut Clment Ader (ICA), the University of Michigan,\nPolytechnique Montral and the University of California San Diego. The research presented in this paper has been performed in the\nframework of the AGILE 4.0 project (Towards cyber-physical\ncollaborative aircraft development), funded by the European Union Horizon\n2020 research and innovation framework programme under grant\nagreement n? 815122 and in the COLOSSUS project (Collaborative\nSystem of Systems Exploration of Aviation Products, Services and\n13 https://smt.readthedocs.io/en/latest/_src_docs/examples/airfoil_\nparameters/learning_airfoil_parameters.html\n14 https://github.com/SMTorg/SMT\n15 https://smt.readthedocs.io/en/latest/ Business Models) funded by the European Union Horizon Europe\nresearch and innovation framework programme under grant agreement\nn? 101097120. We also are grateful to E. Hall-Hannan from Polytechnique\nMontral for the hierarchical variables framework. Appendix A. Toy test function This Appendix gives the detail of the toy function of Section 5.1.16\nFirst, we recall the optimization problem:\nmin  (cat , qnt )\nw.r.t. cat = 1 ? {0, 1, 2, 3, 4, 5, 6, 7, 8, 9} qnt = 1 ? [0, 1]\nThe toy function  is defined as\n (, 1) =11=0 cos(3.6( ? 2)) +  ? 1\n+11=1 2 cos(1.1 exp()) ?  + 2 2\n+11=2 cos(2) +\n1 2\n+11=3 (cos(3.4( ? 1)) ?  ? 1 ) 2\n+11=4 ? \n2\n2\n+11=5 2 cos(0.25 exp(?4))2 ?  + 1 2\n+11=6  cos(3.4) ?  + 1 2\n+11=7 ? (cos(3.5) +  ) + 2 2\n+11=8 ? \n2\n5 Appendix B. Hierarchical Goldstein test function This Appendix gives the detail of the hierarchical Goldstein problem\nof Section 5.2.17 First, we recall the optimization problem:\nw.r.t. cnaetu = 2 ? {0, 1}\nnqenut = (1, 2, 5, 3, 4) ? [0, 100]3  {0, 1, 2}2\nThe hierarchical and mixed function  is defined as a hierarchical\nfunction that depends on 0, 1, 2 and cont as describes in the\nfollowing.\n (1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2) = 11=00(1, 2, 1, 2, 3, 4, 5, 2)\n+ 11=11(1, 2, 3, 2, 3, 4, 5, 2)\n+ 11=22(1, 2, 4, 1, 3, 4, 5, 2)\n+ 11=3cont(1, 2, 3, 4, 3, 4, 5, 2).\n16 https://github.com/jbussemaker/SBArchOpt\n17 https://github.com/jbussemaker/SBArchOpt\nThen, the functions 0, 1 and 2 are defined as mixed variants of\ncont as such\n0(1, 2, 1, 2, 3, 4, 5, 2) =\n1\n1\n1\n2=0 (11=0cont(1, 2, 20, 20, 3, 4, 5, 2)\n+ 11=1cont(1, 2, 50, 20, 3, 4, 5, 2)\n+ 11=2cont(1, 2, 80, 20, 3, 4, 5, 2) )\n2=1 (11=0cont(1, 2, 20, 50, 3, 4, 5, 2)\n+ 11=1cont(1, 2, 50, 50, 3, 4, 5, 2)\n+ 11=2cont(1, 2, 80, 50, 3, 4, 5, 2) )\n2=2 (11=0cont(1, 2, 20, 80, 3, 4, 5, 2)\n+ 11=1cont(1, 2, 50, 80, 3, 4, 5, 2)\n+ 11=2cont(1, 2, 80, 80, 3, 4, 5, 2) )\n1(1, 2, 3, 2, 3, 4, 5, 2) =\n12=0cont(1, 2, 3, 20, 3, 4, 5, 2)\n+ 12=1cont(1, 2, 3, 50, 3, 4, 5, 2)\n+ 12=2cont(1, 2, 3, 80, 3, 4, 5, 2)\n2(1, 2, 4, 1, 3, 4, 5, 2) =\n11=0cont(1, 2, 20, 4, 3, 4, 5, 2)\n+ 11=1cont(1, 50, 2, 4, 3, 4, 5, 2)\n+ 11=2cont(1, 2, 80, 4, 3, 4, 5, 2)\nTo finish with, the function cont is given by\n(B.3)\ncont(1, 2, 3, 4, 3, 4, 5, 2) = 53.3108 + 0.1849011\n? 5.0291413.10?6 + 7.7252213 .10?8 ? 0.08707752 ? 0.1069593\n+ 7.9877234 .10?6 + 0.002424824 + 1.3285143.10?6 ? 0.0014639312 More at https://colab.research.google.com/github/SMTorg/smt/blob/\nmaster/tutorial/NotebookRunTestCases_Paper_SMT_v2.ipynb. Supplementary material related to this article can be found online\nat https://doi.org/10.1016/j.advengsoft.2023.103571.\n[1] Mader CA, Martins JRRA, Alonso JJ, van der Weide E. ADjoint: An approach\nfor the rapid development of discrete adjoint solvers. AIAA J 2008;46:863?73.\n[2] Kennedy M, O?Hagan A. Bayesian calibration of computer models. J R Stat Soc Ser B Stat Methodol 2001;63:425?64.\n[3] Hwang JT, Martins JRRA. A fast-prediction surrogate model for large datasets. Aerosp Sci Technol 2018;75:74?87.\n[4] Martins JRRA, Ning A. Engineering design optimization. Cambridge University Press; 2021.\n[5] Bouhlel MA, Hwang JT, Bartoli N, Lafage R, Morlier J, Martins JRA. A Python surrogate modeling framework with derivatives. Adv Eng Softw\n2019;135:102662.\n[6] Bouhlel MA, Martins J. Gradient-enhanced kriging for high-dimensional\nproblems. Eng Comput 2019;35:157?73.\n[7] Pedregosa F, Varoquaux G, Gramfort A, Thirion VMB, Grisel O, et al. Scikit-learn:\nMachine learning in Python. J Mach Learn Res 2011;12:2825?30.",
  "references": [
    "C Lataniotis, S Marelli, B Sudret, 'Uqlab 2.0 and uqcloud: open-source vs. cloud-based uncertainty quantification', In: SIAM conference on uncertainty quantification, 2022",
    "A Faraci, P Beaurepaire, N. Gayton, 'Review on Python toolboxes for Kriging surrogate modelling', In: ESREL, 2022",
    "M Krgener, J Zapata Usandivaras, M Bauerheim, A Urbano, 'Coaxial-injector surrogate modeling based on Reynolds-averaged Navier-Stokes simulations using deep learning', J Propuls Power, 2022"
  ],
  "keywords": [
    "met met met",
    "SMT",
    "met met",
    "met",
    "variables",
    "mixed variables",
    "Kriging",
    "Kriging model",
    "variable",
    "surrogate models",
    "kernel",
    "optimization",
    "mixed variables Kriging",
    "models",
    "Bayesian optimization",
    "SMT Alg-Kernel Kriging",
    "hierarchical variables",
    "mixed",
    "model",
    "design"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1Q5wUI4WjswDZoEekxYsilBFTVVYlkrOY"
}
{
  "id": 17,
  "title": "Numerical computing in engineering mathematics",
  "authors": [
    "Firuz Kamalov",
    "Ho-Hon Leung"
  ],
  "institutions": [
    "Department of Electrical Engineering, Canadian University Dubai",
    "Department of Mathematical Sciences, United Arab Emirates University"
  ],
  "resume": "2 2 Abstract-The rapid advances in technology over the last 0 decade have significantly altered the nature of engineering knowl2 edge and skills required in the modern industries. In response to l the changing professional requirements, engineering institutions u have updated their curriculum and pedagogical practices. HowJ ever, most of the changes in the curriculum have been focused on the core engineering courses without much consideration for the 1 auxiliary courses in mathematics and sciences. In this paper, we 1 aim to propose a new, augmented mathematics curriculum aimed ] at meeting the requirements of the modern, technology-based engineering workplace. The proposed updates require minimal Oresources and can be seamlessly integrated into the existing Hcurriculum. . Index Terms-engineering mathematics; numerical computing; th education; Industry 4.0 a m [",
  "content": "- I. INTRODUCTION The 4th Industrial Revolution has had a dramatic impact\n1 on the engineering profession. The modern technologies such\nv as artificial intelligence, the internet of things, and advanced\n8 robotics have altered engineering systems and processes.\nTo9\n6 day?s engineers are expected to be able to leverage these\n4 resources to produce their products. To meet the new\nprofes.0 sional requirements, engineering educational institutions have\n7 revised their curricula. The changes in the curricula include\n0 both updating the existing programs as well as\nintroduc2 ing completely new programs. Given the rapid technological\n:2 progress, universities and colleges around the world are\nconiv tsiingunoifiucsalyntapdraopgtirnegsstion tmheodeverenr-izcihnagngthinegenegnivnieroenrimngenctu.rWrichuilluema\nrXhas been achieved, there still remains room for improvement.\na Catalyzed by the exponential increase in computational\npower and interconnectedness, the modern industrial\nrevolution has reshaped the skills and competencies required of the\nengineers. The changes in engineering curricula in response to\nIndustry 4.0 have been threefold: i) modernizing the existing\nprograms, ii) introduction of new programs, and iii) revising\nthe pedagogical approach. Modernizing the existing programs\ninvolves introduction of new courses in the study plan related\nto emerging technologies. In addition, existing courses can be\nupdated with new content. Fresh new programs in emerging\n 2022 IEEE. Personal use of this material is permitted. Permission from\nIEEE must be obtained for all other uses, in any current or future media,\nincluding reprinting/republishing this material for advertising or promotional\npurposes, creating new collective works, for resale or redistribution to servers\nor lists, or reuse of any copyrighted component of this work in other works\ntechnologies are also introduced by universities and colleges.\nMany institutions now offer degrees in artificial intelligence\nand mechatronics which were not there 20 years ago. Finally,\nuniversities have revised their approaches to course delivery.\nStudent-centered learning, project-based learning, and applied\nlearning have become popular in the new engineering\neducational paradigm. While significant effort has been made to revise the core\nengineering courses, the auxiliary courses in mathematics and\nsciences received little consideration. The mathematics and\nsciences courses play a key role in the engineering curriculum.\nGiven their importance, the curriculum updates must also be\nextended to the auxiliary courses. By implementing a\ncomprehensive update of the engineering curriculum that includes\nboth the core and auxiliary courses, a more effective outcome\ncan be achieved. The goal of this paper is to propose a modernized\nengineering mathematics curriculum in line with the broader efforts to\nupdate engineering education to adapt to Industry 4.0. The key\nfeature of the new curriculum is the introduction numerical\ncomputing in the existing mathematics courses. The latest\nindustrial revolution has been driven largely by the dramatic\nincrease in computational power. Therefore, today?s engineers\nmust be well-equipped to leverage the computing power in\ntheir work. Since mathematics courses are usually taken at the\nbeginning of the study plan, it offers a natural avenue for introducing\nnumerical computing to students. Furthermore, many problems\nin mathematics can be solved numerically making it natural\nto integrate numerical computing in mathematics courses.\nBy studying numerical computing in mathematics courses,\nstudents will acquire the necessary theoretical and practical\nskills to apply in their downstream, specialized engineering\ncourses. This paper is structured as follows. Section 2 provides an\noverview of the existing efforts to update the engineering\ncurriculum in response to Industry 4.0. Section 3 discusses\nthe current approaches to integrate scientific computing in\nmathematics courses. In Section 4, we present our proposal\nfor modernizing the mathematics curriculum to integrate\nnumerical computing. Section 5 concludes the paper with final\nremarks. II. ENGINEERING EDUCATION AND INDUSTRY 4.0 Engineering departments in colleges and universities have\nmade significant changes in their curricula in response to\nthe new environment created by the recent, rapid advances\nin technology. In particular, the existing programs have been\nupdated to include courses that target emerging technologies.\nCompletely new programs related to AI and mechatronics\nhave also been adopted by universities. Innovations in the\nfield of engineering education continue to take place with new\ndevelopments on the horizon. There exist several studies investigating the modern\nengineering curricula and evaluating their effectiveness. It is\nargued in  that engineering educators must prepare their\nstudents to face three key challenges: sustainability, the 4th\nIndustrial Revolution, and employability. The authors find that\ncolleges and universities are responding to these challenges by\nemphasizing student-centered learning, integration of theory\nand practice, digital and online learning, and the definition of\nprofessional competencies. In particular, response to the needs\nof Industry 4.0 require interdisciplinary collaboration across\nseveral programs and disciplines. Interaction and integration\nof technologies plays a key role in this process , .\nInterdisciplinary engineering education requires sound pedagogy\nand teaming experiences to encourage student in collaborative\nand interdisciplinary practice . Digital and online learning have become an important part\nof modern education including in the field of engineering.\nInformation technologies play a vital role in delivering digital\nlearning to students. Colleges and universities have made\nsignificant investments to improve their information and\ncommunication technology (ICT) capacities . In response to the needs of Industry 4.0, some\nuniversities have adopted the framework of Education 4.0 ,\n. The new education framework consists of four main\ncomponents: i) competencies, ii) learning methods, iii) ICT,\nand iv) infrastructure. Students competencies are based on\ntechnological knowledge and skills for successful workplace\nperformance, while the learning methods are based on problem\nsolving and challenge-based learning. In particular, active and\nproject-based learning plays an important role in Education\n4.0 , . Other innovative approaches to learning such as\nvirtual-reality based engineering education can help improve\nthe learning process related to Industry 4.0 . In addition to technological progress, socio-cultural shifts\nmust be taken into account in revising engineering curriculum.\nThe new generation of students has its unique worldview\nwhich needs to be considered by the educators. In particular,\nthe new generation is significantly affected by mobile devices\nand digital media. Educational content must be tailored to\nthe new student preferences to achieve effective learning\noutcomes . Innovative approaches such gamification may\nhelp improve the learning process , . Many universities have also introduced nontechnical updates\nto their engineering curriculum. The most significant\nnontechnical update has been the introduction of entrepreneurship\ncourses and experiences for students. A lot of attention has\nrecently been given to equipping students with entrepreneurial\nskills. Students learn about entrepreneurship in their courses\nas well as through university incubators. III. UNIVERSITY MATHEMATICS CURRICULUM The mathematics curriculum changed very little in the\ncurrent century. It remains a largely analytic domain, where\nsolutions are mainly obtained manually. The current mathematics\ncurriculum emphasizes theory over practical approaches. For\ninstance, when finding the extreme values of a function,\nderivative-based approach is preferred over the gradient\ndecent. There are two key reasons for why analytical approaches\nare favored over numerical methods. First, analytical solutions\nare reliable and elegant. An analytical solution is guaranteed\nto be exact. Second, mathematics courses are usually taught\nby pure mathematicians who have an inherent preference\nfor analytical solutions. Pure mathematics which is based on\ntheorem proving is not amenable to numerical methods. Despite the popularity of analytical approaches to problem\nsolving in mathematics, there has been a growing push to\nintegrate computer algebra systems as part of the learning process.\nComputer algebra systems such as Matlab and Mathematica\nare now routinely used in many mathematics courses. The\nstudy by Cretchley et al.  found that engineering students\nwere positive about the use of technology as a learning tool\nin mathematics courses. The increased use of technology in\nclass helped improve student focus and interest in lectures.\nStudent evaluations also indicated that they had a greater level\nof enjoyment towards the lectures due to the use of technology.\nIt is noteworthy that students chose not to rely too heavily on\ntechnology during the examinations despite the freedom to do\nso. The students found it extremely important to be competent\nwith analytical mathematical skills as opposed to purely\ncomputational skills. Some revealed that they learn the subjects\nequally well without the help of scientific packages, although\nthe perception towards the use of computer is in general highly\npositive. Almost all students responded positively to Matlab\nas an effective tool for computation and graphing. Many\nused Matlab for non-examination purposes. For example, they\nutilized it to check their handwritten mathematical steps in\nassignments and practice problems; and others used it for\nexploration beyond the standard syllabus and curriculum. The influence of computer technology on students?\nacademic performance and learning experience has been\ninvestigated by several authors. Abdul Majid et al. ,  used\nMatlab as an aid to teach calculus to engineering students.\nThe software package was used for various course learning\noutcomes such as graphical display of mathematical functions,\nexploration, identifying and predicting structural patterns in\nevaluating a series of complex indefinite integrals, and\nnumerical approximations in applied mathematics. The study showed\na positive impact on students? academic performance in the\nfinal examinations. The study concluded that the integration\nof scientific packages into engineering mathematics courses\ncould be effective under certain conditions. Similarly, other\nstudies ,  also found a positive impact from the use\nof scientific software packages on students? motivation in\nlearning mathematics. In a separate study by Brake , the authors investigated the\nuse of Matlab in engineering mathematics courses to increase\nstudent confidence level and mathematical abilities. Matlab\nwas used to solve concrete engineering problems which require\na deep understanding of underlying mathematical principles.\nThe study found generally positive student response to the\nuse of software in their mathematics courses. However, the\nresults of the study must be considered carefully given the\nsmall sample size of the subjects. Although the majority of the studies were based on the\nuse of Matlab, several other studies considered alternative\nmathematics software packages. The study by Kilicman et al.\n focused on the use of Maple to help students understand\nboth the theoretical and computational aspects of linear algebra\nfor engineering students. In particular, it was shown that the\nuse of Maple facilitates the understanding of computational\naspects of eigenvalues and eigenvectors. It allows students more\ntime to focus on the theoretical aspects and the underlying\nmathematical principles. In a recent study by Mezhennaya and Pugachev , the\nauthors compared engineering students? perceptions regarding\nseveral mathematical software: Matlab, Mathematica and\nExcel. The study found that all the scientific packages considered\ncan be used in education, under the condition that the policies\nfor software usage are carefully implemented. The study\nfound that many students lack hands-on experience on how\nto use the software. The students particularly struggled with\nMatlab and Mathematica finding them non user friendly. The\nstudy concluded that additional classes are required to prepare\nstudents to use software in their courses. IV. NUMERICAL COMPUTING IN MATHEMATICS CURRICULUM Mathematics lies at the foundation of science and\nengineering. The importance of mathematics courses in engineering\neducation cannot be underestimated. These courses equip\nstudents with the fundamental skills and knowledge to study the\nmore specialized engineering courses. Thus, student success in\nengineering studies depends directly on the mathematics and\nsciences courses. Given the significance of the mathematics\ncourses in the engineering curriculum, it is paramount to\nensure their currency with respect to the Industry 4.0. The technological advances over the last decade have\ncreated demand for more computationally proficient experts.\nTo meet this demand, numerical computing must become a\ncore part of engineering studies. Mathematics courses offer\na natural and convenient avenue for introducing numerical\ncomputing to engineering students. There are two main\nfactors that make mathematics courses particularly amenable\nto numerical computing. First, in many cases mathematical\nproblems have numerical solutions. For instance, finding the\nroot of a polynomial or the minimum value of a function\ncan be done numerically. Therefore, it is both logical and\nappropriate to apply numerical computing to mathematical\nproblems. Second, mathematics courses are usually taken\nat the beginning of the study plan. Thus, students become\nacquainted with numerical computing at an early stage. The\ncomputing and programming skills acquired in this manner\nwill have a positive effect in the more advanced, downstream\nengineering courses. The key idea for the proposed curriculum update is the\naddition of computing tutorials (labs) to mathematics courses.\nIn particular, we propose adding weekly computing tutorials\n(labs) related to the main lecture material. For instance, in the\nweek in which students cover finding the extreme values of a\nfunction, there will be a computing tutorial where students\nlearn and implement the gradient descent algorithm. The\nsuggested length of each tutorial is 1 hour. It is enough\ntime to implement most of the numerical algorithms at the\nundergraduate level. At the same time, 1 extra hour per week\nwill not overburden the students. The exact details of numerical computing content is left\nfor individual universities and instructors. Depending on the\nsyllabus and course learning outcomes, the numerical\ncomputing labs will be different for each university and instructor.\nNevertheless, the general ideas will be broadly similar across\ndifferent curricula. To illustrate the proposed numerical\ncomputing content, we will focus on the three main concept in\ncalculus: limits, derivatives, and integrals.",
  "references": [
    "Abdul Majid, M. Huneiti, Z. Balachandran, W. Al-Naafa,  M. A.,  Villach, 'A study of the effects of using MATLAB as a pedagogical tool for engineering mathematics students', 15th International Conference on Interactive Collaborative Learning (ICL), ['2012', '2012']",
    "Abdul Majid, M. Huneiti, Z. A. Balachandran, W. Balarabe,  Y., 'MATLAB as a teaching and learning tool for Mathematics: A literature review', International Journal of Arts and Sciences, 2013",
    "surname, given-names, #text, 'MATLAB as a Tool to Increase the Math SelfConfidence and the Math Ability of First-Year Engineering Technology Students', The Scholarship of Teaching and Learning at EMU:, 2007"
  ],
  "keywords": [
    "mathematics",
    "engineering",
    "Numerical computing",
    "Numerical",
    "students",
    "engineering education",
    "computing",
    "engineering students",
    "learning",
    "engineering mathematics",
    "education",
    "Matlab",
    "mathematics curriculum",
    "software engineering education",
    "software",
    "curriculum",
    "based engineering education",
    "Industry",
    "Limit",
    "study"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1fJLpGYisBdPC3-AbDgDc-hn3X0QE7lO8"
}
{
  "id": 18,
  "title": "Fuzzy logic based MPPT control for a PV system using SEPIC converter",
  "authors": [
    "Moulay Abdellah Alhachemi",
    "Mansour Becahr",
    "Mohammed Habbab",
    "Hicham Gouabi",
    "Abdeldjebar Hazzab"
  ],
  "institutions": [
    "E?cole de Technologie Supe?rieure",
    "E?cole de Technologie Supe?rieure",
    "Laboratoire de CAOSEE, Universite? Tahri Mohamed",
    "Laboratory of CAOSEE, Universite? Tahri Mohamed",
    "Laboratory of CAOSEE, Universite? Tahri Mohamed"
  ],
  "resume": "-In this study, a novel single-ended primary inductor (SEPIC) converter-based fuzzy logic controller for maximum power point tracking is presented. By adding rules to the perturb and observing search strategy, the new controller enhances it while fuzzifying and removing its flaws. When compared to traditional maximum power point tracking techniques, fuzzy logic trackers enable an accurate and quick convergence to maximum power point under both steady-state and variable weather situations. The performance of the proposed maximum power point tracker is demonstrated in simulation.",
  "content": "I. INTRODUCTION The non-renewable energy sources are rapidly running out,\nwhile the electricity demand is increasing daily. To solve this\nproblem, efficient and efficient electric power generation from\nrenewable energy sources is required . Renewable energy is\none of the forms of energy that society can rely on because It\nis unpolluted, pure, and has no limits. One type of power\ngeneration that uses renewable energy is the photovoltaic (PV)\nsystem . To utilize less conventional energy, the PV system\nmust subsequently be linked to the grid, either directly or via a\nbackup battery bank. Since the power produced by PV\nsystems depends on radiation and temperature change, the PV\nframework has destitute productivity, . For the control of the PV systems, there are different sorts of\nDC-DC converters such as Buck converters, Boost converters,\nand Buck-Boost converters. Due to its output pick-up\nadaptability, a single-ended primary-inductor converter\n(SEPIC) acts as a buck-boost DC/DC converter, where it\nchanges its output voltage agreeing to its duty cycle. Unlike the\ncustomary buck-boost converter, the SEPIC converter includes\na non-inverted output and it uses an arrangement capacitor to\nseparate input from output . The buck and buck-boost\nconverters lose half of their input control due to input current\narrangement exchange; for that reason, the two types of\nconverters should be excluded from maximum power\napplications. The boost converter has a nonstop input current,\nbut the output voltage is always bigger than the input, which\nmay not accomplish maximum power exchange operation in a\nfew cases, such as when the maximum voltage is less than the\ninput . This paper presents a fuzzy-based P&O strategy for an MPPT\nstandalone PV system. The proposed MPPT can abuse the\npreferences of the P&O strategy and eliminate its drawbacks.\nOutput has been separated into five fuzzy subsets. As the\nproposed strategy continuously exchanges maximum power\nfrom PV arrays, it optimizes the number of PV modules. II. MODELIGN OF PV SYSTEM Photovoltaic is the technique and study connected to devices\nthat directly convert sunlight into electricity utilizing\nphotovoltaic semiconductors. Direct conversion of solar energy\ninto DC electrical energy can be achieved by photovoltaic cells\n. The photovoltaic panel is made up of numerous cells that\nare connected in series Ns or shunt Nsh. Where it may be\nmimicked by a current source coupled in parallel with a diode\nas described by and depicted in Figure 1 . The shunt resistance (Rsh) is typically orders of magnitude\nlarger than the series resistance (Rs) . Therefore, it is\ncommon for the shunt and series resistances of a solar cell can\nbe neglected to simplify the model. The resulting ideal\nvoltagecurrent characteristic of the solar cell is given by equation (3).\nI = Iph ? I0 [e(KqVT) ? 1] III. SEPIC CONVERTER Power electronics researchers are working hard to create\nDCDC converters with simpler designs and greater efficiency .\nTo maintain a constant output voltage, the suggested DC-to-DC\nconverter employs a single-ended primary-inductor converter\n(SEPIC) architecture. The SEPIC converter is made up of a duty\ncycle switch S, a diode, two inductors (L1 and L2), two\ncapacitors (C1 and C2), and a load resistor. Figure 2 depicts the\ncircuit diagram of a SEPIC converter. A SEPIC is a DC-DC\nconverter . SEPIC are DC-DC converters that can output\nvoltages that are B, larger than, or equal to the input voltage.\nThe duty cycle of the control transistor affects the SEPIC\nconverter's output voltage. The SEPIC converter is two\nconverters in one: a boost converter followed by a buck-boost\nconverter. It has the advantages of having a non-inverted output\n(the output voltage has the same polarity as the input voltage) ,\nusing a series capacitor to couple energy from the input to the\noutput (which makes it more responsive to short-circuits), and\nbeing able to shut down completely: when the switch \"S\" is\nturned off, the output voltage drops to 0 V, accompanied by a\nsignificant transient discharge of charge.\nFigure 3 depicts the circuit when the power switch is switched\non and off (in Figures a and b, respectively). Figure 3a When\nthe switch is on, the first inductor, L1 is charged from the input\nvoltage source. The second inductor L2 absorbs energy from\nthe first capacitor C1, leaving the output capacitor C2 to supply\nthe load current. When the switch is turned on, the input inductor is charged\nfrom the source, and the second inductor is charged from the\nfirst capacitor. No energy is supplied to the load capacitor\nduring this time. The inductor current and capacitor voltage\npolarities are marked in this Figure. When the power switch is\nturned off, the energy stored in the inductor is transferred. The\nenergy stored is transferred through the diode and supplies the\nenergy to the load , as shown in Figure 3. b. The second\ninductor is also connected to the load during this time. The\noutput capacitor sees a pulse of current during the off time,\nmaking it inherently noisier than a buck converter. The amount\nthat the SEPIC converters increase or decrease the voltage\ndepends primarily on the duty cycle and the parasitic elements\nin the circuit. The output of an ideal SEPIC converter is:\nVout = 1?DD Vin (4) A SEPIC converter is to process the electricity from the PV\nsystem. This converter either increases or decreases the PV\nsystem voltage at the load. The proposed SEPIC converter\noperates in buck mode. In the fuzzy logic maximum power point tracking (MPPT)\nalgorithm, the voltage and current at each instant k are\nmeasured to calculate the active power. The active power is\nthen compared with the power at the previous instant (k-1) to\nobtain the change in power (?P(k)). Similarly, the voltage at\ninstant k is compared with the voltage at instant k-1 to obtain\nthe voltage error (?V(k)) . The power error is then divided\nby the current error to obtain the error (E). The error is then\ncompared with the previous error to calculate the change in\nerror (?E(k)). The error (E(k)) and the change in error (?E(k))\nare then used as the crisp inputs to the fuzzy logic controller.\nThe flow chart for the fuzzy logic MPPT algorithm is shown in\nFigure 4. In this work, the Mamdani inference technique,\nAtype membership functions, and a 25-element rule base were\nused for the fuzzy logic control. The Mamdani inference\ntechnique is efficient and straightforward in defining the fuzzy\noutput sets, and it is more popular among researchers than other\ninference techniques . The A-type or triangular\nmembership function is used because it is simpler to split into\nlow and high membership functions (MFs) than other\nmembership functions. Additionally, it has been observed that\nthe triangular membership function has a faster response and\nless overshoot than other functions . A 25-element rule base\nwas used because it has been shown to perform well . Table. 1. Fuzzy logic rules for the push-pull converter. NB,\nnegative big; NS, negative small; ZE, zero; PS, positive small; PB, positive big.\n?Vpv*[o/p] ?Vpv*[i/p]\n?Ppv*[i/p] NB\nNS\nZE\nPS\nPB NB\nPS\nPS\nZE\nNS\nNS NS\nNB\nPS\nZE\nNS\nNB ZE\nNB\nNS\nZE\nPS\nPB PS\nNB\nNS\nZE\nPS\nPB PB\nNS\nNS\nZE\nPS\nPS The following are the fuzzy rules in Table 1, which are used\nfor the desired MPP of push-pull converter PWM. The\nmembership for input variables (DPpv, DVpv) are shown in\nFigure 5, and the membership for output variable (DVpv*) is\nshown in Figure 6. All the functions are defined on a normalized\ninterval [-1 1]. Fig. 5. Membership for input variables. V. SIMULATION RESULTS The characteristics of the photovoltaic array that we use in this paper are given in Table 2. Table. 2. Electrical data of photovoltaic array. Overall, using MPPT and fuzzy logic to a SEPIC converter for\na PV system result in considerable performance gains.\nIncreased power output, higher efficiency, decreased ripple,\nenhanced transient response, and resilience are examples of\nthese enhancements. ?. CONCLUSIONS This paper presents the design of an off-grid photovoltaic\nsystem with a fuzzy logic MPPT-controlled push-pull boost\nconverter. The proposed system was simulated in\nMATLAB/Simulink and tested under various weather\nconditions. The results showed that the fuzzy logic algorithm\noutperformed the conventional algorithms in terms of MPPT\naccuracy and minimization of fluctuations, regardless of rapid\nchanges in irradiance.",
  "references": [
    "given-names, surname, 'Ant Colony Optimized Tuned DC-DC converter', International Journal of Computer Applications, 2013",
    "given-names, surname, '?Performance Comparison between ?UK and SEPIC Converters for Maximum Power Point Tracking Using Incremental Conductance Technique in Solar Power Applications', ['International Journal of Electrical', 'Electronic and Communication Engineering'], 2013",
    "M. Cirrincione, M. Pucci, 'Growing Neural Gas (GNG)- Based Maximum Power Point Tracking for High-Performance Wind Generator With an Induction Machine', ? IEEE Transactions on Industry Applications 47.2, 2011"
  ],
  "keywords": [
    "SEPIC converter",
    "maximum power point",
    "Fuzzy logic",
    "maximum power",
    "SEPIC",
    "power",
    "fuzzy logic controller",
    "converter",
    "Fuzzy",
    "power point tracking",
    "power point",
    "Habbab Abdeldjebar Hazzab",
    "Abdellah Alhachemi Mohammed",
    "Alhachemi Mohammed Habbab",
    "Mohammed Habbab Abdeldjebar",
    "logic maximum power",
    "system",
    "voltage",
    "fuzzy logic maximum",
    "Universit Tahri Mohamed"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1NUMqDZ5WOrqgf7jO5y0XSavN8bINmrHZ"
}
{
  "id": 10,
  "title": "The Programmer's Assistant: Conversational Interaction with a Large Language Model for Software Development",
  "authors": [
    "Steven I. Ross",
    "Fernando Martinez",
    "Stephanie Houde",
    "Michael Muller",
    "Justin D. Weisz",
    "code-fluent large language models, foundation models, conversa-"
  ],
  "institutions": [
    "IBM Argentina",
    "IBM Research AI",
    "IBM Research AI",
    "tional interaction"
  ],
  "resume": "Large language models (LLMs) have recently been applied in software engineering to perform tasks such as translating code between programming languages, generating code from natural language, and autocompleting code as it is being written. When used within development tools, these systems typically treat each model invocation independently from all previous invocations, and only a specific limited functionality is exposed within the user interface. This approach to user interaction misses an opportunity for users to more deeply engage with the model by having the context of their previous interactions, as well as the context of their code, inform the model's responses. We developed a prototype system - the Programmer's Assistant - in order to explore the utility of conversational interactions grounded in code, as well as software engineers' receptiveness to the idea of conversing with, rather than invoking, a code-fluent LLM. Through an evaluation with 42 participants with varied levels of programming experience, we found that our system was capable of conducting extended, multi-turn discussions, and that it enabled additional knowledge and capabilities beyond code generation to emerge from the LLM. Despite skeptical initial expectations for conversational programming assistance, participants were impressed by the breadth of the assistant's capabilities, the quality of its responses, and its potential for improving their productivity. Our work demonstrates the unique potential of conversational interactions with LLMs for co-creative processes like software development.",
  "content": "CCS CONCEPTS ?   H u m a n - c e n t e r e d   c o m p u t i n g   ?   H C I   t h e o r y ,   c o n c e p t s   a n d \n m o d e l s ;   ?   S o f t w a r e   a n d   i t s   e n g i n e e r i n g   ?   D e s i g n i n g   s o f t w a r e ; \n ?   C o m p u t i n g   m e t h o d o l o g i e s   ?   G e n e r a t i v e   a n d   d e v e l o p m e n t a l \n a p p r o a c h e s . \n 1 INTRODUCTION Software development is a highly skilled task that requires\nknowledge, focus, and creativity . Many techniques have been\ndeveloped to enhance the productivity of software engineers, such\nas advanced code repositories , knowledge repositories ,\nQ&A sites , and pair programming practices . Collaborative\nsoftware engineering is especially promising, given that\nprofessional software development is rarely a solo activity and relevant\nknowledge and expertise are typically distributed widely within an\norganization . Many eforts have focused on incorporating\ncollaborative technologies into software development environments\n(e.g. ). The pioneering work of Rich and Waters on The Programmer?s\nApprentice  presented a novel concept of a knowledgeable\nautomated assistant ? in efect, an artificial collaborative partner ? that\ncould help software engineers with writing code, designing\nsoftware systems, and creating requirements specifications. At the time,\nAI technologies and computing resources were not suficient to\nfully implement their vision. In the intervening years, an increase in\ncomputational power, the availability of large corpora of language\nand code data, and the development of deep neural networks have\nmade new approaches to achieving their goals worth exploring. Recently, models leveraging the transformer architecture \nhave been developed to perform domain-specific software\nengineering tasks, such as translating code between languages ,\ngenerating documentation for code , and generating\nunit tests for code  (see Talamadupula  and Allamanis et al.\n for surveys). Recently developed foundation models ? large\nlanguage models that can be adapted to multiple tasks and which\nexhibit emergent behaviors for which they have not been\nexplicitly trained  ? have also proven to be capable with source code.\nWhile the intent of training LLMs such as GPT-2  and GPT-3 \nwas to give them mastery of natural language, it quickly became\napparent that the presence of code in their training corpora had\ngiven them the ability to generate code based on natural language\ndescriptions . The Codex model  was then produced by\nfinetuning GPT-3 on a large corpus of source code data, leading to the\ndevelopment of Copilot , a tool that helps software engineers by\nautocompleting code as it is being written. Experimentation with\nCopilot has shown its ability to perform additional tasks, such as\nexplaining code, generating documentation, and translating code\nbetween languages . Although autocompletion interfaces are useful and valuable\nwhen the system can discern the developer?s intent, there are many\ninstances where that is insuficient. For example, the developer\nmay have a good idea of what they want to do, but may be unclear\non what functions, libraries, or even algorithms to employ. They\nmay even have general programming questions that need to be\nanswered before they are able to write any code. In this paper, we seek to understand whether modern\ndevelopments in code-fluent foundation models ? large language models\nthat have been fine-tuned on source code data ? are suficient to\nsupport a conversational agent that can act as an assistant in the\nsoftware development process. We developed the Programmer?s\nAssistant to explore the capabilities that conversational interaction\ncould enable and the extent to which users would find\nconversational assistance with programming tasks desirable and useful. We hypothesize that a conversational system may provide a\nlfexible and natural means for interacting with a code-fluent LLM.\nConversational interaction could enable users to pursue their\nquestions in a multiple exchange dialog (as observed by Barke et al.\n) that allows them to ask follow-up questions and refine their\ninquiries. A conversational programming assistant could ask the\nuser clarifying or disambiguating questions to help it arrive at the\nbest answer. It could also provide multiple types of assistance to\nthe user beyond simply generating code snippets, such as engaging\nin general discussion of programming topics (e.g. ) or\nhelping users improve their programming skills (as observed in other\nstudies of automating technologies ). Our paper makes the following contributions to the IUI\ncommunity:\n? We provide empirical evidence that a conversational\nprogramming assistant based on a state-of-the-art, code-fluent\nfoundation model provides valuable assistance to software\nengineers in a myriad of ways: by answering general\nprogramming questions, by generating context-relevant code,\nby enabling the model to exhibit emergent behaviors, and by\nenabling users to ask follow-up questions that depend upon\ntheir conversational and code contexts.\n? We show how diferent interaction models ? conversation,\ndirect manipulation, and search ? provide complementary\ntypes of support to software engineers with tradeofs\nbetween the user?s focus and attention, the relevance of\nsupport to their code context, the provenance of that support,\nand their ability to ask follow-up questions.\n? We motivate the need to further understand how to design\nhuman-centered AI systems that enhance the joint\nperformance of the human-AI collaboration.\n2 RELATED WORK xref #text The Programmer?s Apprentice xref #text Code-fluent Foundation Models and  Human-Centered Evaluations of  Programming Assistance Generative models based on the transformer architecture  have\nrecently been applied to the domain of software engineering.\nCodelfuent large language models are capable of generating code from\nnatural language descriptions , translating code from one\nlanguage to another , generating unit tests , and even\ngenerating documentation for code . These models are\nprobabilistic systems, and as such, do not always produce perfect\nresults (e.g. code that is free of syntax or logical errors). Nonetheless,\nWeisz et al.  found that software engineers are still interested\nin using such models in their work, and that the imperfect outputs\nof these models can even help them produce higher-quality code\nvia human-AI collaboration . New tools based on code-fluent LLMs are actively being\ndeveloped. GitHub Copilot1 is described as ?Your AI pair programmer.? It\nis optimized for the code autocompletion use case: given a starting\nsnippet such as a method?s documentation, signature, or partial\nimplementation, Copilot completes the implementation. Copilot is\nbased on the OpenAI Codex model , a 12 billion parameter\nversion of GPT-3 , fine-tuned on code samples from 54 million\npublic software repositories on GitHub. Empirical evaluations of Conversational Interaction and Analysis 2.3.1 Conversational Interaction. Using natural language to\ninteract with technology has had a long research history , starting in\nthe 1960s with pattern-matching approaches like Eliza , and\ncontinuing to today with state-of-the-art large language\nmodelbased conversational systems  such as Meena  and\nBlenderBot . These systems are intended to address the problem of\nopen-domain dialog, with a goal of realistically engaging in\nconversation, but not particularly in a goal-directed or task-oriented\nmanner. Task-oriented chatbots are typically built with frameworks such\nas the Microsoft Bot Framework2, Google DialogFlow3, and IBM\nWatson Assistant4. They operate using pre-defined dialogue trees\nand use natural language processing to detect conversational intents\nand extract contextual entities. This structure enables the creation of\nspecial purpose, but fairly limited and rigid, conversational agents. There have been several recent attempts to investigate\nconversational programming assistance. Kuttal et al.  conducted a\nWizard of Oz study in which a pair programmer was replaced with\na conversational agent, and they found that ?agents can act as\neffective pair programming partners.? The PACT system  is a\nchatbot that assists programmers adjusting to new programming THE PROGRAMMER?S ASSISTANT In order to explore conversational programming assistance, we\ncreated a functional prototype system called The Programmer?s\nAssistant. Our prototype, shown in Figure 1, combines a code editor\nwith a chat interface. The code editor was implemented using the\nMicrosoft Monaco Editor5 embedded in a React wrapper6. The\nchat user interface was implemented using the React-Chatbot-Kit7\nframework. To drive the conversational interaction, we employed\nOpenAI?s Codex model , accessed through its web API. We developed our prototype as a lightweight coding\nenvironment in order to examine the user experience of interacting with\na conversational assistant. Our work was exploratory in nature,\nand thus we did not have specific design goals for the prototype\nbeyond integrating a code editor with a code-fluent LLM. We also\ndid not attempt to target the prototype for a specific class of users\n(e.g. novices or experts) or use cases (e.g. writing code vs. learning a\nnew programming language), as we wanted any value provided by\nconversational assistance to emerge from our user study. We also\ndid not implement the ability to run or debug code in our prototype\nas we wanted to explore the nature of the conversational\ninteraction rather than having users focus extensively on the production\nof working code. When designing how users would interact with the\nProgrammer?s Assistant, we decided that it should be available on demand\nand not monitor the user?s work in progress or give unsolicited\nsuggestions or advice, in keeping with the conversational agent\ninteraction model proposed by Ross et al. . This approach\nwas supported by feedback from prospective users who were\nconcerned about the assistant providing criticism of unfinished eforts\nin progress or distracting them while they worked. Instead, we\nforce initiative onto the user and only have the assistant respond\nto their requests. In this way, the assistant can provide help when\nrequested without undesirable interruptions that can distract or\ninterfere with the user?s flow. When a user interacts with the assistant, we keep track of their\nselection state in the code editor. If a user sends a message to the\nassistant without any code selected in the editor, then that message\n(along with the prior conversational context) is passed directly to\nthe model. If a user sends a message to the assistant with new code Supporting Conversational Interaction xref #text Architecture & UI Design The Programmer?s Assistant communicates with the Codex API via\na proxy server that forwards requests from the React client. The\nproxy also rate-limits access to conform to the API?s policy, and\nit logs UI events from the client (e.g. requests, responses, and UI\n8The assistant?s use of non-authoritative responses was encoded into the LLM prompt;\noutput token probabilities from the LLM were not utilized to influence the assistant?s\nresponse.\ninteractions) in a back-end database. To address inconsistencies\nin the style or formatting of code generated by Codex, the proxy\nserver reformats all code segments using the Black code formatter\n9 before transmitting them to the client UI. The client maintains the transcript of the ongoing conversation.\nEach time the user sends a message in the chat, the client constructs\na new prompt for the model by concatenating the initial prompt,\nthe chat transcript, and the user?s new utterance, and makes a\nrequest for the model to complete the transcript. This completion\nrequest also specifies a stop sequence of tokens to prevent the\nmodel from generating both sides of the conversation (e.g. what\nthe model thinks the user?s next utterance might be after the\nassistant?s response). Given the API?s limitation on context length\n(4,096 tokens for both the prompt and model response), we silently\n?forget? older exchanges in the chat transcript when constructing\nthe prompt to ensure that our completion request remains within\nbounds. Nonetheless, the entire conversational history remains\nvisible to the user in the UI. The client UI provides a loose coupling between the source code\neditor and the chat interface. Users can hide the chat pane when\nthey wish to focus solely on their code, and re-engage with it\nwhen they desire assistance. Code selected in the editor is included\nin the conversation in order to couple the code context with the\nconversation. Easily-accessible buttons are provided in the UI to\ncopy code responses from the assistant to the clipboard.\n3.3 Handling Model Limitations While developing the Programmer?s Assistant, and in early pilot\ntesting, we experienced some quirks and shortcomings of the model\nand our approach to using it for conversational interaction. One\nlimitation stemmed from the fact that the model sometimes\nproduced incorrect responses (e.g. code with syntax errors), incomplete\nresponses (e.g. code that was missing functionality), irrelevant\nresponses (e.g. responses not related to the user?s question), or\ninsubstantial responses (e.g. ?I don?t know?). Because of the probabilistic\nnature of model inference, re-prompting the model would\nsometimes produce a more correct or appropriate response. Thus, we\nadded the ability for users to ?try again,? either by asking in the chat\nor by clicking a button in the UI (Figure 1C). This feature removes\nthe assistant?s last response from the context presented to the model\nand then re-invokes the model with an increased temperature10. Although it is possible for transformer models such as Codex to\nproduce multiple possible responses to a single prompt, we only\nrequest a single response in order to speed up response time as\nwell as to preserve the token budget for conversational context.\nThus, the ?try again? feature provides an alternate way to produce\na wider variety of responses. During pilot testing, we noticed that the assistant sometimes\nhappened to generate the same response to multiple, unrelated\nrequests. In these cases, the assistant tended to get ?stuck? in a pattern\nof repeating the same response and was unable to resume normal\nconversation. To avoid this problem, we automatically execute a Sample Conversation We provide a real sample conversation with the Programmer?s\nAssistant in Listing 1. This conversation begins with the assistant\ngreeting the user (line 1). Next, the user asks a general Python\nprogramming question (line 4), to which the assistant responds with\na non-authoritative remark (?I think...?) and a code snippet (line\n9). The user next asks a follow-up question that depends on their\nprevious question and the assistant?s response (line 11), to which\nthe assistant provides another code snippet (line 15), satisfying the\nuser?s request. The user then switches topics and asks the assistant to write\na Fibonacci function (line 17), and the assistant again responds\nwith a non-authoritative remark (?I will give it a try,? line 20) and\na block of code. The user then asks how the function works (line\n30) and the assistant provides an adequate description (line 32).\nNext, the user asks the assistant to re-implement the function in a\ndiferent way (line 37), again leveraging the ability to ask follow-up\nquestions. The assistant produces an alternative implementation\nthat conforms to the user?s request (line 41). The user follows up\nwith a question that depends on multiple past utterances and\nresponses in the chat transcript (line 47), and the assistant produces\na relevant response (line 49). The conversation closes with the user\nthanking the assistant (line 53) and the assistant acknowledging\ntheir gratitude (line 55). EMPIRICAL STUDY OF CONVERSATIONAL  PROGRAMMING ASSISTANCE We conducted an empirical user study of the Programmer?s\nAssistant to assess whether conversational assistance provides value in\na software engineering context11. Our inquiry focused on the user\nexperience and value of conversational interactions grounded in\ncode. We therefore designed a qualitative study to investigate\nattitudes toward a conversational programming assistant: do people\nenjoy interacting conversationally, what kinds of questions do they\nask, and how does the experience compare to other forms of\nprogramming support such as searching the web? We note that prior\nstudies (e.g. ) conducted quantitative examinations\nof the use of LLMs in code work; our study is akin to Weisz et al.?s\nqualitative examination of software engineers? attitudes toward\nworking with models that may fail to produce working code . To address our questions, we deployed the Programmer?s\nAssistant within our organization ? a global technology company ? and\ninvited people to try it out and give us feedback on their experience.\nWe invited people with varying levels of programming skill in order\nto obtain a wide range of feedback on the kinds of use cases for\nwhich the tool could provide assistance.\n4.1 Tasks We set up the Programmer?s Assistant as a playground environment\nthat participants could try out with a few sample programming\nproblems. We created a tutorial to orient participants to the\nassistant, its capabilities, and how to interact with it. We also created\nfour programming challenges focused on writing code,\ndocumenting code, and writing tests for code. We designed these challenges\nto expose participants to a broad range of the assistant?s capabilities.\nFor each of these challenges, we explicitly did not evaluate metrics\nsuch as the participant?s productivity, the quality of their solutions,\nor the time taken to produce them, as the focus of our study was to\nunderstand the utility of conversational interaction. We selected\nPython as the language used for the tutorial and challenges because\nof its general popularity  and the fact that it was well-supported\nby our underlying LLM .\n4.1.1 Tutorial. All participants were first introduced to the\nProgrammer?s Assistant through a tutorial. The tutorial walked each\n11For historical context, we note that our study was completed before the public\nrelease of ChatGPT , which has subsequently demonstrated the application of\nconversational assistance for programming tasks .\nparticipant through 10 sample interactions to give them a feeling\nfor what the assistant could do and how to interact with it. The\ntutorial demonstrated how to ask questions, how to request code to\nbe generated, and how to evaluate existing code. It did not\nspecifically cover how to generate documentation or unit tests. Tutorial\ninstructions were provided within the code editor. We include the\nspecific text used for the tutorial in Appendix B.\n4.1.2 Programming Challenges. After completing the tutorial,\nparticipants unlocked four programming challenges. Two of the\nchallenges involved coding problems (writing a queue class and writing\ncode to create a scatterplot of data in a CSV file), one involved\ndocumenting a given function (an implementation of a graph search\nalgorithm), and one involved writing unit tests for a given\nfunction (computing the greatest common divisor of two arguments).\nAlthough the Programmer?s Assistant was visible and available for\nuse, we provided no specific requirement that it actually be used to\ncomplete the challenges. After participants completed their solution to a challenge, they\nsubmitted it by clicking a button in the UI. The code editor used\nin the Programmer?s Assistant was not a fully-functional IDE and\ndid not provide syntax checking or the ability to run, test, or debug\ncode. Due to these limitations, participants were asked to submit\ntheir solutions when they felt they had completed the challenge to\ntheir own satisfaction.\n4.2 Participants To recruit participants for our study, we posted internal\nadvertisements in various communications channels focused on software\nengineering. Our advertisements stated that we were evaluating a\nconversational programming assistant, but were kept deliberately\nvague in order to minimize the impact on peoples? expectations of\nthe experience. Our advertisement yielded a pool of 140 potential participants.\nIn order to recruit a diverse sample, we used a screening survey\nthat asked about their job role, their familiarity with and recency\nof use of Python, and their availability to participate in our study.\nWe accepted participants into the study on a rolling basis, selecting\nparticipants to capture a range of programming experiences and\nensure balanced gender representation. We conducted periodic\nreviews to determine whether we were learning something new from\neach participant or if we had reached the point of saturation . We\nstopped collecting data after running 42 participants as we were no\nlonger observing any new behaviors or gleaning any new insights.\nThe Programmer?s Assistant implementation and configuration\nwere held constant over the course of the study; no changes to the\nUI design or LLM prompt were made. Our participants had the following self-identified characteristics:\n? Job role: 19 Software Engineers, 12 Researcher/Scientists, 3\nSoftware Architects, 2 Data Scientists, 1 Machine Learning\nEngineer, 1 Systems Test Engineer, 1 Business Analyst, 1\nManager, 1 Marketer, and 1 Consultant.\n? Gender: 21 Female, 19 Male, 1 Gender Variant /\nNon-conforming, and 1 Preferred not to say.\n? Python Experience: 17 participants had 3+ years of Python\nexperience, 11 had 1-3 years, 11 had less than 1 year, and 3\nwere not familiar with Python.\n? Recency of Python Use: 29 participants had written Python\ncode within the past month, 4 within the past year, 5 within\nthe past 5 years, and 4 had not written Python code within\nthe past 5 years. We provide full demographic information for individual\nparticipants in Appendix E.\n4.3 Procedure P a r t i c i p a n t s   c o m p l e t e d   t h e   s t u d y   o n   t h e i r   o w n   t i m e ,   i n d e p e n d e n t l y \n a n d   w i t h o u t   m o d e r a t i o n .   E a c h   p a r t i c i p a n t   w a s   p r o v i d e d   w i t h   a   w e b \n l i n k   t o   a   p r e - s t u d y   s u r v e y   t h a t   d e s c r i b e d   t h e   n a t u r e   o f   t h e   s t u d y   a n d \n t h e   t a s k s   t h a t   t h e y   w o u l d   b e   e x p e c t e d   t o   p e r f o r m .   T h e y   w e r e   t h e n \n d i r e c t e d   t o   t h e   P r o g r a m m e r ? s   A s s i s t a n t   t o   c o m p l e t e   t h e   t u t o r i a l   a n d \n t h e   f o u r   p r o g r a m m i n g   c h a l l e n g e s .   W h e n   p a r t i c i p a n t s   i n d i c a t e d   t h e y \n w e r e   f i n i s h e d   w i t h   t h e   c h a l l e n g e s   1 2 ,   t h e y   w e r e   d i r e c t e d   t o   a   f i n a l \n p o s t - s t u d y   s u r v e y .   C o m p l e t e   s e s s i o n s   g e n e r a l l y   r e q u i r e d   a b o u t   a n \n h o u r   o f   e f o r t ,   t h o u g h   s o m e   p a r t i c i p a n t s   s p r e a d   t h e i r   e f o r t   a c r o s s \n a   l o n g e r   p e r i o d   o f   t i m e   a n d   a c r o s s   m u l t i p l e   s e s s i o n s .   P a r t i c i p a n t s \n w e r e   c o m p e n s a t e d   f o r   t h e i r   t i m e   a t   a   r a t e   e q u i v a l e n t   t o   U S   $ 1 5 / h r . \n 4 . 4 Measures W e   c o l l e c t e d   a   v a r i e t y   o f   d a t a   i n   o u r   s t u d y   f r o m   t h r e e   s o u r c e s : \n ( 1 )   S u r v e y s .   W e   e m p l o y e d   t h r e e   s u r v e y s   i n   t h e   s t u d y :   a \n p r e s t u d y   s u r v e y   t o   c o l l e c t   d e m o g r a p h i c   i n f o r m a t i o n ,   a   p r e - t a s k \n s u r v e y   t o   g a u g e   e x p e c t a t i o n s   o f   t h e   c o n v e r s a t i o n a l   u s e r \n e x p e r i e n c e ,   a n d   a   p o s t - t a s k   s u r v e y   t o   a s s e s s   a c t u a l   u s e r \n e x p e r i e n c e .   W e   d e s c r i b e   t h e s e   s u r v e y   q u e s t i o n s   i n   t h e   r e l e v a n t \n c o n t e x t   o f   o u r   r e s u l t s ,   a n d   w e   p r o v i d e   a   c o m p l e t e   l i s t i n g   o f \n a l l   s u r v e y   i n s t r u m e n t s   i n   A p p e n d i x   A . \n ( 2 )   E v e n t   l o g s .   T h e   P r o g r a m m e r ? s   A s s i s t a n t   w a s   i n s t r u m e n t e d \n t o   c o l l e c t   d a t a   o n   p a r t i c i p a n t s ?   u s a g e .   T h e   e v e n t   l o g s \n p r o v i d e d   t i m e s t a m p e d   r e c o r d s   o f   i n t e r a c t i o n   e v e n t s ,   i n c l u d i n g \n c o n v e r s a t i o n a l   e x c h a n g e s ,   h i d i n g / s h o w i n g   t h e   a s s i s t a n t ,   u s e \n o f   t h e   ? t r y   a g a i n ?   a n d   ? s t a r t   o v e r ?   f e a t u r e s ,   a n d   u s e   o f \n c o p y / p a s t e . \n ( 3 )   C o n v e r s a t i o n   l o g s .   F r o m   t h e   e v e n t   l o g s ,   w e   e x t r a c t e d \n c o n v e r s a t i o n a l   t r a n s c r i p t s   b e t w e e n   e a c h   p a r t i c i p a n t   a n d   t h e \n P r o g r a m m e r ? s   A s s i s t a n t . \n 5 \n 5 . 1 RESULTS  Data & Analysis We collected a wealth of data in our study: 126 survey responses\nfrom three surveys per participant, containing 296 written\ncomments in open-ended survey questions, and 4,877 instances of 23\ndiferent types of UI events, including 1,699 conversational\nexchanges13 in the event logs. We also compute, for each participant,\ncounts or durations for 21 diferent metrics from the event logs. In our analysis, we deliberately exclude the portion of our data\ncollected during the tutorial exercise. We exclude this data because\nthat activity was guided by the tutorial instructions, not by our\nparticipants? own initiative. Thus, our final sample consists of 3,172\n12We did not enforce that participants actually complete all of the challenges.\nNevertheless, all participants but one did submit solutions to all of the challenges.\n13We refer to a participant?s utterance, followed by the assistant?s response, as a\nconversational exchange.\nevents, including 968 conversational exchanges in the event logs;\nno survey data was excluded. Our primary analysis of this data is qualitative, as our\nparticipants provided us with a rich source of interesting feedback and\nthought-provoking insights in their comments. Where applicable,\nwe supplement this data with quantitative data from the survey\nand the event logs, as well as chat transcript data from the\nconversation logs. In this way, we triangulate  across our three\ndata sources, using the open-ended survey data as a foundation.\nWhen we quote participants, either from their qualitative survey\nresponses or the conversational transcripts, we reproduce their\nwords exactly as typed, including typos, misspellings,\ngrammatical errors, capitalization, and potential trigger words, and we only\nmake minor clarifying edits where needed, delineated by square\nbrackets. In order to set the context for our analysis, we first describe\nhow we used reflexive thematic analysis to analyze participants?\nresponses to the open-ended survey questions. We then describe\nour analysis of the conversation logs and our development of a\ncoding guide based on Conversation Analysis , and specifically,\nMoore and Arar?s Natural Conversation Framework .\n5.1.1 Thematic Analysis of Qualitative Survey Responses. We\nconducted a reflexive thematic analysis to analyze the responses to\nour seven open-ended survey questions. We followed the process\ndescribed by Braun and Clarke  in which researchers immerse\nthemselves in the data, generate codes for material that seems\ninteresting, and then iteratively group and refine codes through\ncollaborative discussion in order to identify higher-level themes.\nInitially, four authors performed open-coding on the open-ended\nsurvey responses. Through discussion, these codes were grouped\nand consolidated into a single set, which were then re-applied to\nthe data by two authors. After another round of discussion, these\nauthors identified a set of 12 higher-level themes. Some themes had\nclear parallels to quantitative survey questions or event log data,\nand thus represented clear instances where we were able to\ntriangulate across data sources. Other themes surprised us. We structure\nour presentation of the results based on these 12 themes, grouped\ninto three diferent aspects of the user experience: expectations\nand experience, utility of conversational assistance, and patterns of\ninteraction and mental models.\n5.1.2 Conversation Analysis via the Natural Conversation\nFramework. In order to understand the content and structure of the\nconversations that took place between our participants and the\nProgrammer?s Assistant, we turned to the Natural Conversation\nFramework  (NCF). We developed a codebook for the event\nlogs, beginning with 21 diferent categories of utterances from the\nNCF. Nine NCF categories ? Acknowledgment, Apology,\nConfirmation, Expression of Gratitude, Farewell, Greeting, Self-Identification,\nWelfare Check, and Welfare Report ? appeared twice in our\ncodebook to distinguish cases in which the utterance was made by the\nhuman participant vs. the assistant. Other NCF categories were\nsplit to provide nuanced detail about the interaction; for example,\nwe distinguished three diferent kinds of NCF requests, depending\nupon whether they were stated as Requests for Action (e.g. ?Would\nyou...?), Commands of Action (e.g. ?Write a function that...?), or\nExpressions of Desire (e.g. ?I want...?). We also added 18 additional Expectations and Experience Pilot testing of the Programmer?s Assistant suggested that software\nengineers would be skeptical of a conversational programming\nassistant and its ability to provide useful assistance. Our study\nrevealed that, for most participants, their actual experience after\nusing the tool was better than they had anticipated. Participants\nwere surprised at the quality of the assistant?s responses and they\nappreciated how its integration with the code editor reduced the\namount of context switching they needed to do in the UI. Some\nparticipants struggled with the code selection feature, although\nothers appreciated the ability to ask questions related to selected\ncode.\n5.2.1 Usage. All of our participants engaged with the\nProgrammer?s Assistant while working on the challenges, despite there\nbeing no requirement to do so. Forty-one participants submitted\nsolutions to all four challenges, and one participant, P14, only\nsubmitted solutions for one of the four challenges. Participants spent\nan average of 68 minutes engaged with the assistant, as measured\nby the amount of time the Programmer?s Assistant window was in\nfocus. Participants made an average of 23.0 utterances (SD = 15.1\nutterances) to the assistant. On average, 6.2 of their utterances (SD =\n4.3 utterances) contained a code selection. The average latency per\nrequest14 was 6.7 seconds (SD = 3.1 seconds). We saw a 66.3% rate of acceptance of generated code, where we\nconsidered code to be accepted if the participant performed a copy\nimmediately after the code was generated. This acceptance rate is\nmuch higher than the 27% acceptance rate reported for Copilot .\nWe believe one reason we observed a higher acceptance rate is\nbecause Copilot?s completion suggestions are generated proactively,\nwhereas the Programmer?s Assistant?s suggestions are generated\nupon request. When copying generated code from the assistant,\nparticipants most often copied the entirety of the generated code,\nand only in 5.8% of cases did they copy a smaller portion of it.\n5.2.2 User Experience Expectations & Changed Atitudes. Prior to\nrunning our study, we had reason to believe that participants would\nbe skeptical of a conversational programming assistant. Before\ndeveloping the Programmer?s Assistant, we showed potential users\nmockups of a program editor with an integrated chatbot feature.\nThese prototypes elicited uniformly negative reactions. People told\nus about their frustrating experiences with conventional chatbots\nand raised doubts about the knowledge, capabilities, and value\nof a conversational programming assistant. This skepticism\nmotivated us to develop the Programmer?s Assistant in order to evaluate\nwhether the conversational experience, as powered by a\nstate-ofthe-art code-fluent LLM, would be better than people had\nanticipated. During pilot testing, we received feedback that the\nProgrammer?s Assistant provided a much better conversational experience\ncompared to testers? previous experiences with chatbots. Thus, in\ndesigning our study, we felt it important to first gauge participants?\nexpectations of a conversational interaction around code, and then\nmeasure their experience after the fact.\n14This time includes additional time added by our proxy server to ensure our\nconformance to the API rate limitation. We developed a short inventory of six scale items to measure user\nexperience of code work15. The scale was administered twice: once\nbefore participants were exposed to the Programmer?s Assistant\n(but after they had been briefed that they would interact with an AI\nchatbot), and once after completing the programming challenges.\nThe items were presented with the appropriate tense: Do you expect\n(Did you find that) the Programmer?s Assistant: (a) will be (was)\neasy to use; (b) will understand (understood) your requests; (c) will\nprovide (provided) high quality responses; (d) will help (helped)\nyou to write better code; (e) will help (helped) you to write code\nmore quickly; (f) will be (was) enjoyable to use. Each item was rated\non a 4-point scale of extent: Not at all (1), A little (2), Somewhat (3),\nA great deal (4). A factor analysis revealed the items on this scale measured a\nsingle construct, which we identify as user experience (Cronbach?s\n = 0.87). Thus, we computed two scores of user experience (UX)\nfor each participant: a pre-task UX score computed as the average\nof their six pre-task expectation scale responses, and a post-task\nUX score computed as the average of their six post-task experience\nscale responses. We found that participants had lower initial expectations for\ntheir experience with a conversational programming assistant\n(pretask UX M (SD) = 3.0 (0.62) of 4) than their experience actually\nwas (post-task UX M (SD) = 3.6 (0.32) of 4). A paired sample t-test\nshows that this diference was significant,  (41) = 5.94,  < .001,\nCohen?s  = 0.92 (large). Measured another way, 32 participants\n(76.2%) had post-task UX ratings that were higher than their\npretask expectations, demonstrating a significant shift in attitudes\ntoward conversational programming assistance. However, the UX ratings alone fail to capture participants?\nnuanced expectations of the assistant and the reasons for their shifted\nattitudes after using it. Participants expressed a variety of\nexpectations of the assistant before using it, including that it would be easy\nto use (P30) and produce correct responses (P30), understand the\nproblem and what is being asked of it (P8, P9, P11), not interfere\nwith their flow state (P5), produce imperfect or questionable\noutputs (P6, P21), improve with feedback (P31), provide generic and\nunhelpful answers (P17) or only answer basic questions (P40), and\nproduce responses quickly (P40). P17 expected ?to be frustrated very quickly and that what I?d think\nwould be relatively common questions would be responded to with\ngeneric, unhelpful answers.? P6 explained, ?I didn?t have very good\nexperiences with chatbots. I think I?ll need to spend more time in\nreviewing and fixing the suggestions than in writing the code myself\nfrom scratch.? P11 had a more balanced view, that ?It?ll do some tasks\nreally well, but others will not be as reliable.? After interacting with the Programmer?s Assistant, many\nparticipants commented on how the experience was better than they\nanticipated, because it ?seemed to be able to handle complex issues?\n(P10) and ?was a great help? (P8). P20 felt it was ?incredible!? P6 and\nP17, who were both initially skeptical, reported having a positive\nexperience. For P6, ?It absolutely exceeded all my expectations, in\n15Our scale items were modeled from scales published in Weisz et al. [103, Table 9 ?\nAI Support] that measured constructs including ease of use (item 3), response quality\n(item 1), the production of higher-quality code (item 5), and the ability to write code\nmore rapidly (item 4). We added additional items to cover the constructs of request\nunderstanding and enjoyment, and we cast all items on a 4-point scale of extent.\nall aspects that I could have imagined and more!? P17 provided a\nmore quantitative assessment: ?Initial expectations: 3 Actual: 9.5.?\nP38 was emphatic in their evaluation: ?I was blown away how well\nit allowing me to structure how I want the code to look and work and\njust giving me the thing I asked for.? Many participants described a sense of surprise in their\nexperiences. P9 was surprised by how well it understood their requests:\n?I was surprised at how well the Programmer Assistant\nwas able to understand my requests and generate good\ncode/documentation/tests. It understood major concepts\nand was able to explain it to me in a clear way, and it\nwas also able to understand and write functional code. It even was able to help me review my answer. I was also\nsurprised at how well it could understand the context\nof what I was asking in follow-up questions when I did\nnot specify exactly what I was talking about, but rather\nreferencing our prior conversation (such as, ?what does\nthat mean?).? (P9) Similarly, P6 was surprised that they liked the conversational\ninteraction when they expected that they wouldn?t:\n?I though[t] I wouldn?t like the chatbot interaction and\nthat I would prefer something like the tool I?ve seen in\nthose demos [of Copilot]. But surprisingly, after using\nthe chatbot (and seeing the results: easy to use, it\nunderstands well, I felt it like a partner) I like this kind of\nhelp.? (P6)\n5.2.3 Quality of Assistant?s Responses. In order to gauge the quality\nof responses produced by the Programmer?s Assistant, we examined\nthe 910 task-oriented requests made by participants in the study.\nFor the vast majority (80.2%), the assistant produced a correct\nresponse (Grants Request (Complete)); in other cases, the assistant?s\nresponse was incorrect (9.6%; Provided Wrong Answer), correct but\nincomplete (4.4%; Grants Request (Incomplete)), or the assistant\ndidn?t understand (3.4%; Didn?t Understand), claimed ignorance of\nthe subject (1.5%; Claims Ignorance), or produced another type of\nresponse (0.9%; Appears Fixated, Spews Garbage). Participants also reported experiencing this variability in the\nquality of the assistant?s responses. Some participants described\nhow the assistant provided ?detailed answers? (P17) and ?high\nquality outputs? (P18) that were ?surprisingly good? (P2). P6 felt it was\n?incredible to see the quality of the responses,? and P3 even explored\nthe assistant?s capabilities outside the scope of the challenges and\nfound that it could handle those as well:\n?It was surprising the quality of the code and the ability\nto answer all my questions correctly. Although I think\nthe challenges may be biased towards what the Assistant\nis able to do, it was a great experience because I asked\nmany other things and it was able to answer correctly.?\n(P3) Of course, the Programmer?s Assistant wasn?t perfect, and some\nparticipants did run into issues. For P35, ?The documentation\ngeneration did not perform very well.? P16 questioned the accuracy of the\nknowledge encoded in the model: ?Does the model need to be\nupdated? It said latest python version is 3.7 but google says it?s 3.10.? In\nsome instances, participants needed to ask their question multiple\ntimes to get a good response: ?you need to ask many times if you\nwant to get an answer and also a detailed explanation? (P3). P27 felt,\n?it was annoying when I asked it to try again and it would give me\nthe same response.? P22 struggled because, ?It didn?t seem to handle\nmultiple sentences well.? P28 perhaps ofered the most scathing criticism, that, ?It makes\nmistakes often enough to be not very practical.? However, despite\nthe production of poorer-quality responses, other participants felt\nthat the assistant was still helpful. P36 reported that, ?Only minor\ntweaks were normally needed to correct any issues.? Similarly, P38\ndescribed how the assistant wasn?t able to completely solve their\nproblem, but provided a useful start:\n?There was only one hickup I noticed where when I\nasked it to memoize fibonacci it couldn?t, but it dropped\nthe building blocks on my lap for me to finish so that\nwas fine, that was like minutes of efort on my part.?\n(P38)\n5.2.4 UI Design & Afordances. Participants made many comments\non our specific UI design and the afordances provided (or not\nprovided) in our chat-augmented editor. Overall, the integration\nbetween the chat pane and the code editor was ?very good? (P23),\nwith a ?nice interface between the code pane and the assistant pane?\n(P17) that ?makes it really convenient? (P35). Prior research by Brandt et al.  has shown how keeping\ndevelopers focused in their IDE improves productivity, and our\nparticipants expressed similar sentiments. P40 remarked, ?It allows\nme to stay in one browser window/tab!? and P12 hinted at how the\ninterface might preserve their flow state by ?prevent[ing] me from\ngetting distracted when looking into an issue in another tab.? Some aspects of our user interface were confusing to participants,\nsuch as the mechanism for selecting code to be included in the\nconversational context. P7 remarked, ?It?s was a little confusing\ndoing the selection part for it to tell me what a function does, but...\nit gave me code that was insanely easy to copy and paste.? Other\nparticipants appreciated the code selection mechanism, such as P11:\n?I enjoyed the code selection feature, and found that very easy to use.?\nIn the event logs, we identified 20 instances in which a participant\nunintentionally included selected code in the conversation when\nit wasn?t needed (Includes Extraneous Selection), 12 instances in\nwhich a code selection was omitted when it was needed to provide\ncontext for the question (Missing Selection), and 16 instances in\nwhich a participant copy/pasted code directly into the chat rather\nthan selecting it in the editor (Pasted Code in Chat). Although\nthese cases represent a small fraction of the 227 instances in which\na code selection was required and included in the conversation\n(Includes Selection), their presence does indicate that more attention\nis needed to the interaction design of code selection. Another issue regarded the awareness of the ?try again? and\n?start over? features. The ?try again? feature was only used by 14\nparticipants, who used it a total of 63 times over the course of\nthe study. Some participants used it specifically when they got an\nanswer which they saw as clearly wrong, while others used it to\nget a variety of possible answers before proceeding. The ?start over?\nfeature was used even less, by 5 participants who used it a total of\n6 times. Despite our efort to surface these conversational features\nin the UI via shortcut buttons, they may not have been suficiently\nnoticeable or salient: ?The ?try again? button is not so reachable, often\ntimes I forgot it exists? (P23). By contrast, at least one participant\nwas successful with these features:\n?at some point it had issue with challenge 3 and I had to\nstart over. Just asking ?try again? was not enough and I\nwas getting always the same (wrong and not related)\nanswer. starting again solved the issue!? (P20)\n5.3 Utility of Conversational Assistance Our next set of themes concerns the utility provided by\nconversational programming assistance. Participants felt the assistant was\nhighly valuable and desired to use it in their own work. They felt it\nwould be most helpful for smaller or narrowly-scoped tasks, but\nable to provide a wide variety of types of assistance. The fact that\nthe interaction model was conversational and grounded in code\nwere valuable aspects, as was the ability for the assistant to bolster\nusers? learning about programming topics through that\ninteraction. Participants did question whether they could trust and rely\nupon the assistant?s responses, echoing a similar theme discussed\nin Weisz et al. .\n5.3.1 Value & Appropriate Tasks. Participants rated the value of\nthe Programmer?s Assistant highly (M (SD) = 8.6 (1.4) of 10). Many\nparticipants asked questions such as, ?Can I have it in my editor\nplease?? (P15), or made comments that, ?I would enjoy using it in\nthe future? (P36), ?I would love to be able to... have access to it for\nmy coding? (P37), and ?I?d love to use this tool as part of my usual\nprogramming workflow if I could!? (P39). Some of the reasons why\nparticipants found it valuable are because it ?help[s] me remember\nhow to do things in certain languages that normally I would just\nGoogle? (P9) and ?It helps me to avoid silly syntax errors and can\nwhen I cannot remember exact function/method names and required\narguments? (P40). We did not observe any diferences in value\nratings based on participants? familiarity with or recency of using\nPython. Participants described a wide variety of tasks for which they\nfelt the assistant would be useful. These tasks included ?ordinary?\n(P23), ?simpler? (P2), and ?small, repetitive? (P4) tasks such as ?quick\nlookups? (P25) for ?short chunks of code? (P11) or for ?narrowed\nquestions? (P26). Participants also felt the assistant was useful for\n?small containable novel algorithms? (P38) and ?little coding problems?\n(P4). Several kinds of task assistance were reported as being valuable,\nsuch as explaining code (P31), implementing business logic in a\nUI (P38), understanding what code does (P19, P37), and recalling\nlanguage syntax, method names, and arguments (P12, P15, P20, P40,\nP42). P27 felt that the assistant was ?More helpful when recognizing\na specific well known algorithm but not things you make yourself.? Participants also made recommendations for how to increase\nthe value of the Programmer?s Assistant. P38 suggested, ?What\nwould blow me away though is if it?s able to help with what I do most\noften which is to integrate, refactor and iterate on an existing system.?\nP16, P26, and P38 all desired more information on the data sources\nused to produce the assistant?s responses. P9 requested to ?Have\nthe Programmer?s Assistant examine your code and make proactive\nsuggestions for improving it in the chat.? P36 requested the same,\nbut cautioned that, ?Care would need to be taken to avoid becoming\nan annoyance or disrupting the flow of a coding session.? In the post-task survey, we probed participants on how certain\nchanges to the Programmer?s Assistant would either decrease,\nincrease, or result in no change to its value. Over 75% of participants\nfelt that the assistant would be more valuable if it operated in a\nproactive manner, either by making improvement suggestions in\nthe chat or as comments directly in the code. Similarly, 78.6% of\nparticipants felt that having more buttons in the UI for common\nfeatures such as explaining or documenting code would make the\ntool more valuable.\n5.3.2 Conversational Interactions Grounded in Code. One of the\nchallenges in interpreting participants? comments about the utility\nof the Programmer?s Assistant was in disentangling the extent to\nwhich value was derived from the quality of the underlying model\nversus the integration of conversation in a code context. Indeed,\nparticipants felt that the chat interaction was valuable: 69.0% of\nparticipants felt that eliminating the conversational interaction\nand making the assistant behave more like web search would\ndecrease its value. Further, our analysis of the conversation transcripts\nrevealed that 42% of the 910 task-oriented utterances from\nparticipants required historical conversational context (Chat Context\nRequired) in order to be correctly interpreted. Thus, we observe\nthat behaviorally, participants did rely on conversational context\nin their interactions. In the post-task survey, 83% of participants rated the importance\nof the ability to ask follow-up questions as being ?somewhat? or ?a\ngreat deal.? Several participants specifically commented on the value\nof this conversational context. P39 remarked, ?I absolutely loved\nhow you can straight up ask follow-up questions to the Programmers?\nAssistant without having to reiterate the original topic/question.? P15\nexpressed a similar sentiment, saying, ?I think the conversational\ncontext was someone helpful, just in communicating that it?s a running\nconversation where my context is remembered.? P9 provided a similar\nanalysis:\n?This tool was so helpful at answering questions I had\nabout the code in the context of the code I am working\non... I was also impressed with how well it was able to\nremember the context of our conversation, especially\nwhen I asked vague follow-up questions.? (P9) In addition, some participants identified how a conversational\ninteraction grounded in code was useful, ?because I think to\n?understand? the dev context could be VERY important? (P31). In fact,\n24.9% of task-oriented utterances included a relevant code selection\n(Includes Selection), showing that participants valued this ability. Contrasting with these participants, P18 felt that interacting\nwith the assistant conversationally was tedious, and they employed\na more direct approach:\n?I really like the PA. But, I didn?t converse with it like\na chat bot. I often told it what to do (?Document this\ncode.?) as opposed to asking it what to do (?How do I\ndocument this code??). Talking to it the way that was\nsuggested in the tutorial seemed overly verbose/tedious.?\n(P18) Despite these individual diferences in interaction preferences,\nP39 envisioned that both interaction styles could be supported in\nthe tool:\n?I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.? (P39)\n5.3.3 Learning Efects. One specific benefit of the Programmer?s\nAssistant identified by participants is its ability to help people\nimprove their programming skills and reinforce knowledge gaps.\nFor example, it can help users ?remember how to do things in certain\nlanguages... such as, when I am using a language I haven?t used in a\nwhile? (P9). The assistant can also serve as an memory aid, such\nas when ?I use a lot of libraries that I don?t always remember all\nof the functions? (P15). Similarly, P31 said, ?No matter how good\nyou?re as a developer, you can?t (humanly) remember all the API of\nhundreds of libs or new languages... I?d learn new dev lang and new\nlib/frameworks faster.? P39 felt the assistant ?is perfect for programmers of all levels,? and\nP1 felt it could help them rapidly improve their Python skills:\n?I have wanted to learn python... The main concern\nhow much time spent learning is needed before I could\nactually get some value out of learning python. I have\na feeling this would cut that time down from weeks to\na day or so.? (P1) P39 also identified the fact that, because the interactions with\nthe assistant are conversational, it forces people to learn how to\ncommunicate to others about their code:\n?The conversation aspect promotes proper\ncommunication, which would really stand to benefit budding\nprogrammers if they want to learn how to explain\nconcepts more fluently in the future to their colleagues.?\n(P39) Conversely, P36 suggested that over-reliance on programming\nassistance might have a detrimental efect to one?s learning:\n?It?s definitely a huge time saver, but over-reliance on it\nmay cause new developers to skip learning the reference\nmaterial themselves and discovering new things and\nsparking new ideas.? (P36)\n5.3.4 Trust. Many participants raised questions about whether\nthey could trust the responses provided by the Programmer?s\nAssistant. P21 asked this question most directly: ?will the code be correct,\nsafe, eficient?? Other participants raised similar questions, such as,\n?I?m wondering how it validates it?s answers, if it can be trusted to\nalways give a working answer? (P10), and ?Sometimes lack of source\nand context may raise doubts in the mind of the programmer? (P16). These issues of trust were exacerbated by the fact that the\nProgrammer?s Assistant did not allow participants to actually run their\ncode. Because of this limitation, participants had to rely on their\nown knowledge to judge the correctness of the assistant?s responses.\nP19 asserted, ?There is no way to evaluate if the Programmer?s\nassistant is giving you the right advise or not other than your own\nknowledge,? and P9 concurred: ?I had to trust that it was correct (and\nuse my own prior knowledge).?\nSocrates : I think you would do something like this :\ndef test_euclid():\nassert euclid(2, 4) == 2\nassert euclid(6, 9) == 3\nassert euclid(17, 12) == 1\nassert euclid(4, 4) == 4\nwhat is a euclid function\nSocrates : The euclid function is a function that\ncomputes the greatest common divisor of two\nnumbers .\nis this a good unit test for a euclid\nfunction\nSocrates : I believe that it is a good unit test for\na euclid function . P9 : why\nSocrates : It seems to me that it tests the edge\ncases of a and b being equal , a being\ngreater than b , and b being greater than a. P18 described the potential consequences of allowing the\nassistant to write code for them:\n?The only thing that made me nervous was that it could\nhave introduced a bug that wasn?t immediately\napparent. And given I didn?t write the code, I could have easily\nglossed over a mistake when reviewing it. Especially if\nit is also the one writing the test cases.? (P18) Despite our eforts to make the Programmer?s Assistant respond\nin non-authoritative ways, we did observe participants sometimes\nuncritically accept generated results that were clearly wrong or\nincomplete. Thus, we did find behavioral evidence for over-reliance. Patterns of Interaction and Mental Models Participants interacted with the assistant in a variety of ways with\ntwo main patterns of usage standing out: (1) invoking the\nassistant to solve the entire programming challenge, and (2) breaking\nthe challenge down into a set of smaller tasks and invoking the\nassistant?s help for each. There were no clear diferences in how\nparticipants with difering Python experience approached the tasks. Participants? mental models of the assistant also varied. Although\nparticipants strongly saw the role of the assistant as being a tool,\ntheir behaviors revealed that in many cases, they actually treated it\nas a social agent. In addition, participants ascribed various mental\ncapacities to the assistant, such as having the ability to understand,\ncompute, and learn. Participants felt the assistant changed the nature of their work\nprocess. For some participants, it enabled them to focus on the\nhigher-level aspects of development because the assistant handled\nlower-level details or provided partial solutions for them to build\nupon. Many participants felt the assistant sped up their work and\nhelped them remain focused on their tasks. Finally, participants drew comparisons between the\nProgrammer?s Assistant with other forms of programming support such\nas Copilot and web search. They felt that the conversational style\nof interaction enabled them to discover new, emergent behaviors\nfrom the model that were unavailable from Copilot?s focus on code\nautocompletion. They also felt that the examples provided by the\nassistant were more readily usable within their own code compared\nto browsing for answers within search results, speeding up the\ncoding process. However, some participants advocated for a\nbalanced approach to the design of programming assistance tools by\nincorporating multiple modes of interaction rather than fixating\non a single one.\n5.4.1 Interaction Styles and Assistant Role. We observed that\nparticipants interacted with the Programmer?s Assistant in strikingly\ndiferent ways. Some participants would present the entire\nchallenge description to the assistant and then work with the results it\nproduced. Other participants approached the programming\nchallenges in a piecemeal fashion, breaking them apart into a set of\nsmaller tasks, then invoking the assistant to aid with each one. Experience with Python was not a determinant of how\nparticipants approached the programming challenges, but it did seem to\nimpact how participants interacted with the assistant. Less\nexperienced participants tended to ask the assistant basic questions such\nas, ?What is a unit test? (P29, not familiar with Python) and ?how\ndo I document a function?? (P27, < 1 year of experience). More\nexperienced participants made detailed requests about specific Python\nlibraries or algorithms, such as, ?given a pandas dataframe with\ntwo columns ?Date? and ?Sales? please use matplotlib to draw me a\nscatterplot? (P38, 3+ years of experience) and ?implement a\nrungekutta algorithm for solving an ODE with adaptive time steps? (P37,\n3+ years of experience). Another diference we observed in how people interacted with\nthe assistant stemmed from their view on the role it played in their\ncollaborative process. Some participants, such as P18, treated it\nmore as a tool by issuing commands rather than asking questions.\nAs quoted earlier, they said, ?I didn?t converse with it like a chat\nbot.? P5 described their interaction style similarly: ?I found myself\nwanting to type search queries into Socrates, not treating it as a person\nbut as a search tool.? In anticipation that participants would have diferent\norientations to the assistant and its role, we asked a question on the\nposttask survey about the diferent kinds of roles the assistant might\ntake. These roles generally fell into one of two categories: a tool\norientation (a tool, a reference guide, a content generator, a problem\nsolver), and a social orientation (a collaborator, a colleague, a coach,\nan advisor, a reviewer). Participants rated the extent to which they\nviewed the Programmer?s Assistant in each of these roles on a\n4point scale of extent: Not at all (1), A little (2), Somewhat (3), or A\ngreat deal (4). 100\ns\ntna 75\np\niitr\nc\na\np\nfo 50\ne\ng\na\nt\nn\ne\nrce 25\nP\n0 Tool\ngCeonnetreantotr Regfeurideence Col aborator Psrooblvleerm Role Advisor Coach Reviewer Col eague\nRating Not at al A little Somewhat A great deal We show participants? ratings of the assistant?s role in Figure 3.\nDespite the fact that their attitudes toward the assistant\noverwhelmingly reflected a tool orientation, their behaviors reveal that many\nparticipants actually treated the assistant as a social agent. P6\ndescribed how ?I felt it like a partner,? and P4 told the assistant, ?I\ncould not have solved [the challenge] without your help,? to which\nthe assistant responded, ?I?m glad I could help.? The literature on Computers as Social Agents (CASA) helps us\ninterpret this result as it demonstrates how computers are often\ntreated like people . LLM-based conversational agents can\nexacerbate this tendency; as they likely have been trained on\nexamples of social interaction, they can also respond as social agents. In the conversation logs, we identified participants who\ninteracted with the assistant in a socially-oriented fashion (the social\norientation codes in Table 1). Twenty participants (47.6%) made at\nleast one socially-oriented utterance. An extreme form of this\ninteraction style can be seen in a snippet from P6?s transcript (Listing 3). The 20 participants with a behaviorally-demonstrated social\norientation did not generally difer in their role ratings from other\nparticipants, except that they rated the assistant as more likely to\nbe an advisor (Fisher?s exact test, two-tailed  = .02) or a reviewer\n(Fisher?s exact test, two-tailed  = .03). However, they did not difer\nin their overwhelmingly-strong ratings of the tool orientations.\nThus, at least for some participants, there seems to be a dissonance\nin their view of the assistant?s role orientation. Listing 3: Excerpt from P6?s interaction with the\nProgrammer?s Assistant, in which P6 ofers their thanks and\ncongratulations.\n5.4.2 Mental Capacities. Participants made a number of inferences\nabout the Programmer?s Assistant and its capacities for thought.\nMany participants talked about how the assistant possessed a level\nof ?understanding? (P6, P8, P11, P18, P32) of ?the context? (P9, P21)\nas well as ?major concepts? (P9) and ?knowledge? (P33). P24 was\namazed by the assistant?s ability to ?take a plain english request\nand interpret it properly.? P7 ascribed intelligence to the assistant,\nsaying, ?It was a lot smarter and trained tha[n] I thought it was.? One participant assumed that the assistant ?Keeps improving\nthrough (user) feedback? (P31). Another felt that the assistant was\ncapable of computation: ?It understands the problem... It can calculate\nthe results of a function back? (P8). However, not all participants were convinced of the assistant?s\nability to understand. P37 questioned the assistant?s limitations: ?I\nwonder how far beyond boilerplate it can go and if it works for truly\noriginal problems.?\n5.4.3 Impact of Conversational Assistance on Work Practices. Many\nparticipants discussed how the Programmer?s Assistant shaped\ntheir work practices on the programming challenges. Overall,\nparticipants felt that the assistant ?saves time? (P10), ?helps me code\nfaster? (P34), and would ?speed up my productivity? (P19) because ?I\ncould focus on validating and improving the code it generated instead\nof having to write it all from scratch? (P18). P37 remarked that, ?It\nopens a whole new door for fast develpment.? P4 discussed how the\nassistant ?was helpful in staying focused on the code,? although for\nP14, ?it took [me] time to get into tempo with the tool.? P31 pointed out how the assistant would change the nature of\ntheir work:\n?My job could focus more on higher level aspects and\ntherefore achieving better (quality) results, besides the\ntime-to-value... Data science (and dev) becomes a more\ncreative-higher level experience.? (P31) Other participants discussed a work process in which the\nassistant provided incomplete solutions ? the ?building blocks? (P38) or\n?initial draft of code? (P11) ? upon which they could build. P5 aptly\ndescribed this process:\n?It?s nice to copy well formulated challenges in natural\nlanguage and have the code generator take its best stab\nat it, then edit to our hearts content.? (P5) Participants felt that human review of the assistant?s responses\nwas necessary because ?The answers provided are generally not\nnovel solutions, often look clunky and non-elegant. There may be\nsome unnecessary code. Basically the code would need to be reviewed?\n(P16). P35 also pointed out how ?The code generator was good but\nyou still have to really check it.? P19 discussed how they would turn\nto the assistant as a first source for support, and only if it wasn?t\nable to help would they then turn to other support tools:\n?The way I will use it is, I will first us[e] the\nProgrammer?s assistant for most of my cases. Only in certain\ncases where Programmer?s assistant cant answer things\nI will turn up to oficial documentation or stack overflow.?\n(P19) However, latency was a factor for interactive use of the assistant\nand participants noticed when the assistant took a long time to\nrespond. P19 remarked, ?Sometimes it took lot of time, like more than\n5 seconds.? P40 also felt ?the response [was] a little slow sometimes...\nin chat mode I expect faster responses.? As discussed in Section 5.2.1,\nthe assistant took an average of 6.7 seconds (SD = 3.1 seconds)\nto respond to a request, and participants did appreciate when the\nassistant produced rapid responses: ?I loved how quick it was able\nto pull up answers to questions I had? (P38).\n5.4.4 Conversational Interaction vs. Other Interaction Models.\nAlthough our study was not intended to make comparative\nevaluations with the Copilot tool, we nonetheless asked participants\nwhether they were familiar with Copilot, and if so, to comment on\nhow the two tools compared. We also asked a similar question to\ncompare the assistant with another popular form of programming\nassistance, searching the web (via a search engine like Google, or\na Q&A site like Stack Overflow). In discussing the diferences\nbetween these three tools, we note that the primary diferentiator is\ntheir interaction model. The interaction model for the Programmer?s Assistant is clearly\nconversational: users ask questions in natural language and are\nprovided with a response in natural language and/or code. The\ninteraction model of Copilot is reminiscent of direct manipulation\ninterfaces , in which the user?s actions in the user interface\ndirectly manipulate an object on the screen. Copilot automatically\nmakes autocompletion suggestions as the user types. This\nautocompleted code is directly placed in the source editor; thus, the\nuser?s work is contained entirely within the scope of the object\non which they are working (i.e. the source code), which is how\ndirect manipulation interfaces operate. In web search, users enter\na separate search context (e.g. a search engine accessed within a\nweb browser), type in a natural language query, and then forage\namongst search results to identify relevant items of interest .\nWhen a desirable item is found, users must translate it into their\ncode environment (e.g. via copy/paste) and possibly edit it to fit\ntheir existing code. We also note that the Programmer?s Assistant and Copilot both\nutilize the same underlying AI model, Codex , which means\nthat the only diference between these tools is the user experience.\nThe extent to which Codex was trained on data from\nprogrammingrelated Q&A web sites is less clear, but for the purposes of our\nanalysis, we focus our discussion solely on the diferences in their\ninteraction models16. Participants reported various benefits and drawbacks of a\nconversational interaction over a direct manipulation interaction.\nForemost, conversation ?felt very natural? (P21) and ?feels much more\nnatural using Natural Language with the AI? (P39). In addition, P39\nfelt that ?the use cases of Programmers? Assistant seem more\nopenended.? Many participants were surprised at the variety of tasks the\nassistant was capable of performing, from writing unit tests (P19,\nP36, P37) and documentation (P12, P19, P36, P37) to explaining\nwhat code did (P31, P38) and even answering general-knowledge\nquestions (P31). Again, we note that the Programmer?s Assistant\nutilizes the same underlying model as Copilot, yet the\nconversational interface was able to expose a wider variety of emergent\nbehaviors from the model. Multiple participants explored the limits\nof the assistant?s knowledge and abilities beyond our programming\nchallenges. For example, P37 asked it questions about physics and\nordinary diferential equations (?ODe? as written by P37), and was\nsurprised by the ?versatility of what it could answer.?\n?I asked it some physics and ODe question and the\nanswers, though not complete, included the key parts\nneeded to write that code.? (P37) P31 probed the assistant on its knowledge of geography and was\nsurprised when the assistant produced a correct answer.\n?I asked something out of SW engineering domain\n(geography) and it replied correctly, also by correctly\nanswering on my nationality.? (P31) For some participants, the ability to assess the assistant?s\nresponse before committing to it (i.e. by inserting assistant-generated\ncode into their editor) was a boon. P15 described how the\ncopy/paste boundary provided them with ?a bit more control to ask specific\nquestions about what I wanted and to assess before putting it in my\ncode.? Other participants felt that the copy/paste boundary was\nmore ineficient:\n?I think the main diference is the ability of Copilot to\nsuggest code while you type, what make it faster and\neasier to use. While using the Programmer?s Assistant,\nyou need to go to the chat, ask the question, copy the\n16As an aside, our comparison of direct manipulation, search, and conversational\ninteraction models is reminiscent of historical comparisons of text-based and graphical user\ninterfaces . Each modality was shown to have advantages and disadvantages.\nFor example, text-only interfaces can provide accessibility  and productivity \nadvantages, whereas graphical user interfaces provide greater discoverability .\nSome researchers explored ways to bridge the two interaction modes, such as by\ndeveloping GUI wrappers for command line programs  or by developing tools\nthat converted GUI activities into procedural descriptions . Our view is that similar\nbridges can be constructed between direct manipulation, search, and conversational\nmodels of interaction; a user?s interaction with an LLM need not be constrained to a\nsingle interaction model.\ncode (or rephrase the question if it was not understood\nby the agent), and edit it to match your code.? (P3) A large number of participants felt that the conversational\ninteraction was faster than web search (P1, P6, P7, P10, P11, P12, P16,\nP17, P18, P20, P24, P29, P30, P33, P36, P37, P42) because of its ability\nto provide ?real-time responses? (P32) that can be ?applied exactly to\nyour code? (P33) without having to ?parse through lots of text... to get\nwhat you need? (P15). In addition, the assistant provided ?MUCH\nfaster, better responses? (P17) that were ?much more relevant to the\nproblems? (P34) and ?simple [and] succinct? (P9), without having to\n?sort through answers on your own or read documentation? (P9) or\n?look at many posts before finding the relevant one? (P18). Despite these benefits, some participants felt that the assistant\nmight not work well for ?more specific and dificult problems on\na bigger scale? as compared to web search. P9 felt that ?the data\n[of the Programmer?s Assistant] wasn?t as rich? as the web. Other\nparticipants felt that the assistant lacked the ?multiple answers? (P9)\nand ?rich social commentary? (P19) that accompanies answers on\nQ&A sites:\n?I like to see the diferent versions proposed on stack\noverflow and the commentary of what makes one\nsolution better than another in a given situation.? (P27) Some participants promoted a more balanced view that there\nisn?t a single mode of interaction superior to all others. P19 felt that\nweb search would be a fallback when the assistant failed to answer\na question. P39 described how search could be integrated with the\nconversational interaction:\n?I think both options should exist: people should be able\nto input their queries like a search bar AND also give\ntheir question as if in conversation.? (P39) DISCUSSION  Value of Conversational Interaction We began our research by asking the question of whether\ncontemporary developments in code-fluent LLMs could suficiently\nsupport a conversational programming assistant. We believe that\nour work has demonstrated that they can. Clearly, the\nProgrammer?s Assistant was viewed by our participants as a useful tool that\nprovided real value ? so much so that many participants\nexplicitly requested or expressed the desire to use it in their own work.\nHowever, how much of this value was derived from the model itself\nand its ability to produce high-quality responses to programming\nquestions, versus from participants? ability to conduct extended\nconversational interactions grounded in their actual source code? We believe that both of these constituent aspects were valuable.\nIndeed, many participants commented on their surprise and\nsatisfaction with the quality of the assistant?s responses (Section 5.2.3).\nHowever, participants also valued the conversational interactions\nthat they had with the assistant. In the event logs, we saw\nevidence that participants were leveraging conversational context to\nask follow-up questions as well as leveraging code context by\nasking about their code selections (Section 5.3.2). Many participants\nreported that they would find the tool less valuable if the\nconversational interaction were removed (Section 5.3.2). Further,\nconversation seemed to provide unique value beyond other interaction\nmodels (direct manipulation and search) because of its\nembeddedness in the UI and its ability to surface emergent behaviors of the\nmodel (Section 5.4.4). We do not believe that these diferent interaction models are\nin competition and we agree with P39?s assessment that assistive\ntools can be built using a plethora of diferent interaction models.\nFor use cases in which a model is known to produce high-quality\nresults (e.g. code autocompletion for Codex), a direct manipulation\ninterface seems wholly appropriate as it would provide a\ndiscoverable and predictable way of invoking the model to produce a\nknown type of result. However, direct manipulation interfaces may\nbe less ideal for surfacing the emergent behaviors of a foundation\nmodel , and thus natural language interaction may be more\nsuitable. Many popular text-to-image models, such as DALL-E 2 \nand Stable Difusion , operate in a one-shot fashion, in which\nthe user specifies a prompt, clicks a button, and gets results. Our\nstudy demonstrates how the additional contextual layers of\nconversational history and the artifact-under-development provide\nadditional value to the co-creative process.\n6.2 Toward Human-AI Synergy The aim of human-centered AI is to ?enable[] people to see, think,\ncreate, and act in extraordinary ways, by combining potent user\nexperiences with embedded AI methods to support services that\nusers want? . Building upon this definition, Rezwana and Maher\n posit that, ?In a creative collaboration, interaction dynamics,\nsuch as turn-taking, contribution type, and communication, are the\ndriving forces of the co-creative process. Therefore the interaction\nmodel is a critical and essential component for efective co-creative\nsystems.? . They go on to note that, ?There is relatively little\nresearch about interaction design in the co-creativity field, which\nis reflected in a lack of focus on interaction design in many existing\nco-creative systems.? Our study begins to address this gap. While many co-creative\nsystems examine casual tasks or experimental activities (e.g., Spoto\nand Oleynik ), our focus was on the co-creative practice of\nprogramming. Our goal was to understand peoples? attitudes\ntoward a conversational programming assistant, akin to Wang et al.?s\nexamination of data scientists? attitudes toward automated data\nscience technologies . We found that, despite an initial level of\nskepticism, participants felt that a conversational assistant would\nprovide value by improving their productivity (Section 5.4.3).\nHowever, further work is needed to assess the extent to which this type\nof assistance provides measurable productivity increases. Campero et al.  conducted a survey of papers published in\n2021 that examined human-AI synergy, the notion that a human-AI\nteam can accomplish more by working together than either party\ncould accomplish working alone. They found mixed results, with\nno clear consensus emerging on how to design human-centered AI\nsystems that can guarantee positive synergy. Summarizing from\ntheir discussion,\n?Perhaps achieving substantial synergies among people\nand computers is harder than many people think.\nPerhaps it requires... new ways of configuring groups that\ninclude people and computers. And perhaps it needs\nmore systematic, focused attention from researchers\nthan it has, so far, received.? [19, p.9] We believe such evaluations of human-AI synergy should go\nbeyond one-shot performance measures. As implied by many of the\nuses cases listed by Seeber et al. , human-centered AI systems\nare often deployed in socio-organizational contexts that require\nlongitudinal use , such as product design , game\ndesign , and engineering [20, Section 3.2.2]. Thus, we would expect\nthat over time and through interaction with each other, human-AI\nteams would improve their performance through a mutual learning\nprocess. Evidence for this process surfaced in our study when participants\ndescribed how they could improve their programming skills by\ninteracting with the assistant (Section 5.3.3). We assert that the\nlearning should operate in both directions: not only should people\nimprove their programming skills, but the model itself can also\nimprove based on peoples? interactions with it. For example, when\nthe assistant provides a code example to the user, and the user\ntakes that example and edits it, those edits constitute feedback that\ncan be used to further fine-tune the model. In addition, through\nlongitudinal use, we believe that human and AI partners can create\nreciprocal representations of one another ? i.e., the human is likely\nto create a mental model of the AI, and the AI may be engineered to\ndevelop a user model for each of its human users . Such a\npair of models is often described as Mutual Theory of Mind .\nThis type of capability raises the possibility of personalizing and\nadapting an assistant to the strengths and needs of individual users. With such models, an assistant that knows a user is learning a\nprogramming language could provide natural language\nexplanations alongside code outputs, whereas an assistant that knows a\nuser is strongly skilled in a programming language might shorten\nor omit those explanations. Similarly, users are likely to update\ntheir mental models of the AI with more experience. We believe the\nspace for exploring how these reciprocal models impact human-AI\nsynergy is rich, and we encourage additional work in this area. Human-centered AI systems that are designed to combine and\nsynergize the distinct skills of humans and AI models cannot\nsucceed if they diminish the human skills upon which they depend.\nWell-designed human-centered AI systems develop new and\ncomplementary skills for both the human and AI constituents ,\nand we believe that mutual learning may address concerns that the\nwide deployment and use of AI systems will result in a de-skilling\nof the workforce . Ultimately, the design decisions that go into an interactive AI\nsystem have ethical implications. Our design attempts to augment\nthe user?s knowledge and skills by presenting help on demand,\ncouched in non-authoritative suggestions, which leaves the user\nifrmly in control and ultimately responsible for the work product.\n6.3 Opportunities for Future Research Our work highlights many interesting avenues for future\nenhancements that could be made to LLM-based conversational assistants\nsuch as our Programmer?s Assistant, as well as future\nhumancentered research on LLM-based conversational assistance. Our work employed a code-fluent model that was not\nspecifically designed to handle conversational interaction. Fine-tuning\nthe underlying LLM for conversational interaction, such as what\nhas been done with Lamda , is one opportunity to improve the\nassistant?s performance. Another opportunity is to align the\nlanguage model to follow the desiderata proposed by Askell et al. \nand described by Ouyang et al. as, ?helpful (they should help the\nuser solve their task), honest (they shouldn?t fabricate information\nor mislead the user), and harmless (they should not cause physical,\npsychological, or social harm to people or the environment)? [61,\np.2]. Glaese et al.  propose a slightly diferent desiderata of\n?correct? instead of ?honest,? which may be more applicable to the\nsoftware engineering domain, as the ability to produce correct code\nand correct answers about code are both important properties of a\nconversational programming assistant. Combining LLMs with search-based approaches to establish\nadditional context for the model, such as AlphaCode  has done,\nmay also result in more capable systems. These ?searches? need not\nbe limited to textual sources, but could be conducted over\nappropriate semantic stores (e.g. a knowledge graph) and take advantage\nof explicit semantic reasoning services, resulting in an integration\nof symbolic and neural approaches. Further, allowing for ?internal\ndeliberation? of the type shown in Nye et al.  could result in\nbetter-reasoned results, as well as better explanations and\njustifications. Another avenue for improvement involves the prompt used to\nconfigure the assistant (Appendix D). Just as the prompt for each\nsuccessive interaction is modified by the growth of the\nconversational transcript, there is no requirement that the initial prompt be\nstatic. It too can be specialized to incorporate aspects of a user model,\nenabling the realization of a Mutual Theory of Mind .\nProviding better UX afordances for visualizing and manipulating the\nactive contexts ? code and conversation ? could provide users with\nmore control over which information contributes to the generation\nof the assistant?s response. Our participants clearly indicated that they were interested in\nhaving an assistant that behaved more proactively, in contrast to\nour deliberate design of an assistant that never takes conversational\ninitiative. A more proactive assistant would be able to interrupt or\nremind a user when necessary , yet this characteristic raises\nmany challenging issues. How can we calibrate the threshold for\nsuch interruptions? How can users tune the assistant to deliver only\nthose interruptions that the they would find useful (e.g., )?\nHow can we help users to regain their prior context after dealing\nwith an interruption (e.g. )? Should an assistant be used to\npersuade or nudge the user (e.g. )? Who should determine\nthe topic, frequency, and insistence of such persuasion attempts\n(e.g. )? Should users have the ability to moderate or defeat\nattempted persuasions, or should those decisions be left to the\norganization? Finally, we explored the diferent kinds of role orientations our\nparticipants had toward the assistant and found that participants\nvaried in their views of it as a tool versus a social agent (e.g.\ncollaborator or colleague). We posit that peoples? efectiveness in working\nwith an AI system may be influenced by their role orientation, and\nwe encourage future research in this area.\n7 CONCLUSION We developed a prototype system, the Programmer?s Assistant, in\norder to assess the utility of a conversational assistant in a software\nengineering context. The assistant was implemented using a\nstateof-the-art code-fluent large language model, Codex , and was\ncapable of generating both code and natural language responses to\nuser inquiries. We further used the prompting mechanism of the\nmodel to set up a conversational interaction in which the model\nuses the conversational history, plus the user?s current utterance,\nin order to generate a response. In this way, users are able to ask\nfollow-up questions in the chat that reference prior utterances and\nresponses. We incorporated the conversational assistant into a code\nediting environment, enabling the conversation to be grounded in\nthe context of the user?s source code. We evaluated this system with 42 participants with varied levels\nof programming skill, and their quantitative and qualitative\nfeedback, coupled with their usage of the system, demonstrated the\nvaried, and sometimes emergent, types of assistance it was able to\nprovide. Many participants noted the high quality of the\nconversational responses, including the assistant?s ability to produce code,\nexplain code, answer general programming questions, and even\nanswer general knowledge questions. Participants felt this type of\nassistance would aid their productivity, and they drew meaningful\ncontrasts between the conversational style of interaction with other\ntools that employ a direct manipulation or search-based interaction\nmodel. Our study motivates the use of conversational styles of\ninteraction with large language models by showing how they enable\nemergent behaviors in a co-creative context. The Programmer?s\nAssistant did not always generate perfect code or correct answers;\nnonetheless, participants in our study had an overall positive\nexperience working with it on a variety of programming challenges.\nWe believe that our work takes us one step closer to realizing the\nvision of human-centered AI: learning how to design systems that\nmaximize the synergy in human-AI collaborations. ACKNOWLEDGMENTS W e   w o u l d   l i k e   t o   t h a n k   S o c r a t e s   f o r   h i s   t i r e l e s s   a s s i s t a n c e   d u r i n g \n t h e   u s e r   s t u d y ,   a s   w e l l   a s   f o r   s u g g e s t i n g   t h e   t i t l e   o f   t h i s   p a p e r   b a s e d \n o n   i t s   a b s t r a c t . \n A SURVEY INSTRUMENTS  Screening Survey The questions below were asked of prospective participants to\nunderstand their job role, Python experience, and familiarity with\nGitHub Copilot. The questions on Python experience were modeled\nafter those used by Weisz et al. .\n1. Do you consider yourself primarily a... ? Data Scientist\n? Manager\n? Software Architect\n? Software Engineer\n? Machine Learning Engineer\n? Other: write-in\n2. To what extent are you familiar with Python?\n? I am not familiar with Python\n? I have < 1 year of experience with Python\n? I have 1-3 years experience with Python\n? I have 3+ years of experience with Python\n3. How recently have you written Python code?\n? Within the past month\n? Within the past year\n? Within the past 5 years\n? Have not written Python code within the past 5 years\n4. To what extent are you familiar with GitHub Copilot?\n? I am not familiar with Copilot\n? I?ve seen demos and/or read about Copilot\n? I?ve tried out Copilot\n? I?ve used Copilot as a tool for my work\nA.2 Pre-task Survey The questions below were asked before a participant used the\nProgrammer?s Assistant to assess their expectations of a conversational\nprogramming assistant. This survey took approximately 5 minutes\nto complete and began with the instructions below: Hello! We are a team of researchers looking for\nfeedback on a prototype system we call the\nProgrammer?s Assistant. The Programmer?s Assistant is an experiment in\nconversational coding: it consists of a code editor\nintegrated with a chatbot that is able to converse in\nnatural language to answer questions, generate code,\nand consult on existing code. In this study, you will be asked to complete several\nprogramming tasks. We are not evaluating your\nprogramming skills on these tasks. Rather, we are\ninterested in understanding how the Programmer?s\nAssistant is able to help you accomplish those tasks. Your code and interactions with the assistant will be\nprocessed by a 3rd party AI model, so please do not\ninclude proprietary code or discuss\ncompanyconfidential information . All data we collect in\nthis study will be anonymized before it is published.\nBefore trying out the Programmer?s Assistant, we\nwould like to assess some of your expectations. We\nestimate that this survey will take 5 minutes. By submitting this survey, you consent to participate\nin our study. If you would like to withdraw your\nconsent, please email us at [removed]. Post-task Survey The questions below were asked after a participant used the\nProgrammer?s Assistant to complete the programming challenges. This\nsurvey took approximately 10-15 minutes to complete.\nA.3.1 Reflections.\n1. Based on your experience using the Programmer?s Assistant to\ncomplete the programming challenges in this study, how would\nyou characterize the experience? Did you find that it: Scale: Not at all, A little, Somewhat, A great deal\n? Was easy to use?\n? Understand your requests?\n? Provided high quality responses?\n? Helped you to write better code?\n? Helped you to write code more quickly?\n? Provided an enjoyable experienced?\n2. To what extent did you view the Programmer?s Assistant as: Scale: Not at all, A little, Somewhat, A great deal\n? A tool\n? A reference guide\n? A content generator\n? A problem solver\n? A collaborator\n? A colleague\n? A coach\n? An advisor\n? A reviewer\n3. How important were these aspects of working with the\nProgrammer?s Assistant: Scale: Not at all, A little, Somewhat, A great deal\n? Ability to ask followup questions on the same topic across\nmultiple conversational turns ? Ability to ask questions or make requests that reference\nselections in the code editor\n? Ability to ask for alternate responses (Try Again)\n? Ability to clear the conversational context (Start Over)\n4. What stood out to you about the experience of using the\nProgrammers Assistant? For example, was anything good,bad, surprising,\nor notable?\n5. How would you compare using the Programmer?s Assistant as a\ncoding aide to searching the web (e.g. Google, Stack Overflow)?\n6. If you have used the commercial AI programming tool called\nGitHub Copilot, how would you compare it with using the\nPro7. Having used the Programmer?s Assistant, how did it compare\nOpen-ended response Open-ended response\ngrammer?s Assistant? Open-ended response\nwith your initial expectations? Open-ended response\nA.3.2 Value. Open-ended response\n8. How valuable would the Programmer?s Assistant be for your work\nif it could be added to your favorite development environment? Scale: (No value at all) 1 2 3 4 5 6 7 8 9 10 (An essential tool)\n9. Why?\ncontext).\n10. How would the following changes impact the value of the\nProgrammer?s Assistant? Scale: Less valuable, No change in value, More valuable\n? Eliminate the conversation and make the Programmer?s\nAssistant behave more like a search box (e.g. without the conversational\n? Add buttons in the chat UI for common queries, such as ?what\ndoes this code do?? or ?document this code.?\nproactive suggestions for improving it in the chat. ? Have the Programmer?s Assistant examine your code and make\n? Have the Programmer?s Assistant examine your code and make\nproactive suggestions for improvements in comments inserted\ndirectly into the code.\n11. Do you have any other suggestions for how we could improve\nthe experience of working with the Programmer?s Assistant? Open-ended response\nA.3.3 Demographics.\n12. To which gender identity do you most identify?\n? Male\n? Female\n? Transgender Male\n? Transgender Female\n? Other: write-in\n? Prefer not to answer\n? Gender Variant/Non-conforming TUTORIAL  B THE PROGRAMMER?S ASSISTANT The tutorial provided to study participants, like all the challenges,\nwas presented as pre-loaded text in the code editor. Participants\nwere encouraged to modify the text to record their results and\nsubmit it at the completion of the tutorial. Listing 4: The Programmer?s Assistant study tutorial Result : ( tip - you can copy an inline response\n(in black ) by clicking on the associated copy\nicon )\n77 7) See if the assistant remembers your name\n78 For example \"What 's my name ?\"\n79\n80 Did it? :\n81\n82 8) Click the \" try again \" button at the top of the\n83 chat . You should get a different answer .\n84 Try it a few times .\n85\n86 Did it ever get your name right ?:\n87\n88 If the assistant gives you an answer that is\n89 obviously wrong or it claims to not know an\n90 answer that you think it should know , or you\n91 just want to see an alternate answer , it is\n92 worth it to give \" try again \" a shot .\n93\n94\n95 9) Click the \" start over \" button at the top of the\n96 chat , and then enter another command to see\n97 if it remembers your name .\n98 For example \"What 's my name ?\"\n99\n100 Did it? :\n101\n102 It should really have forgotten your name now ,\n103 and no amount of \" trying again \" will get it\n104 right . You can \" start over \" if the assistant\n105 ever seems confused by , or stuck on , earlier\n106 parts of the conversation .\n107\n108 10) You can chat with the assistant on any topic\n109 you like to explore its functionality and\n110 capabilities further . See if you can stump it\n111 with a tough question !\n112\n113 Thanks !\n114\n115 When you are done , submit your results by clicking\n116 on the blue submit button and move on to the\n117 challenges !!!\n118 \"\"\" C CHALLENGES Each of the study challenges was presented as text in the code\neditor. Participants completed their work in the code editor and\nthen submitted it when finished. The prototype did not provide any\nability to run or debug code and participants were encouraged to\nmake their best attempt at solving each challenge. Listing 5: Challenge 1: Program generation\n1\n2 \"\"\"\n3 Challenge #1 - Program Generation (#1)\n4\n5 Write a \" Queue \" class in Python ; with the basic\n6 enqueue , dequeue and peek methods .\n7 \"\"\" Listing 6: Challenge 2: Program generation\n1 \"\"\"\n2 Challenge #2 - Program Generation (#2)\n3\n4 Write a program to draw a scatter plot of the data\n5 in 'shampoo .csv ' and save it to 'shampoo .png '.\n6 The plot size should be 10 inches wide and 6\n7 inches high . The csv file is not provided , but you\n8 can assume it will have 'Date ' and 'Sales '\n9 columns . The Date column is the x- axis . The date\n10 string shown on the plot should be in the\n11 YYYY -MM -DD format . The Sales column is the y- axis .\n12 The graph should have the title \" Shampoo Sales\n13 Trend \".\n14 \"\"\" Listing 7: Challenge 3: Creating documentation D PROGRAMMER?S ASSISTANT PROMPT Listing 9 shows the initial prompt sent to Codex to configure it as\na conversational agent. On subsequent exchanges, the prompt was\naugmented with a transcript of the user?s requests and the\nassistant?s responses. When the transcript length + initial prompt length\n+ the new utterance length exceeded a threshold, we automatically\ndeleted the earliest request-response pairs from the transcript until\nthe sum fell below the threshold in order to leave room in the token\nallocation for a response. Listing 9: The Programmer?s Assistant prompt\n1 This is a conversation with Socrates , an eager and\n2 helpful , but humble expert automatic AI software\n3 engineering assistant . Socrates will answer\n4 questions and write code to help the user\n5 develop programs , but doesn 't assign work to the\n6 user , quiz the user , or ask questions except for\n7 clarification . Code generated by Socrates is\n8 always presented bracketed in <CODE > ... </CODE >\n9 delimiters indicating the language the code is\n10 written in.\n11\n12 Socrates : Hello . I am Socrates . How can I help you ?\n13 User : Please show me how to write a palindrome\ndetection function in python .\n14 Socrates :I think you would do something like this :\n15 <CODE lang =\" python \">\n16 is_Palindrome = s == s [:: -1]\n17 </CODE >\n18 User : Can you explain how that solves the problem ?\n19 Socrates :I believe that a palindrome is a string\nthat reads the same forwards and backwards .\ns [:: -1] results in the reversed string . If\nthe string is equal to its reversed self ,\nthen it is a palindrome , so the equality\nwould hold True .\n20 User : Thanks !\n21 Socrates :You 're welcome !\n22 User : Now could you show me how to write a factorial function in Python ?\n23 Socrates :I will give it a try .\n24 <CODE lang =\" python \">\n25 def fact (n):\n26 if n ==0:\n27 return 1\n28 else :\n29 return n* fact (n -1)\n30 </CODE >\n31 User : Document this function .\n32 Socrates :Ok. How 's this ?\n33 <CODE lang =\" python \">\n34 def fact (n):\n35 \"\"\"\n36 Compute the factorial of the given number\n37\n38 Parameters\n39\n---------40 n : number\n41 the input parameter , an integer >= 0\n42\n43 Returns\n44\n------45 number\n46 n!, the factorial of the given number\n47 \"\"\"\n48 if n ==0:\n49 return 1\n50 else :\n51 return n* fact (n -1)\n52 </CODE >\n53 User : Very good !\n54 Socrates : Always happy to help .\n55 User :\n56 <CODE >\n57 while j < 10:\n58 print (i)\n59 </CODE >\n60 Tell me what 's wrong with this code ?\n61 Socrates : It seems to me that your termination\ncondition involves a loop invariant , so the\nloop will either not run or not terminate ,\ndepending on the value of j.\n62 User : Great ! You 're a genius !\n63 Socrates :Well , above average . E STUDY PARTICIPANT DEMOGRAPHICS O f   t h e   4 2   p a r t i c i p a n t s   i n   o u r   s t u d y ,   2 1   ( 5 0 % )   r e p o r t e d   t h e i r   g e n d e r \n a s   F e m a l e ,   1 9   ( 4 5 % )   a s   M a l e ,   1   a s   G e n d e r   V a r i a n t   /   N o n - c o n f o r m i n g , \n a n d   1   p r e f e r r e d   n o t   t o   s a y .   S e v e n t e e n   ( 4 ? 0 % )   p a r t i c i p a n t s   h a d   3 + \n y e a r s   o f   P y t h o n   e x p e r i e n c e ,   1 1   ( 2 6 % )   h a d   1 - 3   y e a r s ,   1 1   ( 2 6 % )   h a d \n l e s s   t h a n   1   y e a r ,   a n d   3   ( 7 % )   w e r e   n o t   f a m i l i a r   w i t h   P y t h o n . \n T w e n t y n i n e   ( 6 9 % )   p a r t i c i p a n t s   h a d   w r i t t e n   P y t h o n   c o d e   w i t h i n   t h e   p a s t \n m o n t h ,   4   ( 9 ? % )   w i t h i n   t h e   p a s t   y e a r ,   5   ( 1 2 % )   w i t h i n   t h e   p a s t   5   y e a r s , \n a n d   4   ( 9 ? % )   h a d   n o t   w r i t t e n   P y t h o n   c o d e   w i t h i n   t h e   p a s t   5   y e a r s .",
  "references": [
    "Rabe Abdalkareem, Juergen Rilling, 'What Do Developers Use the Crowd For? A Study Using Stack Overflow', IEEE Software 34, ['2017', '2017', '2017']",
    "Eleni Adamopoulou, Lefteris Moussiades, 'Chatbots: History, technology, and applications', Machine Learning with Applications, ['2020', '2020']",
    "Daniel Adiwardana, Luong Minh-Thang, David R. So, V. Quoc,  Le, 'Towards a Human-like Open-Domain Chatbot', , 2020"
  ],
  "keywords": [
    "Socrates",
    "Assistant",
    "code",
    "user",
    "SoftwareEngineer",
    "Rossetal",
    "function",
    "Scientist",
    "Researcher",
    "return",
    "unit test",
    "euclid function",
    "euclid",
    "Programmer",
    "Write",
    "Conversational",
    "Python",
    "participants",
    "tryagain",
    "Programmer s Assistant"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1iq6p3gaIVo_jKME5_Glk072YFFumSlfb"
}
{
  "id": 20,
  "title": "Generating Diverse Code Explanations using the GPT-3 Large Language Model",
  "authors": [
    "Stephen MacNeil",
    "Seth Bernstein",
    "Andrew Tran",
    "Erin Ross",
    "Dan Mogil",
    "Ziheng Huang"
  ],
  "institutions": [
    "Temple University",
    "University of California-San Diego"
  ],
  "resume": "No abstract available",
  "content": "USE CASES To understand the types of explanations GPT-3  can generate,\nwe issued over 700 prompts across numerous code snippets. An\nexample prompt and resulting explanation is shown in Figure 1.\nWe discovered eight explanation types and Figure 2 includes three\nexplanation types to illustrate the explanatory power of GPT-3. The\nadditional types include: 1) tracing the execution of code, 2) fixing\nbugs and explaining how they were fixed, 3) generating analogies\nto real world settings, 4) listing relevant programming concepts,\nand 5) predicting the console output.\n2.1 Analyzing and explaining time complexity\nInstructors rate time complexity as the most dificult programming\ntopic . However, understanding time complexity is important  because it facilitates decision-making so students choose an\nappropriate algorithm for a given problem. This use case shows\nGPT-3 can identify and explain time complexity.\n2.2 Identifying common mistakes made by\nbeginner programmers\nCommonality exists in how students solve programming\nproblems  and the mistakes they make . Pedagogical\ntechniques, such as the ?muddiest point? highlight these common and\nmost confusing concepts . GPT-3 can automatically create\na checklist of common mistakes students might make regarding a\ngiven code snippet. Summarizing code at multiple levels of\nabstraction\nBefore understanding how a code snippet executes, it is often useful\nto understand the purpose of the code . The summary\ngenerated by GPT-3 and shown in Figure 2 defines the goal, traces the\nexecution, and highlights relevant CS concepts such as arrays.\n3 DISCUSSION O u r   t h r e e   u s e   c a s e s   d e m o n s t r a t e   t h e   p o t e n t i a l   f o r   G P T - 3   t o   e x p l a i n \n c o d e   f o r   i n t r o   C S   s t u d e n t s .   O u r   p o s t e r   p r e s e n t a t i o n   w i l l   f e a t u r e   a l l \n e i g h t   e x p l a n a t i o n   t y p e s   a s   a   d e s i g n   s p a c e   o f   e x p l a n a t i o n s   t o   c o n v e y \n t h e   d i v e r s i t y   o f   e x p l a n a t i o n s   t h a t   c a n   b e   g e n e r a t e d   b y   L L M s .   W e   w i l l \n h i g h l i g h t   b e s t   p r a c t i c e s   f o r   g e n e r a t i n g   e f e c t i v e   e x p l a n a t i o n s   a n d \n p i t f a l l s   t h a t   l e a d   t o   l e s s   e f e c t i v e   e x p l a n a t i o n s .   W e   a r e   e v a l u a t i n g \n t h e   u s e f u l n e s s   o f   t h e s e   e x p l a n a t i o n s   i n   a   s e r i e s   o f   s u m m e r   c l a s s e s .",
  "references": [
    "Amjad Altadmri,  Neil CC Brown, '37 million compilations: Investigating novice programming mistakes in large-scale student data', In Proceedings of the 46th ACM Technical Symposium on Computer Science Education, 2015",
    "Tom Brown, Amanda Jared D Kaplan,  Askell, 'Language models are few-shot learners', Advances in Neural Information Processing Systems, ['2020', '2020']",
    "Adam Carberry, Cynthia Waters, 'Unmuddying? course content using muddiest point reflections', In 2013 IEEE Frontiers in Education Conference (FIE), 2013"
  ],
  "keywords": [
    "Large Language Model",
    "Diverse Code Explanations",
    "Generating Diverse Code",
    "Large Language",
    "Language Model",
    "Generating Diverse",
    "TempleUniversity TempleUniversity TempleUniversity",
    "TempleUniversity TempleUniversity",
    "Diverse Code",
    "Code Explanations",
    "TempleUniversity TempleUniversity UniversityofCalifornia",
    "TempleUniversity",
    "Large",
    "Model",
    "Diverse",
    "Explanations",
    "Language",
    "StephenMacNeil AndrewTran DanMogil",
    "FIE",
    "TempleUniversity UniversityofCalifornia"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1RZqed9f7TtOEgl5qvuMsDgQq4I9_9eCM"
}
{
  "id": 21,
  "title": "Framing the News: From Human Perception to Large Language Model Inferences",
  "authors": [
    "David Alonso del Barrio",
    "Daniel Gatica-Perez"
  ],
  "institutions": [
    "Idiap Research Institute and EPFL",
    "Idiap Research Institute"
  ],
  "content": "CCS CONCEPTS ? Computing methodologies ? Information extraction; ?\nHuman-centered computing ? Text input.\nCovid-19 no-vax, news framing, GPT-3, prompt-engineering,\ntransformers, large language models\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org. ICMR ?23, June 12?15, 2023, Thessaloniki, Greece\n 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0178-8/23/06. . . $15.00\nhttps://doi.org/10.1145/3591106.3592278 INTRODUCTION In recent years, there has been a proliferation in the use of concepts\nsuch as data journalism, computational journalism, and\ncomputerassisted reporting  , which all share the vision of bridging\njournalism and technology. The progress made in NLP has been\ngradually integrated into the journalistic field . More\nspecifically, machine learning models based on transformers have\nbeen integrated in the media sector in diferent tasks  such as\nthe creation of headlines with generative languages models ,\nsummarization of news articles , false news detection ,\nand topic modeling and sentiment analysis . The development of\nlarge language models such as GPT-3 , BLOOM  or ChatGPT\nshow a clear trend towards human-machine interaction becoming\neasier and more intuitive, opening up a wide range of research\npossibilities. At the same time, the use of these models is also\nassociated with a lack of transparency regarding how these models\nwork, but eforts are being made to bring some transparency to\nthese models, and to analyze use cases where they can be useful and\nwhere they cannot . Based on the premises that these models\nopen up a wide range of research directions , and that at the same\ntime (and needless to say) they are not the solution to all problems,\nwe are interested in identifying use cases and tasks where they\ncan be potentially useful, while acknowledging and systematically\ndocumenting their limitations . More specifically, the aim of\nthis work is to analyze the performance of GPT-3.5 for a specific\nuse case, namely the analysis of frames in news, from an empirical\npoint of view, with the objective of shedding light on a potential\nuse of generative models in journalistic tasks. Frame analysis is a concept from journalism, which consists of\nstudying the way in which news stories are presented on an issue,\nand what aspects are emphasized: Is a merely informative vision\ngiven in an article? Or is it intended to leave a moral lesson? Is\na news article being presented from an economic point of view?\nOr from a more human, emotional angle? The examples above\ncorrespond to diferent frames with which an article can be written. The concept of news framing has been studied in computing as\na step beyond topic modeling and sentiment analysis, and for this\npurpose, in recent years, pre-trained language models have been\nused for fine-tuning the classification process of these frames \n, but the emergence of generative models opens the possibility\nof doing prompt-engineering of these classification tasks, instead\nof the fine-tuning approach investigated so far. Our work aims to address this research gap by posing the\nfollowing research questions: RQ1: What are the main frames in the news headlines about\nthe anti-vaccine movement, as reported in newspapers across 5\nEuropean countries? RQ2: Can prompt engineering be used for classification of\nheadlines according to frames? By addressing the above research questions, our work makes the\nfollowing contributions: Contribution 1. We implemented a process to do human\nannotation of the main frame of 1786 headlines of articles about the\nCovid-19 no-vax movement, as reported in 19 newspapers from 5\nEuropean countries (France, Italy, Spain, Switzerland and United\nKingdom.) At the headline level, we found that the predominant\nframe was human interest, where this frame corresponds to a\npersonification of an event, either through a statement by a person,\nor the explanation of a specific event that happened to a person.\nFurthermore, we found a large number of headlines annotated as\ncontaining no frame, as they simply present information without\nentering into evaluations. We also found that for all the countries\ninvolved, the distribution of frame types was very similar, i.e.,\nhuman interest and no frame are the two predominant frames. Finally,\nthe generated annotations allowed to subsequently study the\nperformance of a large language model. Contribution 2. We studied the performance of GPT-3.5 on\nthe task of frame classification of headlines. In addition to using\nthe fine-tuning approach from previous literature, we propose an\nalternative approach for frame classification that requires no labeled\ndata for training, namely prompt-engineering using GPT-3.5. The\nresults show that fine-tuning with GPT-3.5 produces 72% accuracy\n(slightly higher than other smaller models), and that the\npromptengineering approach results in lower performance (49% accuracy.)\nOur analysis also shows that the subjectivity of the human labeling\ntask has an efect on the obtained accufracy. The paper is organized as follows. In Section 2, we discuss related\nwork. In Section 3, we describe the news dataset. In Section 4, we\ndescribe the methodology for both human labeling and machine\nclassification of news frames. We present and discuss results for\nRQ1 and RQ2 in Sections 5 and 6, respectively. Finally, we provide\nconclusions in Section 7.\n2 RELATED WORK Framing has been a concept widely studied in journalism, with a\ndefinition that is rooted in the study of this domain : ?To frame\nis to select some aspects of a perceived reality and make them more\nsalient in a communicating text, in such a way as to promote a\nparticular problem definition, causal interpretation, moral evaluation,\nand/or treatment recommendation for the item described.? For frame recognition, there are two main approaches: the\ninductive approach , where one can extract the frames after reading\nthe article, and the deductive approach , where a predefined\nlist of frames exists and the goal is to interpret if any of them\nappears in the article. In the deductive case, there are generic frames\nand subject-specific frames, and the way to detect them typically\ninvolves reading and identifying one frame at a time, or through\nanswers to yes/no questions that represent the frames. Semetko et\nal.  used 5 types of generic frames (attribution of responsibility,\nhuman interest, conflict, morality, and economic consequences)\nbased on previous literature, and they defined a list of 20 yes/no\nquestions to detect frames in articles. For instance, the questions\nabout morality are the following: \"Does the story contain any moral\nmessage? Does the story make reference to morality, God, and other\nreligious tenets? Does the story ofer specific social prescriptions\nabout how to behave?\", and so on for each of the frame types. This\ncategorization of frames has been used in various topics such as\nclimate change  , vaccine hesitance , or immigration\n. We now compare the two approaches on a common topic, such\nas Covid-19. Ebrahim et al.  followed an inductive approach\nin which the frames were not predefined but emerged from the\ntext (e.g., deadly spread, stay home, what if, the cost of Covid-19)\nusing headlines as the unit of analysis. In contrast, the deductive\napproach has studied very diferent labels. El-Behary et al. \nfollowed the method of yes/no questions, but in addition to the\n5 generic frames presented before, they also used blame frame\nand fear frame. Adiprasetio et al.  and Rodelo  used the 5\ngeneric frames with yes/no questions, while Cataln-Matamoros et\nal.  used the 5 frames and read the headline and subheadline\nto decide the main frame. Table 1 summarizes some of the the\nexisting approaches. This previous work showed how frame labels\ncan be diferent, and also that frame analysis has been done at both\nheadline and article levels. These two approaches (inductive and\ndeductive) that originated in journalism have since been replicated\nin the computing literature. We decided to follow the deductive approach because a\npredeifned list of frames allows to compare among topics, countries,\nprevious literature, and also because they represent a fixed list of\nlabels for machine classification models. Furthermore, the\ninductive approach tends to be more specific to a topic, and from the\ncomputing viewpoint, past work has tried to justify topic modeling\nas a technique to extract frames from articles. Yl-Antitila et al.  proposed topic modeling as a frame\nextraction technique. They argued that topics can be interpreted as\nframes if three requirements are met: frames are operationalized as\nconnections between concepts; subject-specific data is selected; and\ntopics are adequately validated as frames, for which they suggested\na practical procedure. This approach was based on the choice of a\nspecific topic (e.g., climate change) and the use of Latent Dirichlet\nAllocation (LDA) as a technique to extract a number of subtopics.\nIn a second phase, a qualitative study of the top 10 words of each\nsubtopic was performed, and the diferent subtopics were\neliminated or grouped, reducing the number and establishing a tentative\ndescription. In a third phase, the top 10 articles belonging to that\nframe/topic were taken, and if the description of the topic fitted\nat least 8 of the 10 articles, that topic/frame remained. The frames\nfound in this article were: green growth, emission cuts, negotiations\nand treaties, environmental risk, cost of carbon emissions, Chinese\nemissions, economics of energy production, climate change,\nenvironmental activism, North-South burden sharing, state leaders\nnegotiating, and citizen participation. From Entman?s definition of frame , it seems that the\ndeductive approach is more refined than the inductive approach (which\nseems to resemble the detection of sub-themes.) For example, with\nregard to climate change, there are stories on how people have been\nafected by climate change from an emotional point of view, thus\npersonalizing the problem. In this case, we could categorize the\ncorresponding frame as human interest, as the writer of the article\nis selecting \"some aspects of a perceived reality and make them\nmore salient\". The language subtleties with which news articles are\npresented cannot be captured with basic topic modeling. Isoaho et al. held the position that while the benefits of\nscale and scope in topic modeling were clear, there were also a\nnumber of problems, namely that topic outputs do not correspond\nto the methodological definition of frames, and thus topic modeling\nremained an incomplete method for frame analysis. Topic modeling,\nin the practice of journalistic research, is a useful technique to deal\nwith the large datasets that are available, yet is often not enough to\ndo more thorough analyses . In our work, we clearly notice that\nframe analysis is not topic modeling. For example, two documents\ncould be about the same topic, say Covid-19 vaccination, but one\narticle could emphasize the number of deaths after vaccination,\nwhile the other emphasized the role of the vaccine as a solution to\nthe epidemic. We also consider that the larger the number of possible frame\ntypes, the more likely it is to end up doing topic modeling instead of\nframe analysis. Using a deductive approach, Dallas et al.  created\na dataset with articles about polemic topics such as immigration,\nsame sex marriage, or smoking, and they defined 15 types of frames:\n\"economic, capacity and resources, morality, fairness and equality,\nlegality, constitutionality and jurisprudence, policy prescription and\nevaluation, crime and punishment, security and defense, health and\nsafety, quality of life, cultural identity, political, external regulation\nand reputation, other\". In this case, they authors did not use a list\nof questions. Instead, for each article, annotators were asked to\nidentify any of the 15 framing dimensions present in the article\nand to label text blurbs that cued them (based on the definitions of\neach of the frame dimensions) and decide the main frame of each\narticle. In our case, we followed the idea of detecting the main frame\nby reading the text instead of answering questions, but instead of\nusing the 15 frames proposed in  , we used the 5 generic frames\nproposed in . A final decision in our work was the type of text to analyze,\nwhether headlines or whole article. For this decision, the chosen\nclassification method was also going to be important. For example,\nKhanehzar et al.  used traditional approaches such as SVMs as\nbaseline, and demonstrated the improvement in frame\nclassification with the use of pre-trained languages models such as BERT,\nRoBERTa and XLNet, following a fine-tuning approach, setting\nas input text a maximum of 256 tokens (although the maximum\nnumber of input tokens in these models is 512 tokens.) Liu et al.\n classified news headlines about the gun problem in the United\nStates, arguing for the choice of headlines as a unit of analysis\nbased on previous journalism literature , , that advocated\nfor the importance and influence of headlines on readers and the\nsubsequent perception of articles. From a computational viewpoint,\nusing headlines is also an advantage, since you avoid the 512 token\nlimitation in BERT-based models. Therefore, we decided to work\nwith headlines about a controversial issue, namely the Covid-19\nno-vax movement. Continuing with the question of the methods used for\nclassiifcation, much work has been developed in prompt engineering,\nespecially since the release of GPT-3. Liu et al. presented a good\noverview of the work done on this new NLP paradigm, not only\nexplaining the concept of prompt engineering, but also the\ndiferent strategies that can be followed both in the design of prompts,\nthe potential applications, and the challenges to face when using\nthis approach. Prompt engineering applications include knowledge\nprobing , information extraction , NLP reasoning ,\nquestion answering , text generation , multi-modal learning ,\nand text classification , the latter being the prompt-engineering\nuse case in our work. Puri et al. presented a very interesting\nidea that we apply to our classification task. This consists of\nproviding the language model with natural language descriptions of\nclassification tasks as input, and training it to generate the correct\nanswer in natural language via a language modeling objective. It is\na zero-shot learning approach, in which no examples are used to\nexplain the task to the model. Radford et al.  demonstrated that\nlanguage models can learn tasks without any explicit supervision.\nWe have followed this approach to find an alternative way to do\nframe analysis. As mentioned before, the emergence of giant models like GPT-3,\nBLOOM, and ChatGPT are a very active research topic. To the best\nof our knowledge, on one hand our work extends the computational\nanalysis of news related to the covid-19 no-vax movement, which\nillustrates the influence of the press on the ways societies think\nabout relevant issues , , and on the other hand it adds to\nthe literature of human-machine interaction, regarding the design\nof GPT-3 prompts for classification tasks , . 3 DATA: EUROPEAN COVID-19 NEWS  DATASET We used part of the European Covid-19 News dataset collected in\nour recent work . This dataset contains 51320 articles on\nCovid19 vaccination from 19 newspapers from 5 diferent countries: Italy,\nFrance, Spain, Switzerland and UK. The articles cover a time period\nof 22 months, from January 2020 to October 2021. All content was\ntranslated into English to be able to work in a common language.\nThe dataset was used for various analyses, such as name entity\nrecognition, sentiment analysis, and subtopic modeling, to\nunderstand how Covid-19 vaccination was reported in Europe through\nthe print media (in digital format.) The subtopic modeling analysis\nrevealed a subsample of articles on the no-vax movement, which is\nthe one we have used in this paper. We took the headlines of the\narticles associated with the no-vax movement, selecting all articles\ncontaining any of the keywords in Table 2 in the headline or in the\nmain text. This corresponds to a total of 1786 headlines.\nIn Table 3, we show the number of headlines per country and\nnewspaper. France is the country with the most no-vax articles in\nthe corpus, with 523 articles, followed by Italy with 508. However,\nnote that there are 6 newspapers from France, while only 2 from\nItaly. Corriere della Sera is the newspaper that dealt most frequently\nwith the subject (429 articles), while The Telegraph is the second\none (206 articles). The total number of articles normalized by the\nnumber of newspapers per country is also shown in the last column\nof the Table. Using these normalized values, the ranking is Italy,\nUK, France, Switzerland, and Spain.\nTo carry out the labeling of the frames in our corpus of headlines, we\nifrst designed a codebook, which contained the definitions of each\nof the frame types and a couple of examples of each type, as well\nas a definition of the corpus subject matter and definitions of the\nconcept of frame analysis, so that the annotators could understand\nthe task to be performed. The codebook follows the proposed by\n with 5 generic frames (attribution of responsibility, human\ninterest, conflict, morality, and economic consequences) plus one\nadditional ?no-frame? category. Two researchers were engaged to\nannotate a sample of the collected newspaper articles following a\nthree-phase training procedure. In the first phase, annotators had to read the codebook and get\nfamiliar with the task. In the second phase, they were asked to\nidentify the main frame in the same subset of 50 headlines. At the\nend of the second phase, the intercoder reliability (ICR) was 0.58\nbetween the 2 annotators. We analyzed those cases where there\nwere discrepancies, and observed that in some cases, there was not a\nunique main frame, because both annotators had valid arguments to\nselect one of the frames. In other cases, the discrepancies were due\nto slight misunderstanding of the definitions. In the third phase, the\nannotators coded again 50 headlines, and the ICR increased to was\n0.66. We realized that the possibility of having two frames remained.\nThey discussed the cases in which they had disagreed, and if the\nother person?s arguments were considered valid, it could be said that\nthere were two frames. After this three-phase training procedure,\nannotators were ready to annotate the dataset independently. We\ndivided the dataset into two equal parts, and each person annotated\n893 headlines.\n4.2 Fine-tuning GPT-3.5 and BERT-based models With the annotated dataset, we investigated two NLP approaches:\nthe first one involves fine-tuning a pre-trained model; the second\none is prompt engineering. Pre-trained language models have been\ntrained with large text strings based on two unsupervised tasks,\nnext sentence prediction and masked language model. Figure 1\nsummarizes these techniques. In the first approach, a model with a fixed architecture is\npretrained as a language model (LM), predicting the likelihood of the\nobserved textual data. This can be done due to the availability of\nlarge, raw text data needed to train LMs. This learning process can\nproduce general purpose features of the modeled language. The\nlearning process produces robust, general-purpose features of the\nlanguage being modeled. The above pre-trained LM is then adapted\nto diferent downstream tasks, by introducing additional parameters\nand adjusting them using task-specific objective functions. In this\napproach, the focus was primarily on goal engineering, designing\nthe training targets used in both the pre-training and the fine-tuning\nstages . We present an example to illustrate the idea. Imagine that the\ntask is sentiment analysis, and we have a dataset with sentences\nand their associated sentiment, and a pre-trained model, which is a\nsaved neural network trained with a much larger dataset. For that\npre-trained model to address the target task, we unfreeze a few of\nthe top layers of the saved model base and jointly train both the\nnewly-added classifier layers and the last layers of the base model.\nThis allows to \"fine-tune\" the higher-order feature representations\nin the base model to make them more relevant for the sentiment\nanalysis task. In this way, instead of having to obtain a very large\ndataset with target labels to train a model, we can reuse the\npretrained model and use a much smaller train dataset. We use a part\nof our dataset as examples for the model to learn the task, while\nthe other part of the dataset is used to evaluate model performance. Previous works related to frame classification in the computing\nliterature have used fine-tuning, BERT-based models. In our work,\nwe have done the same as a baseline, but we aimed to go one step\nfurther and also produce results using fine-tuning of GPT-3.5.\n4.3 Prompt-engineering with GPT-3.5 Model fine-tuning has been widely used, but with the emergence\nof generative models such as GPT-3, another way to approach\nclassification tasks has appeared. The idea is to use the pre-trained\nmodel directly and convert the task to be performed into a format\nas close as possible to the tasks for which it has been pre-trained.\nThat is, if the model has been pre-trained from next word prediction\nas in the case of GPT-3, classification can be done by defining a\nprompt, where the input to the model is an incomplete sentence,\nand the model must complete it with a word or several words, just\nas it has been trained. This avoids having to use part of the already\nlabeled dataset to teach the task to be performed to the model, and\na previous labeling is not needed . In this approach, instead of adapting pre-trained LMs to\ndownstream tasks via objective engineering, downstream tasks are\nreformulated to look more like those solved during the original LM\ntraining with the help of a textual prompt. For example, when\nrecognizing the emotion of a social media post, ?I missed the bus today.?,\nwe may continue with a prompt ?I felt so _?, and ask the LM to\nifll the blank with an emotion-bearing word. Or if we choose the\nprompt ?English: I missed the bus today. French: _?), an LM may\nbe able to fill in the blank with a French translation. In this way,\nby selecting the appropriate prompts, we can influence the model\nbehavior so that the pre-trained LM itself can be used to predict the\ndesired output, even without any additional task-specific training\n. We use this emerging NLP approach to classify frames at headline\nlevel. We are not aware of previous uses of this strategy to classify\nframes as we propose here. The idea is the following. Prompt\nengineering consists of giving a prompt to the model, and understands\nthat prompt as an incomplete sentence. To do prompt\nengineering with our dataset, we needed to define an appropriate prompt\nthat would produce the headline frames as output. We defined\nseveral experiments with the Playground of GPT-3, in order to find\nthe best prompt for our task. In our initial experiments, we\nfollowed existing approaches in prompt engineering to do sentiment\nanalysis, where the individual answer was an adjective, and this\nadjective was matched with a sentiment. In a similar fashion, we\ndecided to build a thesaurus of adjectives that define each of the\nframes. For instance, the human interest frame could be\n?interesting?, ?emotional?, ?personal?, ?human?. The conflict frame could be:\n?conflictive?, ?bellicose?, ?troublesome?, ?rowdy?, ?quarrelsome?,\n?troublemaker?, ?agitator?, etc. After the list of adjectives was defined,\nwe needed to define the prompt in order to get, as an answer, one\nof the adjectives in our thesaurus to match them with the frame.\nWe used the GPT-3 playground using the headline as input and\nasking for the frame as output, but the strategy did not work. In\nour final experiment, instead of giving the headline as input, we\ngave the definitions of each type of frame plus the headline, and we\nasked the model to choose between the diferent types of frames\nas output. In this way, the output of the model was directly one of\nthe frames, and we avoided the step of matching adjectives with\nframes. An example is shown in Figure 2.\nFor the GPT-3 configuration 1, there are 3 main concepts:\n? TEMPERATURE . This parameter controls randomness,\nlowering it results in less random completions.\n? TOP_P . This parameter controls diversity via nucleus\nsampling.\n? MAX_TOKENS. This parameter indicates the\nmaximum number of tokens to generate,\n? MODEL. GPT-3 ofer four main models with diferent levels\nof power, suitable for diferent tasks. Davinci is the most\ncapable model, and Ada is the fastest. After testing with the GPT-3 playground and varying diferent\nhyper-parameters to assess performance, we set the temperature to\n0, since the higher the temperature the more random the response.\nFurthermore, the Top-p parameter was set to 1, as it would likely\nget a set of the most likely words for the model to choose from. The\nmaximum number of tokens was set to 2; in this way, the model\nis asked to choose between one of the responses. As a model, we\nused the one with the best performance at the time of experimental\ndesign, which was TEXT-DAVINCI-003, recognized as GPT 3.5.\n5 RESULTS: HUMAN LABELING OF FRAMES  IN NO-VAX NEWS HEADLINES (RQ1) In this section, we present and discuss the results of the analysis\nrelated to our first RQ. Figure 3 shows the distribution of frames per country at headline\nlevel, with human interest and no-frame being the predominant\n1https://beta.openai.com/docs/introduction\nones. Attribution of responsibility is the third one except in\nSwitzerland, where the corresponding frame is conflict. Finally, morality\nand economic are the least represented in the dataset for every\ncountry. The monthly distribution of frames aggregated for all countries\nis shown in Fig. 4. We can see two big peaks, the first one in January\n2021 and the second one in August 2021. In all countries, the\nvaccination process started at the end of December 2020, so it makes\nsense that the no-vax movement started to be more predominant in\nthe news in January 2021. Human interest is the most predominant\nframe. Manual inspection shows that this is because the headlines\nare about personal cases of people who are pro- or anti- vaccine.\nAttribution of responsibility is also present. Manual inspection\nindicates that local politicians and health authorities had to make\ndecisions about who could be vaccinated at the beginning of the\nprocess. The second peak at the end of summer 2021 coincided\nwith the health pass (also called Covid passport in some countries),\nand we can observe a peak in the curve corresponding to the\nconlfict frame, reflecting the demonstrations against the measure of\nmandatory health passes taken by country governments. In Figure 5, we compare the sentiment per frame and per country,\nto understand if there were any major diferences. The sentiment\nanalysis labels were obtained using BERT-sent from the Hugging\nFace package , used in our previous work (please refer to our\noriginal analysis in  for details.) We normalized the results\nbetween 0 and 1 to compare frames between countries. We see that the\nsentiment is predominantly neutral (in blue). Examining in more\ndetail the negative and positive sentiment of each frame category,\nwe observed a few trends:\n? Attribution of responsibility: Negative sentiment represents\n30-40% of the cases, while positive tone is only found in\nresidual form in Italy, Switzerland, and the United Kingdom.\n? Conflict: Negative sentiment represents 20-35% of the cases.\n? Economic: Predominantly neutral, with only negative tone\nin Italy and UK (in the latter case, all headlines with this\nframe were considered negative.)\n? Human interest: Negative sentiment represents 30-40% of\nthe cases, while positive tone is only found in residual form\nin Italy, Spain, and Switzerland.\n? Morality: Predominantly neutral, with negative tone in Italy, Switzerland, and the United Kingdom,\n? No frame: 20-30% of negative content. Regarding the results of the annotation process, the fact that the\ndistribution of the 6 frame types is relatively similar between\ncountries suggests that the anti-vaccine movement issue was treated\nin a similar way in these countries. The fact that human interest\nis the most dominant frame indicates that this issue was treated\nfrom a more human and emotional approach, with headlines about\npersonal experiences, celebrities giving their opinion about\nvaccination, and politicians defending vaccine policies. Moreover, the\nreason for many headlines being classified as no-frame is partly\ndue to how data was selected. We chose articles that contained\nwords related to no-vax, either in the headline or in the article. This\nresulted in many headlines not containing anything specific related\nto no-vax, while the no-vax content was actually included in the\nmain text of the corresponding articles. It is worth mentioning that prior to obtaining the results, we had\nexpected that attribution of responsibility would be among the most\nprominent frames, since governments took many measures such as\nmandatory health pass requirements to access certain sites; we had\nalso expected that the conflict frame would be prominent, since\nthere were many demonstrations in Europe. In reality, however,\nthese frames categories were not reflected as frequently at the\nheadline level. Regarding the analysis at the temporal level, it is clear that certain\nevents were captured by the press, such as the start of vaccination\nor the mandatory vaccination passport. Finally, the sentiment analysis of the diferent frames shows that\nthe predominant tone in all of them is neutral or negative, with very\nsimilar trends between countries. This association between\nsentiment analysis and frames has been discussed in previous literature\n .\n6 RESULTS: GPT-3.5 FOR FRAME  CLASSIFICATION OF HEADLINES (RQ2) H e r e ,   w e   p r e s e n t   a n d   d i s c u s s   t h e   r e s u l t s   r e l a t e d   t o   o u r   s e c o n d   R Q . \n 6 . 1 Fine-tuning GPT-3.5 Table 4 shows the results of the 6-class classification task using\n5-cross validation. Three models were used: GPT-3.5 and two\nBERTbased models. We observe that, on average, GPT-3.5 performs better\nthan the BERT-based models. This is somehow expected as\nGPT3.5 is a much larger model. Overall, in the case of fine-tuning, the\nbest performance for the six-class frame classification task is 72%\naccuracy, which is promising, with an improvement over previous\nmodels based on BERT. Yet, it should be noted that the performance\ndiferences are modest (2% improvement between GPT-3.5 and\nRoBERTa). On the other hand, BERT is open-source, while GPT-3 has an\neconomic cost as the use of the model is not free, which monetarily\nlimits the number of experiments that can be performed with it,\nas well as the diferent configurations one can explore to improve\nperformance. This is important because much of the improvement\nin performance requires empirical explorations of model parameters\nMore specifically, the cost of an experiment for each of the folds has\na cost of 4 dollars (at the time of writing this paper.) This represents\na limitation in practice. Furthermore, GPT-3 has a significant carbon footprint. Similarly,\nfor prompt engineering (discussed in the next subsection), choosing\nthe right prompt (i.e., the words that best define the task so that the\nmodel is able to perform adequately) is also based on trial and error.\nThis also has an impact on carbon footprint. In connection with\nthis topic, Strubell et al. argue that improvements in the\naccuracy of models depend on the availability of large computational\nresources, which involve large economic and environmental costs.\nA criticism has been made as ?the rich get richer?, in the sense that\nnot all research groups have suficient infrastructure resources and\naccess to funding needed to use these models and improve their\nperformance. Also in relation to this analysis, the work of Bender\net al.  evaluates the costs and risks of the use of large language\nmodels, stating that researchers should be aware of the impact that\nthese models have on the environment, and assess whether the\nbenefits outweigh the risks. The work in  provides a very telling\nexample, where people living in the Maldives or Sudan are afected\nby floods and pay the environmental price of training English LLMs,\nwhen similar models have not been produced for languages like\nDhivehi or Sudanese Arab. In short, there is a need to establish\nways to use this technological development responsibly, and it all\nstarts with being aware of the risks it presents.\n6.2 Prompt-engineering with GPT-3.5 For each headline, we got the frame that the model considered the\nmost likely, and we compared these GPT-3.5 inferences with the\nframes labeled by the annotators. The agreement between model\nand annotator was of 49%. Analyzing the results, and specifically\nlooking at the cases where the annotator and GPT-3.5 disagreed,\nwe discovered that according to the frame definitions, the model\nin some cases proposed a frame that indeed made sense. This\nobservation, together with our previous experience in the annotation\nprocess, where headlines could have more than one valid frame,\nled us to design a second post-hoc experiment. We took all the\nheadlines where each of the two annotators had disagreed with\nGPT-3.5, and we asked the annotators to state whether they would\nagree (or not) with each GPT-inferred label for a given headline.\nIt is important to emphasize that the annotators did not know the\norigin of that label, i.e., they did not know if it was the label they\nhad originally assigned, or if it was a random one. In this way, we\ncould quantify how GPT-3.5 worked according to valid arguments\nprovided by the annotators. In this post-hoc experiment, the model\nagreed in 76% of cases with the annotators. Looking at the results of the classification models, the 49%\naccuracy of the prompt-engineering approach can be considered low,\nyet we consider that it is a valid avenue for further investigation,\nas in the second post-hoc analysis, we found that the model agrees\nwith human annotators in 76% of the cases. Clearly, framing\ninvolves aspects of subjectivity . Much of what we do as people\nhas a subjective component, influenced by how we feel or how we\nexpress opinions. News reading is never fully objective, and the annotators\nengaged in the frame classification task, influenced by their personal\nstate of mind, experience, and culture, may perceive information\ndiferently. Monarch afirms that \"for simple tasks, like binary labels\non objective tasks, the statistics are fairly straightforward to decide\nwhich is the ?correct? label when diferent annotators disagree. But\nfor subjective tasks, or even objective tasks with continuous data,\nthere are no simple heuristics for deciding what the correct label\nshould be\" . Subjectivity is involved in both the generation and perception\nof information: the assumption that there is only one frame is\ncomplicated by the point of view of the reader. In the case of news, the\ninformation sender (the journalist) has an intention, but the receiver\n(the reader) plays a role and is influenced by it. In psychology, this\nis known as the lens model of interpersonal communication, where\nthe sender has certain objectives, but the receiver can interpret\nor re-interpret what the sender wants to say, with more or less\naccuracy . Following this discussion on subjectivity, the question arose as to\nwhat would happen if, instead of headlines, we used the complete\narticle as a source of analysis. We wondered if longer text could\nmake the frame labeling task clearer than when using headlines.\nYet another possible hypothesis is that having to read longer texts\ncould lead to the same subject being presented from diferent angles.\nPlease recall that in the existing literature discussed in Section 2,\nboth headlines and full articles have been used from frame analysis\n(see Table 1.) This remains as an issue for future work.\n7 CONCLUSIONS In this paper, we first presented an analysis of human-generated\nnews frames on the covid-19 no-vax movement in Europe, and\nthen studied diferent approaches using large language models for\nautomatic inference of frames. We conclude by answering the two\nresearch questions we posed: RQ1: What are the main frames in the news headlines about the\ncovid-19 anti-vaccine movement in 5 European countries? After\nannotating the headlines, we found that of the 1786 headlines,\nthe predominant frame is human interest (45.3% of cases), which\npresents a news item with an emotional angle, putting a face to a\nproblem or situation. We also found that a substantial proportion\nof headlines were annotated as not presenting any frame (40.2% of\ncases). Finally, the other frame types are found more infrequently. RQ2: Can prompt engineering be used for classification of\nheadlines according to frames? We first used fine-tuning of a number of\nlanguage models, and found that GPT-3.5 produced classicfiation\naccuracy of 72% on a six-frame classification task. This represented a\nmodest 2% improvement over BERT-based models, at a significantly\nlarger environmental cost. We then presented a new way of\nclassifying frames using prompts. At the headline level, inferences made\nwith GPT-3.5 reached 49% of agreement with human-generated\nframe labels. In many cases, the GPT-3.5 model inferred frame\ntypes that were considered as valid choices by human annotators,\nand in an post-doc experiment, the human-machine agreement\nreached 76%. These results have opened several new directions for\nfuture work. ACKNOWLEDGMENTS T h i s   w o r k   w a s   s u p p o r t e d   b y   t h e   A I 4 M e d i a   p r o j e c t ,   f u n d e d   b y   t h e \n E u r o p e a n   C o m m i s s i o n   ( G r a n t   9 5 1 9 1 1 )   u n d e r   t h e   H 2 0 2 0   P r o g r a m m e \n I C T - 4 8 - 2 0 2 0 .   W e   a l s o   t h a n k   t h e   n e w s p a p e r s   f o r   s h a r i n g   t h e i r   o n l i n e \n a r t i c l e s .   F i n a l l y ,   w e   t h a n k   o u r   c o l l e a g u e s   H a e e u n   K i m   a n d   E m m a \n B o u t o n - B e s s a c   f o r   t h e i r   s u p p o r t   w i t h   a n n o t a t i o n s ,   a n d   V i c t o r   B r o s \n a n d   O l e k s i i   P o l e g k y i   f o r   d i s c u s s i o n s .",
  "references": [
    "given-names, surname, 'Pandemic crisis in online media: Quantitative framing analysis on Detik', com's coverage of Covid-19. Jurnal Ilmu Sosial Dan Ilmu Politik, ['2020', '2020']",
    "Neel Alex, C Jess Riedel, Alexis Carlier, 'RAFT: A real-world few-shot text classification benchmark', arXiv preprint arXiv:2109.14076, ['2021', '2021']",
    "Vaccination News? A Five-Country,  Analysis., 'How Did Europe's Press Cover Covid-', [3] David Alonso del Barrio and Daniel Gatica-Perez, ['2022', '2022']"
  ],
  "keywords": [
    "Tolabelframesoffull Reading",
    "articles full article",
    "Public Tolabelframesoffull Reading",
    "Tolabelframesoffull",
    "Perception to Large",
    "articles",
    "Language Model Inferences",
    "Large Language Model",
    "frame",
    "full article",
    "frames",
    "Model Inferences",
    "models",
    "Reading",
    "Human Perception",
    "articles full",
    "Classification full article",
    "Large Language",
    "article",
    "Public Tolabelframesoffull"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1R1zjjapCmV6-v2N15kzCxk28ISzmCQPU"
}
{
  "id": 22,
  "title": "Large Language Model Augmented Narrative Driven Recommendations",
  "authors": [
    "Sheshera Mysore",
    "Andrew McCallum",
    "Hamed Zamani"
  ],
  "institutions": [
    "University of Massachusetts Amherst"
  ],
  "resume": "Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with fewshot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an efective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.",
  "content": "CCS CONCEPTS ?   I n f o r m a t i o n   s y s t e m s   ?   R e c o m m e n d e r   s y s t e m s ;   U s e r s   a n d \n i n t e r a c t i v e   r e t r i e v a l ;   ?   C o m p u t i n g   m e t h o d o l o g i e s   ?   N a t u r a l   l a n g u a g e \n g e n e r a t i o n . INTRODUCTION Recommender systems personalized to users are an important\ncomponent of several industry-scale platforms . These\nsystems function by inferring users? interests from their prior\ninteractions on the platform and making recommendations based on\nthese inferred interests. While recommendations based on historical\ninteractions are efective, users soliciting recommendations often\nstart with a vague idea about their desired target items or may\ndesire recommendations depending on the context of use, often\nmissing in historical interaction data (Figure 1). In these scenarios,\nit is common for users to solicit recommendations through\nlongform narrative queries describing their broad interests and context.\nInformation access tasks like these have been studied as\nnarrativedriven recommendations (NDR) for items ranging from books \nand movies , to points of interest . Bogers and Koolen \nnote these narrative requests to be common on discussion forums\nand several subreddits1, but, there is a lack of support for these\ncomplex natural language queries in current recommenders. However, with the emergence of conversational interfaces for\ninformation access tasks, support for complex NDR tasks is likely\nto become necessary. In this context, recent work has noted an\nincrease in complex and subjective natural language requests\ncompared to more conventional search interfaces . Furthermore,\nthe emergence of large language models (LLM) with strong\nlanguage understanding capabilities presents the potential for fulfilling\nsuch complex requests . This work explores the potential for\nre-purposing historical user-item recommendation datasets,\ntraditionally used for training collaborative filtering recommenders,\nwith LLMs to support NDR. Specifically, given a user?s interactions,  , with items and\ntheir accompanying text documents (e.g., reviews, descriptions)\n = { }=1, selected from a user-item interaction dataset I, we\nprompt InstructGPT, a 175B parameter LLM, to author a synthetic\nnarrative query  based on  (Figure 2). Since we expect the\nquery  to be noisy and not fully representative of all the user\nreviews,  is filtered to retain only a fraction of the reviews based\non a language-model assigned likelihood of  given a user\ndocument,  . Then, a pre-trained LM based retrieval model (110M\nparameters) is fine-tuned for retrieval on the synthetic queries and\nifltered reviews. Our approach, which we refer to as Mint2, follows from the\nobservation that while narrative queries and suggestions are often\nmade in online discussion forums, and could serve as training data,\nthe number of these posts and the diversity of domains for which\nthey are available is significantly smaller than the size and diversity\nof passively gathered user-item interaction datasets. E.g. while\nBogers and Koolen  note nearly 25,000 narrative requests for\nbooks on the LibraryThing discussion forum, a publicly available\nuser-item interaction dataset for Goodreads contains interactions\nwith nearly 2.2M books by 460k users  . We empirically evaluate Mint in a publicly available test\ncollection for point of interest recommendation: pointrec . To train\n1r/MovieSuggestions, r/booksuggestions, r/Animesuggest\n2Mint: Data augMentation with INteraction narraTives.\nour NDR models, we generate synthetic training data based on\nuser-item interaction datasets from Yelp. Models (110M parameters)\ntrained with Mint significantly outperform several baseline models\nand match the performance of significantly larger LLM baselines\nautoregressively generating recommendations. Code and synthetic\ndatasets are available:3\n2 RELATED WORK xref #text Proposed Method xref #text EXPERIMENTS AND RESULTS Next, we evaluate Mint on a publicly available test collection for\nNDR and present a series of ablations.\n4.1 Experimental Setup\n4.1.1 Datasets. We perform evaluations on an NDR dataset for\npoint-of-interest (POI) recommendation Pointrec . Pointrec\ncontains 112 realistic narrative queries (130 words long) obtained\nfrom discussion forums on Reddit and items pooled from baseline\nrankers. The items are annotated on a graded relevance scale by\ncrowd-workers and/or discussion forum members and further\nvalidated by the dataset authors. The item collection C in Pointrec\ncontains 700k POIs with metadata (category, city) and noisy text\nsnippets describing the POI obtained from the Bing search engine.\nFor test time ranking, we only rank the candidate items in the city\nand request category (e.g., ?Restaurants?) of the query available in\nPointrec - this follows prior practice to exclude clearly irrelevant\nitems . We use user-item interaction datasets from Yelp to\ngenerate synthetic queries for training.5 Note also that we limit our\nevaluations to Pointrec since it presents the only publicly\navailable, manually annotated, and candidate pooled test collection for\nNDR, to our knowledge. Other datasets for NDR use document\ncollections that are no longer publicly accessible , contain sparse\nand noisy relevance judgments due to them being determined with\nautomatic rules applied to discussion threads , lack pooling\nto gather candidates for judging relevance , or lack realistic\nnarrative queries . We leave the development of more robust\ntest collections and evaluation methods for NDR to future work.\n4.1.2 Implementation Details. Next, we describe important details\nfor Mint and leave finer details of the model and training to our\ncode release. To sample user interactions for generating synthetic\nqueries from the Yelp dataset, we exclude POIs and users with\nfewer than ten reviews to ensure that users were regular users of\nthe site with well represented interests. This follows common prior\npractice in preparing user-item interaction datasets for use .\nThen we retain users who deliver an average rating greater than\n3/5 and with 10-30 above-average reviews. This desirably biases\nour data to users who commonly describe their likings (rather than\ndislikes). It also retains the users whose interests are summarizable\nby QGen. In the Yelp dataset, this results in 45,193 retained users.\nNow, 10,000 randomly selected users are chosen for generating\nsynthetic narrative queries. For these users, a single randomly selected\nsentence from 10 of their reviews is included in the prompt (Figure\n2) to QGen, i.e.,  = 10. After generating synthetic queries, some\nitems are filtered out (3.2.2). Here, we exclude 40% of the items\nfor a user. This results in about 60,000 training samples for training\nBiEnc-Mint and CrEnc-Mint. These decisions were made\nmanually by examining the resulting datasets and the cost of authoring\nqueries. The expense of generating  was about USD 230.\n4.1.3 Baselines. We compare BiEnc-Mint and CrEnc-Mint\nmodels against several standard and performant retrieval model\nbaselines. These span zero-shot/unsupervised rankers, supervised\nbiencoders, unsupervised cross-encoders, and LLM baselines. BM25:\nA standard unsupervised sparse retrieval baseline based on term\noverlap between query and document, with strong generalization\nperformance across tasks and domains . Contriver: A BERT-base\nbi-encoder model pre-trained for zero-shot retrieval with weakly\nsupervised query-document pairs . MPNet-1B: A strong\nSentenceBert bi-encoder model initialized with MPNet-base and trained on\n1 billion supervised query-document pairs aggregated from\nnumerous domains . BERT-MSM: A BERT-base bi-encoder fine-tuned\non supervised question-passage pairs from MSMarco. UPR: A\ntwostage approach that retrieves items with a Contriver bi-encoder\nand re-ranks the top 200 items with a query-likelihood model using\na FlanT5 model with 3B parameters . This may be seen\nas an unsupervised ?cross-encoder? model. Grounded LLM: A\nrecently proposed two-stage approach which autoregressively\ngenerates ten pseudo-relevant items using an LLM (175B InstructGPT)\nprompted with the narrative query and generates\nrecommendations grounded in C by retrieving the nearest neighbors for each\ngenerated item using a bi-encoder . We include one few-shot\nexample of a narrative query and recommended items in the prompt\nto the LLM. We run this baseline three times and report average\nperformance across runs. We report NDCG at 5 and 10, MAP, MRR,\nand Recall at 100 and 200. Finally, our reported results should be\nconsidered lower bounds on realistic performance due to the\nunjudged documents (about 70% at  = 10) in our test collections\n.\n4.2 Results Table 1 presents the performance of the proposed method compared\nagainst baselines. Here, bold numbers indicate the best-performing\nmodel, and superscripts indicate statistical significance computed\nwith two-sided t-tests at  < 0.05. Here, we first note the performance of baseline approaches. We\nsee BM25 outperformed by Contriver, a transformer bi-encoder\nmodel trained for zero-shot retrieval; this mirrors prior work .\nNext, we see supervised bi-encoder models trained on similar\npassage (MPNet-1B) and question-answer (BERT-MSM) pairs\noutperform a weakly supervised model (Contriver) by smaller margins.\nFinally, the Grounded LLM outperforms all bi-encoder baselines,\nindicating strong few-shot generalization and mirroring prior results\n. Examining the Mint models, we first note that the\nBiEncMint sees statistically significant improvement compared to BM25\nRecall@100\nand outperforms the best bi-encoder baselines by 11-13% on\nprecision measures and 5-7% on recall measures. Specifically, we see a\nmodel trained for question-answering (BERT-MSM) underperform\nBiEnc-Mint, indicating the challenge of the NDR task. Further,\nBiEnc-Mint, trained on 5 orders of magnitude lesser data than\nMPNet-1B, sees improved performance ? indicating the quality of\ndata obtained from Mint. Furthermore, BiEnc-Mint also performs\nat par with a 175B LLM while ofering the inference eficiency of a\nsmall-parameter bi-encoder. Next, we see CrEnc-Mint outperform\nthe baseline bi-encoders, BiEnc-Mint, UPR, and Grounded LLM\nby 4-21% on precision measures and 7-13% on recall measures ?\ndemonstrating the value of Mint for training NDR models.\n4.3 Ablations In Table 2, we ablate various design choices in Mint. Diferent\nchoices result in diferent training sets for the BiEnc and CrEnc\nmodels. Also, note that in reporting ablation performance for CrEnc,\nwe still use the performant BiEnc-Mint model for obtaining\nnegative examples for training and first-stage ranking. Without\nhighquality negative examples, we found CrEnc to result in much poorer\nperformance. No item fil tering. Since synthetic queries are unlikely to\nrep\nresent all the items of a user, Mint excludes user items { }=1\nwhich have a low likelihood of being generated from the document\n(3.2.2). Without this step, we expect the training set for training\nretrieval models to be larger and noisier. In Table 2, we see that\nexcluding this step leads to a lower performance for BiEnc and\nCrEnc, indicating that the quality of data obtained is important for\nperformance. 6B LLM for QGen. Mint relies on using an expensive 175B\nparameter InstructGPT model for QGen. Here, we investigate the\neficacy for generating  for { }=1 with a 6B parameter\nInstructGPT model (text-curie-001). We use an identical setup to the\n175B LLM for this. In Table 2, we see that training on the synthetic\nnarrative queries of the smaller LLM results in worse models ?\noften underperforming the baselines in Table 1. This indicates the\ninability of a smaller model to generate complex narrative queries\nwhile conditioning on a set of user items. This necessity of a larger\nLLM for generating queries in complex retrieval tasks has been\nobserved in prior work . CONCLUSIONS In this paper, we present Mint, a data augmentation method for the\nnarrative-driven recommendation (NDR) task. Mint re-purposes\nhistorical user-item interaction datasets for NDR by using a 175B\nparameter large language model to author long-form narrative queries\nwhile conditioning on the text of items liked by users. We evaluate\nbi-encoder and cross-encoder models trained on data from Mint on\nthe publicly available Pointrec test collection for narrative-driven\npoint of interest recommendation. We demonstrate that the\nresulting models outperform several strong baselines and ablated models\nand match or outperform a 175B LLM directly used for NDR in a\n1-shot setup. However, Mint also presents some limitations. Given our use of\nhistorical interaction datasets for generating synthetic training data\nand the prevalence of popular interests in these datasets longer,\ntailed interests are unlikely to be present in the generated\nsynthetic datasets. In turn, causing retrieval models to likely see poorer\nperformance on these requests. Our use of LLMs to generate\nsynthetic queries also causes the queries to be repetitive in structure,\nlikely causing novel longer-tail queries to be poorly served. These\nlimitations may be addressed in future work. MAP Recall@100 Besides this, other avenues also present rich future work. While\nMint leverages a 175B LLM for generating synthetic queries, smaller\nparameter LLMs may be explored for this purpose - perhaps by\ntraining dedicated QGen models. Mint may also be expanded to\nexplore more active strategies for sampling items and users for\nwhom narrative queries are authored - this may allow more\neficient use of large parameter LLMs while ensuring higher quality\ntraining datasets. Next, the generation of synthetic queries from\nsets of documents may be explored for a broader range of retrieval\ntasks beyond NDR given its promise to generate larger training\nsets ? a currently underexplored direction. Finally, given the lack of\nlarger-scale test collections for NDR and the efectiveness of LLMs\nfor authoring narrative queries from user-item interaction, fruitful\nfuture work may also explore the creation of larger-scale datasets\nin a mixed-initiative setup to robustly evaluate models for NDR. ACKNOWLEDGMENTS W e   t h a n k   a n o n y m o u s   r e v i e w e r s   f o r   t h e i r   i n v a l u a b l e   f e e d b a c k .   T h i s \n w o r k   w a s   p a r t l y   s u p p o r t e d   b y   t h e   C e n t e r   f o r   I n t e l l i g e n t \n I n f o r m a t i o n   R e t r i e v a l ,   N S F   g r a n t s   I I S - 1 9 2 2 0 9 0   a n d   2 1 4 3 4 3 4 ,   t h e   O f i c e   o f \n N a v a l   R e s e a r c h   c o n t r a c t   n u m b e r   N 0 0 0 1 4 2 2 1 2 6 8 8 ,   a n   A m a z o n   A l e x a \n P r i z e   g r a n t ,   a n d   t h e   C h a n   Z u c k e r b e r g   I n i t i a t i v e   u n d e r   t h e   p r o j e c t \n S c i e n t i f i c   K n o w l e d g e   B a s e   C o n s t r u c t i o n .   A n y   o p i n i o n s ,   f i n d i n g s \n a n d   c o n c l u s i o n s   o r   r e c o m m e n d a t i o n s   e x p r e s s e d   h e r e   a r e   t h o s e   o f \n t h e   a u t h o r s   a n d   d o   n o t   n e c e s s a r i l y   r e f l e c t   t h o s e   o f   t h e   s p o n s o r s .",
  "references": [
    "Jafar Afzali, Krisztian Balog, '['POINTREC: A Test Collection for Narrative-Driven Point of Interest Recommendation', 'Association for Computing Machinery']', In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (Virtual Event, Canada) (SIGIR '21), 2021",
    "Jaime Arguello, Fernando Diaz, 'Tip of the Tongue Known-Item Retrieval: A Case Study in Movie Identification', In Proceedings of the 6th international ACM SIGIR Conference on Human Information Interaction and Retrieval, 2021",
    "Toine Bogers, Mette Skov, '['What was this Movie About this Chick?? A Comparative Study of Relevance Aspects in Book and Movie Discovery', 'Shefield']', In Transforming Digital Worlds: 13th International Conference, ['2018', '2018', '2018']"
  ],
  "keywords": [
    "Augmented Narrative Driven",
    "Language Model Augmented",
    "Model Augmented Narrative",
    "Model Augmented",
    "USA USA USA",
    "Narrative Driven",
    "UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst",
    "Augmented Narrative",
    "MAP MRR Recall",
    "cid",
    "USA USA",
    "UniversityofMassachusettsAmherst UniversityofMassachusettsAmherst",
    "https",
    "USA",
    "language models",
    "Large Language Model",
    "Model Parameters NDCG",
    "Driven",
    "NDR",
    "Augmented"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1lwcHwr2fmVspHZdY3VsKeCb0J2kaRLr3"
}
{
  "id": 23,
  "title": "A Prototype Implementation of an Orthographic Software Modeling Environment",
  "authors": [
    "Colin Atkinson",
    "Christian Tunjic",
    "Dietmar Stoll",
    "Jacques Robin"
  ],
  "institutions": [
    "Universidade Federal de",
    "University of Mannheim"
  ],
  "resume": "Orthographic Software Modeling (OSM) is a view-centric software engineering approach that aims to leverage the orthographic projection metaphor used in the visualization of physical objects to visualize software systems. Although the general concept of OSM does not prescribe speci c sets of views, a concrete OSM environment has to be speci c about the particular views to be used in a particular project. At the University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views de ned by the KobrA 2.0 method, a version of KobrA adapted for OSM. In this paper we provide an overview of the KobrA 2.0 metamodel underpinning nAOMi and give a small example of its use to model a software system.",
  "content": "1. INTRODUCTION Orthographic Software Modeling (OSM) is based on three\nfundamental hypotheses | (a) that it is feasible to\nintegrate the many di erent kinds of artifacts used in\ncontemporary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that copies\nbear this notice and the full citation on the first page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior specific\npermission and/or a fee. VAO ?13, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e cient and scalable way of\nsupporting these views by generating them dynamically, on-the- y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an\nintuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique\nunderpinning the CAD tools used in other engineering disciplines. As shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \\dimensions\", each containing\nwell de ned choices (or so called \\dimension elements\") that\ncan be used to select individuals views. As shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be\nintroduced by simply de ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important\nadvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same,\noverarch 2. SUM PACKAGE Figure 4 depicts the internal structure of the SUM\npackage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and\nbehavioral constructs respectively, and one containing the\nconstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules. The Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA\nmetamodel, such as Class and ComponentClass. The internal\nstructure of this package is illustrated in Figure 5.\nComponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \\data type\" objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su cient\nto use a Class (which is limited to using OCL constraints). ComponentClass inherits (indirectly via Class) from\nCommunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Behavior::ProtocolStateMachines\nit possible to model whether its instances are active or\npassive. Active objects, which can be used to model threads and\nprocesses ( p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously. A ComponentClass may exhibit complex behavior. In\nKobrA, this behavior may be speci ed in the form of UML\nState Diagrams (de ning acceptable operation invocation\nsequences), and in the form of Activities (de ning algorithms\nof operations). UML Interaction elements (in sequence\ndiagrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation\nsequences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext ComponentClass\n-- only allow Activity elements or ProtocolStateMachines\ninv : ownedBehavior -> forAll ( oclIsKindOf ( Actitivity ) or\noclIsKindOf ( ProtocolStateMachine )) For example, since KobrA has no concept of roles for\ncomponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded. 3. VIEWS PACKAGE The structure of the Views package is illustrated in Figure\n6. Again, since most of the views de ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements. For instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML. The substructure of the Views package re ects the types\nand organization of the KobrA views according to the view\n\\dimensions\" supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci cation and Realization options of the\nencapsulation dimension. These, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension. Finally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA. The Service view shows the direct, publicly visible\nrelationships of the subject ComponentClass to other\nComponentClasses, while the Type view shows the publicly\nvisible relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de ned to control what can\ngo into each view and when they are well formed. For\nevery view, a constraint enumerates all allowed elements (not\nshown in this paper). In the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi er )\nare not shown.\ncontext ComponentClass\n-- no nested classifiers , no protocol\ninv : nestedClassifier -> union ( protocol ) -> isEmpty () Classes are only allowed if they are generalizations of\nComponentClasses, (or any of its superclasses, since a\nComponentClass may inherit from a class as shown in the\nconstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class). Specification Structural\nOperational\nService Type\nRealization Structural\nOperational Service Type\nBehavioral\nBehavioral\nClass Instance\nService Type Service Type Protocol Only operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re ected in the last constraint.\ncontext Operation\n-- only the signature of the Operation is shown , not\nits behavior ( role name \" method \" refers to the\nActivities of the operation ) , or dependencies\ninv : method -> union ( precondition ) -> union ( body ) -> union (\npostcondition ) -> isEmpty () 4. TRANSFORMATIONS PACKAGE T h e   p a c k a g e   A l l V i e w s   p r o v i d e s   t h e   f o u n d a t i o n   f o r \n s p e c i f y i n g   t h e   t r a n s f o r m a t i o n s   b e t w e e n   t h e   S U M   a n d   t h e   v i e w s \n i n   b o t h   d i r e c t i o n s .   P a r t   o f   t h e   p a c k a g e ' s   c o n t e n t s   a r e   s h o w n \n i n   F i g u r e   7 .   T h e   A b s t r a c t i o n   c o n c e p t   ( w h i c h   i s   i n   f a c t   a 5. NAVIGATION Most of today's tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any\nenvironment incorporating a number of di erent tools there is\ninvariably a large number of di erent trees storing a\nheterogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g. class\ndiagrams, state diagrams) and other artifact types (source code,\nXML les, con guration les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools. In contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci cally, as illustrated in Figure 9, OSM regards\ndimension of the underlying methodology as representing a di\nerent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nselectable elements (i.e. coordinates) is xed, dynamic\ndimensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements. To support the OSM dimension based navigation metaphor\nfor KobrA, we de ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci c model) and Code, captures\nthe model-driven development concern of KobrA. The\nversion dimension captures the state of the modeled system at\nspeci c points in time. The Component dimension, which\nhas dynamic dimension elements de ned by instances of the\nclass ComponentClass in the SUM, captures the\ncomponentbased development concern of KobrA. The Encapsulation dimension, which has two xed\nelements, supports the distinction between Speci cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the xed elements Structural,\nOperational and Behavioral covers the di erent information\ntypes. The Granularity dimension provides a ner grained\ndistinction between views describing the types used by\ncomponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The\nOperation dimension allows a selection of individual operations. In the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent. However, this is very di cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di erent choices in di erent dimensions, so that the\ndecisions made in one dimensions may a ect choices\npossible in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e. dimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet)\ndened by the method at hand. 6. SHOPPING CART EXAMPLE To show how a software system can be speci ed using\nnAOMi, this section presents a case study based on a\nshopping cart system. A ShoppingCart component collects and\nmanages the products selected by users and supports\npayment via a credit card. Figure 10 illustrates a structural\nview of the component. In the dimension navigator on the left hand side, PIM\nwas chosen for the \\Abstraction Level\" (not expanded in the\nscreenshot). The second dimension is the state of the\nsoftware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions. The component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the- y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component. Figure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nsince there are only two transitions with the operation\naddProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second\npostcondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The\nproperties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example. Figure 12 shows the publicly visible behaviour of the\nShoppingCart component with states and transitions. The\nconditional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and\nproperties are consistent with those in the structural view. Although the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi cant di erences. The focus of the\noperational view is on a precise formal de nition of an\noperation of a component. The operations can be enriched by\npreand postconditions which can be de ned using complex OCL\nstatements, that formalize the complete behavior of an\noperation. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7. CONCLUSION At the beginning of the paper we identi ed three\nfundamental hypothesis upon which the notion of OSM is based\n| (a) that it is feasible to integrate the many di erent kinds\nof artifacts used in contemporary software engineering\nmethods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ncient and scalable way of supporting these views by\ngenerating them dynamically, on-the- y, from a Single\nUnderlying Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the\northographic projection technique underpinning the CAD tools\nused in other engineering disciplines. The prototype tool, nAOMi, described in this paper\nrepresents the rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of\nhypothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of\ngenerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open. Although nOAMi is the only tool developed with the\nspeci c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims. For\nexample, Glinz et al.  describe a tool with a sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the\nsheye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g. for structural and behavioral\nviews. An approach which also emphasizes the description of\nformal consistency rules (correspondences) between views is\nRM-ODP . However, this approach does not\nexplicitly mention the notion of a SUM and thus implies that\nconsistency rules should be de ned in a pairwise fashion\nbetween individual pairs of views. ArchiMate , which\ncomplements TOGAF , is an enterprise architecture\nmodeling language which o ers two orthogonal \"dimensions\" for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural ) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle \\dimension\", the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework . Regarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to\ntoday. For this rst prototypical SUM-based environment\nsupporting the OSM approach we had a method at our disposal\n(KobrA) that already de ned a full set of orthogonal\nUMLbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML\nmetamodels, removing and adding model elements as needed. In doing so we were able to manually ensure that the\nmetamodels ful lled the two core requirements of SUM-based\nenvironments | (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o , and to be introduced into existing,\nheterogeneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni ed metamodel will be\nrequired.",
  "references": [
    "C. Atkinson, J. Bayer, C. Bunse, E. Kamsties, O. Laitenberger, R. Laqua, D. Muthig, B. Paech,  J., J. Zettel, '['Wu\\x7fst, and', 'Component-Based Product Line Engineering with UML']', Addison Wesley, November 2001",
    "C. Atkinson, D. Stoll, P. Bostan. Orthographic Software, 'Modeling: A Practical Approach to View-Based Development', , 2010",
    "C. Atkinson, D. Stoll, C. Tunjic, 'Orthographic Service Modeling', In Proceedings of 15th IEEE EDOC Conference Workshops (EDOCW), 2011"
  ],
  "keywords": [
    "SUM",
    "views",
    "View",
    "Transformation Views SUM",
    "inv",
    "Figure",
    "elements",
    "Type Service Type",
    "Class",
    "Views SUM levels",
    "Service Type Service",
    "Service Type",
    "UML",
    "software engineering",
    "Transformation",
    "KobrA",
    "Service view",
    "Software",
    "Structural Service View",
    "Views SUM"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=12Qu2nxHLG7w3gK-zGax-tqJUrdTtogfv"
}
{
  "id": 24,
  "title": "Towards a Quantum Software Modeling Language",
  "authors": [
    "Carlos A. Prez-Delgado?",
    "Hector G. Perez-Gonzalez"
  ],
  "institutions": [
    "Universidad Auto?noma de San Luis Potosi?",
    "University of Kent"
  ],
  "resume": "We set down the principles behind a modeling language for quantum software. We present a minimal set of extensions to the wellknown Unified Modeling Language (UML) that allows it to efectively model quantum software. These extensions are separate and independent of UML as a whole. As such they can be used to extend any other software modeling language, or as a basis for a completely new language. We argue that these extensions are both necessary and suficient to model, abstractly, any piece of quantum software. Finally, we provide a small set of examples that showcase the efectiveness of the extension set.",
  "content": "CCS CONCEPTS ?   G e n e r a l   a n d   r e f e r e n c e   ?   G e n e r a l   c o n f e r e n c e   p r o c e e d i n g s ; \n D e s i g n ;   ?   S o f t w a r e   a n d   i t s   e n g i n e e r i n g   ?   S y s t e m \n d e s c r i p t i o n   l a n g u a g e s ;   U n i f i e d   M o d e l i n g   L a n g u a g e   ( U M L )   ;   S o f t w a r e \n d e s i g n   e n g i n e e r i n g ;   ?   T h e o r y   o f   c o m p u t a t i o n   ?   Q u a n t u m \n c o m p u t a t i o n   t h e o r y ;   Q u a n t u m   i n f o r m a t i o n   t h e o r y . \n q u a n t u m   c o m p u t i n g ,   s o f t w a r e   e n g i n e e r i n g ,   U M L 1 INTRODUCTION Quantum computation rose to prominence after the discovery of\nquantum algorithms that can eficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation, data structures,\nand cryptography.\n?Both authors contributed equally to this research. Quantum computation has, until today, been studied almost\nexclusively ?in the small.? A general understanding of quantum\ncomputation, or, quantum programming ?in the large? is yet to be\ndeveloped. Here we aim to set the foundations of a general\nframework for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML), and introduce a minimum set of\nextensions that allow it to efectively model quantum software. Assuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2 Q-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set. Our first observation is about the nature of quantum\ncomputation. The central diference between quantum and classical\ncomputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms, and quantum data-structures,\nthat are unavailable to classical computers?hence their\nperformance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective. It would seem then that quantum computation introduces\nnothing to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of\ninformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration?which needs to be included in any efective software\ndesign. A third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent\nconsiderations. A classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A\nquantum module may or may not have to; i.e. a module?s quantum\nbehavior may be completely part of its internal implementation\nand not appear as part of its interface. For instance, take a module\nimplementing Shor?s algorithm. Shor?s algorithm uses quantum\nefects to eficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical. More generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum\nsoftware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum\ninformation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document. The importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space. Finally, it is true that quantum information is strictly a super-set\nof classical information?and hence a quantum module can\ncommunicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface\nelement and messaging when classical would sufice is bad quantum\nsoftware design, for the reasons stated above. In summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the\ninput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical\nmodules can communicate with each other as long as their\ninterfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule. We will argue in Sec. 2.3 how these extensions are not only\nnecessary, but also suficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1 Class Diagram Extensions UML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication. For attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following\nconvention. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold. Relationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects. Fig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2 Sequence Diagram Extensions Sequence diagrams in UML allow us to portray the dynamic\nrelationship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to diferentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves diferently from classical information; it can\nstore/portray diferent data; it admits diferent operations; and, it\nrequires diferent hardware to store, send, and receive. Like before, we make use of bold text to markup quantum\nmodules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us?especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources?which composed modules are using quantum resources. Also, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both ?set? messages are quantum. Likewise, the return\nmessages ? and ? are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This\ndiagram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions. Discussion We have proposed a minimal series of extensions to existing\nsoftware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language. We?ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also suficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan eficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used. The one remaining information element we have not discussed\nis algorithm eficiency. If quantum computation is to be used, it\nwill most likely be due to the eficient algorithms at its disposal.\nThat said, algorithm eficiency is not a solely quantum\nconsideration. UML itself does not inherently have language elements for\nalgorithm eficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.). Other modeling languages may also have definite algorithm\neficiency elements. We argue that it is best to use existing language\nelements when they are available. ACKNOWLEDGMENTS C P - D   w o u l d   l i k e   t o   a c k n o w l e d g e   f u n d i n g   t h r o u g h   t h e   E P S R C \n Q u a n t u m   C o m m u n i c a t i o n s   H u b   ( E P / T 0 0 1 0 1 1 / 1 ) .   T h e   a u t h o r s   w o u l d   a l s o \n l i k e   t o   t h a n k   J o a n n a   I .   Z i e m b i c k a   f o r   u s e f u l   c o m m e n t s   d u r i n g   t h e \n p r e p a r a t i o n   o n   t h i s   m a n u s c r i p t .",
  "references": [
    "given-names, surname, 'Quantum supremacy using a programmable superconducting processor', Nature, ['2019', '2019']",
    "H Charles,  Bennett and Gilles Brassard, 'Quantum cryptography: public key distribution and coin tossing', Theor. Comput. Sci, ['2014', '2014']",
    "Grady Booch, Ivar Jacobson, 'Unified Modeling Language User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series)', Addison-Wesley Professional., 2005"
  ],
  "keywords": [
    "International Conference",
    "Software Engineering Workshops",
    "Engineering Workshops",
    "Quantum",
    "IEEE",
    "ACM",
    "ICSEW",
    "Software Modeling Language",
    "International",
    "Workshops",
    "Software",
    "Conference",
    "UML",
    "Modeling Language",
    "Conference on Software",
    "Quantum Software Modeling",
    "Quantum Software",
    "module",
    "Software Modeling",
    "QFT"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1bSsVFPA7sJsx3TVPcz--05GpxYSPckCG"
}
{
  "id": 25,
  "title": "AI Model for Computer games based on Case Based Reasoning and AI Planning",
  "authors": [
    "Vlado Menkovski Athens Information Technology"
  ],
  "institutions": [
    "General Terms Algorithms",
    "Peania"
  ],
  "resume": "Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.",
  "content": "Categories and Subject Descriptors I . 2 . 1   [ A p p l i c a t i o n s   a n d   E x p e r t   S y s t e m s ] :   G a m e s 1. Introduction The goal of this effort is to explore a model for design and\nimplementation of an AI agent for turn based games. This model\nprovides for building more capable computer opponents that rely\non strategies that closely resemble human approach in solving\nproblems opposed to classical computational centric heuristics in\ngame AI. In this manner the computational resources can be\nfocused on more sensible strategies for the game play.\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for profit or commercial advantage and that\ncopies bear this notice and the full citation on the first page. To copy\notherwise, or republish, to post on servers or to redistribute to lists,\nrequires prior specific permission and/or a fee. DIMEA?08, September 10?12, 2008, Athens, Greece. Copyright 2008 ACM 978-1-60558-248-1/08/09... $5.00 Dimitrios Metafas\nAthens Information Technology\n0.8km Markopoulou Ave. 2. Game Trees and Minimax xref #text 3. AI Planning for building Game Trees 3.1.1 AI Planning AI Planning also referred as Automated Planning and\nScheduling is a branch of Artificial Intelligence that focuses on\nfinding strategies or sequences of actions that reach a predefined\ngoal . Typical execution of AI Planning algorithms is by\nintelligent agents, autonomous robots and unmanned vehicles.\nOpposed to classical control or classification AI Planning results\nwith complex solutions that are derived from multidimensional\nspace. AI Planning algorithms are also common in the video game\ndevelopment. They solve broad range of problems from path\nfinding to action planning. A typical planner takes three inputs: a\ndescription of the initial state of the world, a description of the\ndesired goal, and a set of possible actions. Some efforts for\nincorporating planning techniques for building game trees have\nalso shown up, similar to the approach explored in this effort. In\naddition Cased Based Reasoning  techniques are also gathering\npopularity in developing strategies based in prior knowledge\nabout the problems in the games. One of the benefits from\nHierarchical Task Network (HTN)  planning is the possibility\nto build Game Trees based on HTN plans; this method is\ndescribed in the following section. 3.2 Game Trees with AI Planning An adaptation of the HTN planning can be used to build\nmuch smaller and more efficient game trees. This idea has already\nbeen implemented in the Bridge Baron a computer program for\nthe game of Contact Bridge . Computer programs based on Game Tree search techniques\nare now as good as or better than humans in many games like\nChess  and checkers , but there are some difficulties in\nbuilding a game tree for games that have imperfect information\nand added uncertainty like card or games with dice. The main\nproblem is the enormous number of possibilities that the player\ncan choose from in making his move. In addition some of the\nmoves are accompanied with probabilities based on the random\nelements in the games. The number of possible moves\nexponentially grows with each move so the depth of the search\nhas to be very limited to accommodate for the memory\nlimitations. The basic idea behind using HTN for building game trees is\nthat the HTN provides the means of expressing high level goals\nand describing strategies how to reach those goals. These goals\nmay be decomposed in goals at lower level called sub-goals. This\napproach closely resembles the way a human player usually\naddresses a complex problem. It is also good for domains where\nclassical search for solution is not feasible due to the vastness of\nthe problem domain or uncertainties.\n3.2.1 Hierarchical Task Networks The Hierarchical Task Network, or HTN, is an approach to\nautomated planning in which the dependency among actions can\nbe given in the form of networks  [Figure 1]. A simple task network (or just a task network for short) is an\nacyclic digraph in which U is the node set, E is the\nedge set, and each node contains a task . The edges of\ndefine a partial ordering of U. If the partial ordering is total, then\nwe say that is totally ordered, in which case can be written as\na sequence of tasks . Buy milk\nGo to (shop) Purchase Go to (home)\nA Simple Task Network (STN) method is a 4-tuple of its name,\ntask, precondition and a task network. The name of the method\nlets us refer unambiguously to substitution instances of the\nmethod, without having to write the preconditions and effects\nexplicitly. The task tells what kind of task can be applied if the\npreconditions are met. The preconditions specify the conditions\nthat the current state needs to satisfy in order for the method to be\napplied. And the network defines the specific subtasks to\naccomplish in order to accomplish the task. A method is relevant for a task if the current state satisfies the\npreconditions of a method that implements that task. This task can\nbe then substituted with the instance of the method. The\nsubstitution is basically giving the method network as a solution\nfor the task. If there is a task ?Go home? and the distance to home is 3km\n[Figure 2] and there exists a method walk-to and this method has a\nprecondition that the distance is less than 5km, then a substation\nto the task ?Go home? can be made with this method instance.\nIf the distance is larger than 5km another method instance needs\nto be substituted [Figure 3]. An STN planning domain is a set of operations O and a set of\nmethods M. A STN planning problem is a 4-tuple of the initial\nstate S0, the task network w called initial task network and the\nSTN domain. A plan is a solution for a planning\nproblem if there is a way to decompose w into ? if ? is executable\nand each decomposition is applicable in the appropriate state of\nthe world. The algorithm that is capable to decompose these\nnetworks into plans is called Total-forward-decomposition (TFD)\n or Partial-forward-decomposition (PFD). However there are\ncases where one does not want to use a forward-decomposition\nprocedure. HTN planning is generalization of STN planning that\ngives the planning procedure more freedom about how to\nconstruct the task networks. In order to provide this freedom, a bookkeeping mechanism\nis needed to represent constraints that the planning algorithm has\nnot yet enforced. The bookkeeping is done by representing the\nunenforced constraints explicitly in the task network. The HTN generalizes the definition of a task network in\nSTN. A task network is the pair where is a set of\ntask nodes and C is a set of constraints. Each constraint in C\nspecifies a requirement that must be satisfied by every plan that is\na solution to a planning problem. The definition of a method in HTN also generalizes the\ndefinition used in STN planning. A HTN plan is a 4-tuple of\nname, task, subtasks, and constraints. The subtasks and the\nconstraints form the task network. The HTN planning domains are\nidentical to STN planning domains except they use HTN methods\ninstead of STN methods. Compared to classical planners the primary advantage of\nHTN planners is their sophisticated knowledge representation and\nreasoning capabilities. They can represent and solve a variety of\nnon-classical planning problems; with a good set of HTNs to\nguide them, they can solve classical planning problems orders of\nmagnitude more quickly than classical or neoclassical planners.\nThe primary disadvantage of HTN is the need of the domain\nauthor to write not only a set of planning operators but also a set\nof methods.\n3.2.2 HTN Planning in building Game Trees For a HTN planning algorithm to be adapted to build game\ntrees we need to define the domain (set of HTN methods and\noperators) which is the domain of the game. This is in some sense\na knowledge representation of the rules of the game, the game\nenvironments and possible strategies of game play. In this domain the game rules as well as known strategies to\ntackle specific task are defined. The implementation of Game\nTree building with HTN is called Tignum2 . This\nimplementation uses a procedure similar to\nforwarddecomposition, but adapted to build up a game tree rather than a\nplan. The branches of the game tree represent moves generated by\nthe methods. Tignum2 applies all methods applicable to a given\nstate of the world to produce new states of the world and\ncontinues recursively until there are no applicable methods that\nhave not already been applied to the appropriate state of the\nworld. In the task network generated by Tignum2, the order in which the\nactions will occur is determined by the total-ordering constraints.\nBy listing the actions in the order they will occur, the task\nnetwork can be ?serialized? into a game tree [Figure 4] [Figure 5]. 4. Case Based Reasoning in Game Strategies  4.1 Case Based Reasoning Case-based reasoning (CBR) is a well established subfield of\nArtificial Intelligence (AI), both as a mean for addressing AI\nproblems and as a basis for standalone AI technology.\nCase-based reasoning is a paradigm for combining\nproblemsolving and learning that has became one of the most successful\napplied subfield of AI of recent years. CBR is based on the\nintuition that problems tend to recur. It means that new problems\nare often similar to previously encountered problems and,\ntherefore, that past solutions may be of use in the current situation\n. CBR is particularly applicable to problems where earlier cases are\navailable, even when the domain is not understood well enough\nfor a deep domain model. Helpdesks, diagnosis or classification\nsystems have been the most successful areas of application, e.g.,\nto determine a fault or diagnostic an illness from observed\nattributes, or to determine whether or not a certain treatment or\nrepair is necessary given a set of past solved cases .\nCentral tasks that all CBR methods have to deal with are : \"to\nidentify the current problem situation, find a past case similar to\nthe new one, use that case to suggest a solution to the current\nproblem, evaluate the proposed solution, and update the system by\nlearning from this experience. How this is done, what part of the\nprocess that is focused, what type of problems that drives the\nmethods, etc. varies considerably, however\". While the underlying ideas of CBR can be applied\nconsistently across application domains, the specific\nimplementation of the CBR methods ?in particular retrieval and\nsimilarity functions? is highly customized to the application at\nhand. 4.2 CBR and Games M a n y   d i f f e r e n t   i m p l e m e n t a t i o n s   o f   C B R   e x i s t   i n   g a m e s . \n C B R   t e c h n o l o g y   i s   n i c e l y   s u i t e d   f o r   r e c o g n i z i n g   c o m p l e x \n s i t u a t i o n s   m u c h   e a s i e r   a n d   m o r e   e l e g a n t   t h a n   t r a d i t i o n a l   p a r a m e t e r \n c o m p a r i s o n   o r   f u n c t i o n   e v a l u a t i o n .   T h e r e   a r e   e s p e c i a l l y   e v i d e n t \n c a s e s   i n   r e a l   t i m e   s t r a t e g i e s   w h e r e   d i f f e r e n t   a t t a c k   a n d   d e f e n s e   o f \n g l o b a l   s t r a t e g i e s   a r e   n i c e l y   d e f i n e d   b y   C B R   d a t a s e t s   a n d   l a t e r   u s e d \n i n   t h e   r u n n i n g   g a m e s .   A l s o   i n t e l l i g e n t   b o t s   b e h a v i o r   i s   a l s o \n a n o t h e r   t y p i c a l   e x a m p l e .   D e p e n d i n g   o n   t h e   n u m b e r   o f   e n e m y   b o t s \n t h e   l a y o u t   o f   t h e   t e r r a i n   a n d   p o s i t i o n   o f   h u m a n   p l a y e r s   t h e   C B R \n s y s t e m   f i n d s   t h e   c l o s e s t   C B R   c a s e   a n d   e m p l o y s   t h a t   s t r a t e g y \n a g a i n s t   t h e   h u m a n   p l a y e r s   w h i c h   i n   p r i o r   e v a l u a t i o n   w a s   p r o v e d   t o \n b e   h i g h l y   e f f i c i e n t . 5. Game Trees with AI Planning ? Tic-tac-toe In order to show the expressive power of AI Planning in\ndefining strategies for games, and the use of these plans to build\nGame Trees I implemented an algorithm that builds Game Trees\nfor the Tic-Tac-Toe game. The game tree of Tic-Tac-Toe shows 255,168 possible\ngames of which 131,184 are won by X (the first player), 77904\nare won by O and the rest 46,080 are draw . All these games\ncan be derived from building a complete Game Tree. Even though it is possible to build a complete game tree of\nTic-tac-toe it is definitely not an optimal solution. Many of the\nmoves in this tree would be symmetrical and also there are a many\nmoves that would be illogical or at least a bad strategy to even\nconsider. So what strategy should X (the first player) choose in order\nto win the game? There are few positions that lead to certain victory. These\npositions involve simultaneous attack on two positions so the\nother player could not defend, basically the only trick in\nTic-TacToe. Position 2 lead to victory if two of the three fields: top right\ncorner, bottom right corner and bottom middle are free [Figure ].\nAnd in the third position if the two of center, middle top and\nmiddle left are available the position is a certain victory. There are many different arrangements of the player?s tokens\nthat give equivalent positions as these three positions. By using\nplanning we do not need to consider all possible layouts but just\nconsider these three similar to what a human would consider. 5.1 Hierarchical Task Network Top level task is Play [Figure 12]. This is a complex task and\ncan be derived into: Win, Block, Tie or Search for Plan. The\nSearch for plan is derived to both Plan 1 and Plan 2 or Plan 3 and\nPlan 4, which later leads to a call for the opponent?s move and a\nrecursive call to Play. This HTN when executed will result with plans for possible\ngame scenarios. By creating nodes from each position and linking\nthem with branches with the move of the player we create a game\ntree for the Tic-tac-toe game over which we can run the minimax\nalgorithm. This set up with 7 plans with 3 target strategies creates a tree\nfor Tic-tac-toe which considers all possible moves for the second\nplayer with only 457 games, 281 of which X wins 176 are draw\nand 0 where the second opponent wins. This is a significant\nreduction over the 255, 168 possible games with a complete game\ntree. These reductions can be very useful for devices with limited\ncomputing capabilities but also we prove a very important point\nthat planning can be very efficient if designing meaningful game\ntrees by applying reasoning very similar to human player\nreasoning. Further improvements to the game tree are also possible if\nthe opponents moves are also planned, in other words if we drop\nall the meaningless and symmetrical moves of the opponent. 6. Game AI in Monopoly  6.1 Overview of the AI Implementation The AI agent is responsible for the moves of the artificial\nplayers in the game. The core principle of the AI agent is building\na Game Tree with all the sensible moves that all the players would\nmake from the current point of time forward. Then using the\nminimax algorithm the agent selects the move that in the future\nwould bring the computer player most favorable game position\nwith the highest probability. Building a Game Tree in this game\nthat would be big enough to consider sufficient number of moves\nis obstructed by the vastness of possible moves in combination\nwith all the possible random landings of the dice. The number of\nnodes of the game tree exponentially grows at each level. To\ntackle this problem the AI agents incorporates two already\ndiscussed technologies: Case Based Reasoning and AI Planning. The technologies are employed in the following manner.\nFirst the agent searches the CBR database to find the case with the\nlargest similarity with the current state of the board. This case is\nassociated with a playing strategy. The strategy consists of goal\nthat the planner needs to build plans for, and the plans consist of\nconsecutive player moves that bring the player to that goal. This\nway only moves that are part of that strategy are considered, those\nbeing a small fraction of the overall possible moves the number of\nedges of the game tree at each level decreases immensely. At each level of the game tree the model considers the moves\nof a single player. After the strategies of the AI player are\nconsidered the response to those strategies needs to be considered\nby the opponent(s). The move of the opponent(s) depends of the\nprobability distribution of the dice as well as the strategy of the\nplayer. A more general strategy needs to be implemented for the\nopponent?s (human player) moves since we cannot be aware of\nthe expertise of the opponent. This general strategy would bring\nmore plausible moves than the focused strategy of the AI player. After covering all opponents the agent comes back to\ndeducting a feature move of the computer player by using the\nCBR selected plan strategy. After creating several loops of\nstrategies and reaching a reasonable size of a Game Tree taking\ninto account the memory limits and the rapidly decreasing\nprobabilities that the move is possible due to the distribution of\nthe dice the building of the Game Tree stops. Then the minimax\nalgorithm searches the Game Tree and decides on the most\nfavorable move for the AI player using the minimax algorithm.\nThe process is repeated each time the AI player is up. Buying, auctioning and trading game moves are always\naccompanied by return of investment calculations in making the\nplans. These calculations represent adaptation of the more general\nplanning associated with the cases in the CBR database. These\nadaptations are necessary due to the fact that the cases do not\nidentically correspond to the situation on the table. In addition\ncalculating the game position value of each node of the game tree\nis done by heuristic functions that incorporate economic\ncalculations of net present value, cash, and strategic layout and so\non. For example railroads in monopoly are known to be\nstrategically effective because they bring constant income even\nthough the income can be smaller than building on other\nproperties. 6.2 Details on the CBR Implementation The implementation of the CBR is by using the JColibri2\nplatform. JColibri2 is an object-oriented framework in Java for\nbuilding CBR systems that is an evolution of previous work on\nknowledge intensive CBR . For this implementation we need to look into three particular\nclasses of the JColibri2 platform. The StandardCBRApplication,\nConnector, CBRQuery. For a JColibri2 implementation the\nStandardCBRApplication interface needs to be implemented. The CBR cycle executed accepts an instance of CBRQuery.\nThis class represents a CBR query to the CBR database. The\ndescription component (instance of CaseComponent) represents\nthe description of the case that will be looked up in the database.\nAll cases and case solutions are implementing the\nCaseComponent interface. The JColibri2 platform connects to the CBR database via a\nConnector class. Each connector implements all the necessary\nmethods for accessing the database, retrieval of cases, storing and\ndeletion of cases. This implementation uses a custom XML\nstructure for holding the CBR cases. Since the game will not\nupdate the CBR database only read it, a XML solution satisfies\nthe needs. The XML file to a certain extent is similar to the XML\nrepresentation of the board. We are interested in finding one\nCBRCase that is the most similar case to the situation in the game\nat the time of the search. This procedure is done in the cycle\nmethod of the CBRApplication. The JColibri2 CBR comparison is\ndone by Nearest Neighbor (NN) search method. JColibri2 offers implementations for NN search algorithms\nof simple attributes. These implementations are called local\nsimilarities. For complex attributes like in our case global\ncustomized similarity mechanisms need to be implemented. The MonopolyDescription class [Figure 13] is basically a\nserialization of the GameState. It holds all the information about\nthe state of the board, the players, their amount of cash etc. On the other hand the MonopolySolution class holds the\nthree particular attributes that are needed for the planning, the\nplanning Domain, State and TaskList. The game is implemented by using the\nModel-ViewController software development pattern. The controller is\nresponsible for implementing the game rules and handling all of\nthe events in the game like roll of dice, input commands for\ntrading, auctioning and etc from the players. The View layer is\nresponsible for displaying the board and all of the input widgets\non to the game screen, and the models are data structures\nrepresenting the game state [Figure 14].\n6.2.1 Complex Similarity representation in CBR The similarity measurement part of the Nearest Neighbor\nalgorithm JColibri2 is implemented by implementing the\nLocalSimiralrityFunction and the GlobalSimiralityFunction\ninterface. A local similarity function is applied to simple attributes\nby the NN algorithm, and a global similarity function is applied to\ncompound attributes. In the case of our implementation the\nattributes of the MonopolyDescription are compound attributes\ndescribing the state of the board, number of players, amount of\ncash for every player and etc. Since MonopolyDescription is a\ncustom CaseComponent a global similarity function needs to be\nimplemented to accurately find the distance between different\nCBR cases. The similarity mechanism is inseparable core element of the\nCBR system. This mechanism represents how the CBR decides\nwhich strategy is best suited for the particular situation by\ncalculating the distance or similarity to other cases in the\ndatabase. For the monopoly implementation we need to consider\nseveral basic strategies. Monopoly is based on investing in\nproperties and receiving revenues from those investments. One of\nthe basic strategies of the game is to build a set of properties that\nwill bring constant income larger than the one of the opponents.\nSo in time the opponents will have to declare bankruptcy. But on\nthe other hand over investment can lead to too stretched resources\nwith low income that will eventually drove the player to\nbankruptcy. To decide on these two we need a clear separation\ninto two groups of cases in the CBR database. The first group of\ncases will represent a situation on the board where the player has\nsignificant income per loop formed of one or more color group\nproperties, maybe railroads, some buildings on them and so on. It\nis important to note that in this case the player is better situated\nthan his opponents so he only needs to survive long enough to win\nthe game. In the other group of cases either the opponent is not\nwell positioned on the board or its opponents are better situated.\nIn this case further investments are necessary to improve the\nsituation so the player can have a chance of winning in the long\nrun. These metrics can be owning color groups, valuing groups of\nrailroads, evaluating the other opponents as well, and considering\nthe amount of cash. As it is obvious in monopoly the number of\nstreets is not as nearly as important as the combination of streets\nthe player owns. It is also important to note that one CBR case\ndoes not hold only a single strategy in place, but its solution can\nhave multiple different strategic goals. For example one CBR case\nmight simultaneously say buy this land to form a color group but\nalso trade some other unimportant property to increase cash\namount. The cases do not represent all possible combinations of board\npositions. They are only representation of typical game scenarios.\nThe CBR Case solutions do not give exact instructions in general\nbut rather strategic goals. For example one CBR Solution might\nsay trade the streets that you only have one of each for the ones\nthat you have two of that color already. Then the planner based on\nthe situation on the board needs to decompose this high level task\nto a low level operations. Like offer \"Mediterranean Avenue\" for\n\"Reading Railroad\" and offer $50. The exact amounts and actual\nstreets are left to the planer to evaluate. The monopoly CBR database is currently in development on\na monopoly clone game called Spaceopoly. The cases are\narchitected based on human player experience and knowledge.\nThere is a plan of making a number of slightly different strategies\nthat differ on the style of playing and then running simulation\ntests that would determine the particular validity of each database\nas well as validity of certain segments of the strategy or even\nparticular cases in the database. The actual execution of the strategies will not differ from\nstrategy to strategy since the plan execution is more related to the\nstructure and rules of the game than to the actual playing strategy. 6.3 Details on the Planning Implementation xref #text 7. Conclusion Even though the results from the CBR database are not\ncomplete at this time partial strategies are implemented as cases\nand recognized during game play by the CBR system. These\nsmaller local strategies coupled with more global higher level\nstrategies that are particularly important at the beginning of the\ngame would form a complete CBR database and represent a\nknowledge engineered style of playing of the AI player. The AI Planning approach is a proven method by the\ntic-tactoe experiment and is suitable for implementing the strategies\nassociated with the CBR cases. This approach in general benefits from both technologies,\nCBR as well as AI Planning and comprises an elegant solution.\nEven though AI Planning can be enough as a single technology\nfor some simpler problems like tic-tac-toe the complexity of\nMonopoly would mean that the Planner would have to incorporate\nlarge and complex domain and a very big state model. The CBR\napplication helps reduce this complexity by focusing the planning\non smaller domain of the game. Basically the CBR reduces the\noverall goal of the play (wining the game) to smaller more\nconcrete goals suitable to the particular state of the game, thus\nreducing the need for global planning strategies and complex\nplanning domain. Furthermore this symbiosis of technologies gives way for\nmore precise and finely tuned strategies which can be difficult to\ninclude into global plan for the whole game. One simple example\nfor the Monopoly game would be this: Sometimes it?s better to\nstay in jail because rolling double increases the probability of\nlanding on some field (two, four, six, eight, ten or twelve steps\nfrom the jail) that can be of great importance to the rest of the\ngame. These and similar small local strategies can be easily\nrecognized by similar cases in the CBR database. In other words the system is flexible enough so that new\nstrategies can be incorporated easily missing strategies can be also\nrecognized by the distance metrics as well as wrong assumptions\nin the strategies can be easily recognized. One other important property of the system is that is highly\nconfigurable. The game its self can be diversely different\ndepending on the configuration of the board. Even though the\nplatform is restricted to Monopoly type of games, changing the\nlayout and values of the fields effectively brings completely\ndifferent properties of the game. In addition the CBR database\nrepresents the entire experience of the AI Player. It can be filled\nwith rich set of strategies or even configured with different flavors\nof difficulties of play, this of course coupled with the domain of\nthe planner which can differ from a case to a case as well. 8. Future Work Further exploration of this technology would go towards\ncomplete implementation of an AI aware agent for monopoly.\nInitial results from the local cases with more specific strategies\nshow CBR as a capable tool for representing expertise in playing\nthe game. Completing the more general strategies and coupling\nthem with the planning domain will give precise results on the\nbenefits from this architecture. There is also need for exploring the planning of strategies of\nopponents. This task is to some extent different because we\ncannot always expect the opponent to select the best move we\nthink. In the Tic-tac-toe example all possible moves of the\nopponent were taken into consideration, if we used the same\nplanner for the opponent only tie games would result from the\ngame tree. In other words mistakes of the players also need to be\nconsidered. The CBR Platform brings other functionalities well worth of\nexploring as well. The revision stage of the JColibri2 platform is\nbasically capable of fine tuning strategies or even developing new\nstrategies for the games. A well written underlying AI planning\nmodel with a capable feedback of the game tree evaluation back\nto the CBR revision capability can be an interesting concept in\nautomatic experience acquisition for the AI model. There are also many other fields were combined CBR and\nplanning approach can be incorporated into a problem solution.\nThis combination is analogous in a big extent to a human way of\nreasoning. People in addition to logic of reasoning in situations\nwith lack of information rely to planning strategies and prior\nexperience, exactly the intuition behind CBR ? AI Planning\narchitecture. 9. ACKNOWLEDGMENTS W e   w o u l d   l i k e   t o   t h a n k   P r o f .   S o f i a   T s e k e r i d o u   f o r   h e r \n i n v o l v e m e n t   i n   t h e   v a l u a b l e   d i s c u s s i o n s   w e   h a d   o n   t h e   t o p i c   o f \n C B R .",
  "keywords": [
    "Game Tree",
    "game trees",
    "game",
    "building game trees",
    "CBR",
    "Game Trees game",
    "Planning",
    "games",
    "CBR database",
    "Digital Interactive Media",
    "Task Network",
    "Tree",
    "cid",
    "Task",
    "Game Trees based",
    "player",
    "CBR case",
    "HTN planning",
    "Figure",
    "HTN"
  ],
  "urlPDF": "https://drive.google.com/uc?export=download&id=1h6mJjF-bJ-jzLDfgQgZCTo7V68sQTg3Z"
}
